[{"name":"dtiInit","github":"brainlife/app-dtiinit","desc":"Runs vistasoft/dtiInit to preprocess and register dwi to anat/t1","stats":{"stars":1,"requested":14370,"users":39,"success_rate":54.957372908114934,"serviceinfo":{"_id":"5d729e1e78356a109788b233","counts":{"_id":"5e5c686f87cac7de3eab1b92","failed":30,"finished":1044,"removed":1558,"requested":1609,"running":1089,"running_sync":0,"stop_requested":29},"success_rate":97.20670391061452,"users":19,"readme_status":"ok","runtime_mean":2202728,"runtime_std":3686661.6435123985,"service":"brainlife/app-dtiinit","__v":0},"gitinfo":{"desc":"Runs vistasoft/dtiInit to preprocess and register dwi to anat/t1","tags":["diffusion-preprocessing"],"stats":{"stars":1},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lindsey Kitchell","email":null},{"name":"Paolo Avesani","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":1459889.81,"runtime_std":1528096.900155986,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf24bde14be11ff25ae6e"}],"examples":5,"groups":63},"create_date":"2017-02-18T01:05:51.509Z","doi":"10.25663/bl.app.3"},{"name":"Freesurfer","github":"brainlife/app-freesurfer","desc":"Freesurfer segments the t1w anatomical data into functionally different parts of the brain. Segmentation/parcellation can then be fed to many other subsequent analysis. ","stats":{"stars":1,"serviceinfo":{"_id":"5d729e1e78356a109788b237","counts":{"_id":"5e5c687087cac710c7ab1b93","failed":2373,"finished":7602,"removed":15314,"requested":17864,"running":10020,"running_sync":0,"stop_requested":967},"success_rate":76.21052631578948,"users":86,"readme_status":"ok","runtime_mean":33554577.82,"runtime_std":31101394.54702112,"service":"brainlife/app-freesurfer","__v":0},"gitinfo":{"desc":"Freesurfer segments the t1w anatomical data into functionally different parts of the brain. Segmentation/parcellation can then be fed to many other subsequent analysis. Please consider using OSG version of Freesurfer (https://brainlife.io/app/5931c0b8ff090a00210eff09) to process a large number of subjects. ","tags":["analysis","anatomy-preprocessing"],"stats":{"stars":1},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Lindsey Kitchell","email":null}]},"success_rate":48.68517116737809,"users":431,"runtime_mean":32186778.47,"runtime_std":21686686.3444785,"requested":368573,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf250de14be11ff25b094"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf250de14be11ff25b095"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf250de14be11ff25b096"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf250de14be11ff25b097"}],"examples":5,"groups":1071},"create_date":"2017-02-18T01:05:51.509Z","doi":"10.25663/bl.app.0"},{"name":"Network Neuro","github":"brainlife/app-networkneuro","desc":"Build structural brain networks using diffusion-weighted MRI, tractography and a brain atlas for cortical and subcortical parcellation.","stats":{"stars":2,"requested":12127,"users":31,"success_rate":36.78949431595453,"serviceinfo":{"_id":"5d729e1e78356a109788b201","counts":{"_id":"5e5c687187cac74fdeab1b94","failed":61,"finished":115,"removed":125,"requested":195,"running":172,"running_sync":0,"stop_requested":8},"success_rate":65.3409090909091,"users":14,"readme_status":"ok","runtime_mean":5663272.09,"runtime_std":15846236.322127793,"service":"brainlife/app-networkneuro","__v":0},"gitinfo":{"desc":"Build structural brain networks using diffusion-weighted MRI, tractography and a brain atlas for cortical and subcortical parcellation.","tags":["analysis"],"stats":{"stars":2},"contributors":[{"name":"Brent McPherson","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":12052772.49,"runtime_std":20335184.622566253,"resources":[],"examples":3,"groups":35},"create_date":"2017-04-07T00:08:21.513Z","doi":"10.25663/bl.app.47"},{"name":"MRtrix2 Tracking with dtiInit","github":"brainlife/app-tracking","desc":"This service uses mrtrix 2.0 to track using three methods DTI-based Deterministic, CSD-based Probabilistic and Deterministic. It generates three separate tractograms (TCK), one for each algorithm.","stats":{"stars":0,"requested":772,"users":10,"success_rate":0,"serviceinfo":{"_id":"5d729e1f78356a109788b2a3","counts":{"_id":"5e5c687287cac70b79ab1b95","failed":98,"finished":0,"removed":146,"requested":168,"running":110,"running_sync":0,"stop_requested":18},"success_rate":0,"users":6,"readme_status":"ok","service":"brainlife/app-tracking","__v":0},"gitinfo":{"desc":"This service uses mrtrix 2.0 to track using three methods DTI-based Deterministic, CSD-based Probabilistic and Deterministic. It generates three separate tractograms (TCK), one for each algorithm.","tags":["tracking"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Lindsey Kitchell","email":null},{"name":"Paolo Avesani","email":null}]},"resources":[],"examples":0,"groups":12},"create_date":"2017-02-18T01:05:51.509Z","doi":"10.25663/bl.app.59"},{"name":"LiFE with dtiInit","github":"brainlife/app-life","desc":"LiFE (Linear Fasicle Evaluation) predicts the measured diffusion signal using the orientation of the fascicles present in a connectome. LiFE uses the difference between the measured and predicted diffusion signals to measure prediction error. The connectome model prediction error is used to compute two metrics to evaluate the evidence supporting properties of the connectome.","stats":{"stars":1,"requested":11930,"users":38,"success_rate":87.2557928214448,"serviceinfo":{"_id":"5d729e1e78356a109788b1ff","counts":{"_id":"5e5c687387cac736e7ab1b96","failed":135,"finished":194,"removed":198,"requested":652,"running":362,"running_sync":0,"stop_requested":8},"success_rate":58.96656534954408,"users":20,"readme_status":"ok","runtime_mean":3978616.38,"runtime_std":5754398.031555204,"service":"brainlife/app-life","__v":0},"gitinfo":{"desc":"LiFE (Linear Fasicle Evaluation) predicts the measured diffusion signal using the orientation of the fascicles present in a connectome. LiFE uses the difference between the measured and predicted diffusion signals to measure prediction error. The connectome model prediction error is used to compute two metrics to evaluate the evidence supporting properties of the connectome.","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lindsey Kitchell","email":null},{"name":"Ariel Rokem","email":"arokem@gmail.com"},{"name":"Steven O'Riley","email":null},{"name":"Brent McPherson","email":null},{"name":"Brian Wandell","email":null}]},"runtime_mean":10802537.57,"runtime_std":31841149.15570827,"resources":[],"examples":2,"groups":52},"create_date":"2017-02-18T01:05:51.509Z","doi":"10.25663/bl.app.1"},{"name":"AFQ Tract Classification with LiFE","github":"brainlife/app-tractclassification","desc":"This service uses Automated fiber quantification AFQ and fe structure output from LiFE to identify major tract segments and quantify tissue properties along their trajectories. You can choose to have the zero weighted fibers (as determined by LiFE) removed before or after AFQ is applied. useinterhemisphericsplit is a variable from AFQ, which if set to true will cut fibers crossing between hemispheres with a midsaggital plane below z=-10. This is to get rid of CST fibers that appear to cross at the level of the brainstem. For more information about AFQ see https://github.com/yeatmanlab/AFQ/wiki","stats":{"stars":0,"requested":3423,"users":33,"success_rate":49.98354721948009,"serviceinfo":{"_id":"5d729e1e78356a109788b21b","counts":{"_id":"5e5c687587cac76bafab1b97","failed":352,"finished":255,"removed":787,"requested":809,"running":280,"running_sync":0,"stop_requested":22},"success_rate":42.00988467874794,"users":21,"readme_status":"too short","runtime_mean":4841074.02,"runtime_std":6487919.963962646,"service":"brainlife/app-tractclassification","__v":0},"gitinfo":{"desc":"This service uses Automated fiber quantification AFQ and fe structure output from LiFE to identify major tract segments and quantify tissue properties along their trajectories. You can choose to have the zero weighted fibers (as determined by LiFE) removed before or after AFQ is applied. useinterhemisphericsplit is a variable from AFQ, which if set to true will cut fibers crossing between hemispheres with a midsaggital plane below z=-10. This is to get rid of CST fibers that appear to cross at the level of the brainstem. For more information about AFQ see https://github.com/yeatmanlab/AFQ/wiki","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Steven O'Riley","email":null}]},"runtime_mean":506468.95,"runtime_std":549388.260618688,"resources":[],"examples":0,"groups":27},"create_date":"2017-02-18T01:05:51.509Z","doi":"10.25663/bl.app.56"},{"name":"Round b-values / Flip b-vecs for dtiInit","github":"brainlife/app-datanormalize","desc":"(soon to be deprecated) This service round the b-values to the nearest 100. It will also flip the b-vecs around one or more chosen axes (please use Test Gradient Flip app to find out which one needs to be flipped). Some apps requires b-values to be round for their algorithms to work properly.","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1f78356a109788b2f7","counts":{"_id":"5e5c687687cac76eecab1b98","failed":1160,"finished":7195,"removed":8816,"requested":13523,"running":8234,"running_sync":0,"stop_requested":130},"success_rate":86.11609814482347,"users":31,"readme_status":"ok","runtime_mean":457217.38,"runtime_std":627787.970992114,"service":"brain-life/app-datanormalize","__v":0},"gitinfo":{"desc":"(soon to be deprecated) This service round the b-values to the nearest 100. It will also flip the b-vecs around one or more chosen axes (please use Test Gradient Flip app to find out which one needs to be flipped). Some apps requires b-values to be round for their algorithms to work properly.","tags":["diffusion-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"success_rate":100,"users":3,"runtime_mean":85004.30769230769,"runtime_std":91424.42046965908,"requested":18,"resources":[],"examples":1,"groups":6},"create_date":"2017-05-25T18:38:13.562Z","doi":"10.25663/bl.app.4"},{"name":"Split Shells","github":"brainlife/app-splitshells","desc":"Split multi-shell diffusion data into a single chosen b value shell while rounding bvals","stats":{"stars":0,"requested":2473,"users":27,"success_rate":91.46280579131303,"serviceinfo":{"_id":"5d729e1e78356a109788b229","counts":{"_id":"5e5c687787cac7de27ab1b99","failed":29,"finished":462,"removed":833,"requested":858,"running":610,"running_sync":0,"stop_requested":121},"success_rate":94.09368635437882,"users":14,"readme_status":"ok","runtime_mean":313953.05,"runtime_std":194584.31356763456,"service":"brainlife/app-splitshells","__v":0},"gitinfo":{"desc":"Split multi-shell diffusion data into a single chosen b value shell while rounding bvals","tags":["diffusion-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":99288.89,"runtime_std":135753.42899093893,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf274de14be11ff25b4d2"}],"examples":3,"groups":43},"create_date":"2017-05-30T18:16:55.217Z","doi":"10.25663/bl.app.17"},{"name":"Ensemble Tracking with dtiInit","github":"brainlife/app-ensembletracking","desc":"This App creates a large set of candidate streamlines using an ensemble of algorithms and parameter values. All outputs will be then combined into a single track.tck output.","stats":{"stars":0,"requested":2015,"users":13,"success_rate":34.54641350210971,"serviceinfo":{"_id":"5d729e1f78356a109788b2cf","counts":{"_id":"5e5c687887cac7753eab1b9a","failed":3487,"finished":8002,"removed":13974,"requested":22463,"running":16311,"running_sync":0,"stop_requested":341},"success_rate":69.64922969797198,"users":61,"readme_status":"ok","runtime_mean":6502764.34,"runtime_std":3757949.399415393,"service":"brain-life/app-ensembletracking","__v":0},"gitinfo":{"desc":"This service uses MRtrix 0.2.12 to do ensemble tracking using tensor and constrained spherical deconvolution (csd) algorithms. It generates a large set of candidate streamlines using a tensor-based deterministic model, csd-based deterministic model, and csd-based probabilistic model. The csd-based models can be computed at lmax values of 2, 4, 6, 8, 10, and 12. All candidate streamlines are combined into a single track.mat file. If you know the max lmax value for your data input the value for max_lmax, otherwise leave it blank and it will be calculated for you. If you wish to use just deterministic tracking (MRtrix streamtrack parameter SD_STREAM) check do_deterministic. If you wish to use just probabilistic tracking (MRtrix streamtrack parameter SD_PROB) check do_probabilistic If you wish to use the tensor tracking (MRtrix streamtrack parameter DT_STREAM) check do_tensor. By default it will use all three tracking methods. For more information about Ensemble Tractography see Takemura, H., Caiafa, C. F., Wandell, B. A., & Pestilli, F. (2016). Ensemble tractography. PLoS computational biology, 12(2), e1004692.","tags":["brain-connectome","diffusion-mri","mri","tracking","tractography","white-matter"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Brent McPherson","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":1206734.29,"runtime_std":2026412.4706887305,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf27bde14be11ff25b5d7"}],"examples":2,"groups":13},"create_date":"2017-05-30T18:37:00.962Z","doi":"10.25663/bl.app.33"},{"name":"Binary Tract Masks","github":"kitchell/app-generatetractmasks","desc":"app to generate binary masks of the segmented fiber tracts","stats":{"stars":0,"requested":10227,"users":8,"success_rate":97.32898056091408,"serviceinfo":{"_id":"5d729e1f78356a109788b2f1","counts":{"_id":"5e5c687987cac7ba03ab1b9b","failed":158,"finished":6143,"removed":7259,"requested":9779,"running":6321,"running_sync":0,"stop_requested":65},"success_rate":97.49246151404539,"users":6,"readme_status":"ok","runtime_mean":7967674.38,"runtime_std":20064547.981120333,"service":"kitchell/app-generatetractmasks","__v":0},"gitinfo":{"desc":"app to generate binary masks of the segmented fiber tracts","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":1867230.15,"runtime_std":1669497.647901622,"resources":[],"examples":0,"groups":7},"create_date":"2017-05-30T18:55:58.823Z","doi":"10.25663/brainlife.app.142"},{"name":"3D Tract Surfaces","github":"kitchell/app-generatetractsurfaces","desc":"app to generate surfaces of each fiber tract","stats":{"stars":0,"requested":9424,"users":14,"success_rate":98.2351053588619,"serviceinfo":{"_id":"5d729e1f78356a109788b30b","counts":{"_id":"5e5c687a87cac73d90ab1b9c","failed":162,"finished":9184,"removed":9251,"requested":9420,"running":9303,"running_sync":0,"stop_requested":13},"success_rate":98.26663813396105,"users":10,"readme_status":"ok","runtime_mean":325577.4,"runtime_std":313812.4076364094,"service":"kitchell/app-generatetractsurfaces","__v":0},"gitinfo":{"desc":"app to generate surfaces of each fiber tract","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":325577.4,"runtime_std":313812.4076364094,"resources":[],"examples":0,"groups":5},"create_date":"2017-06-01T17:07:35.770Z","doi":"10.25663/brainlife.app.108"},{"name":"Freesurfer on OSG (fsurf)","github":"brainlife/app-freesurfer-osg","desc":"A Pegasus workflow for running FreeSurfer on the Open Science Grid","stats":{"stars":0,"requested":240,"users":9,"success_rate":5.240174672489083,"serviceinfo":{"_id":"5d729e1e78356a109788b20b","counts":{"_id":"5e5c687a87cac7566aab1b9d","failed":158,"finished":470,"removed":1848,"requested":2017,"running":929,"running_sync":0,"stop_requested":334},"success_rate":74.84076433121018,"users":11,"readme_status":"ok","runtime_mean":129984753.41,"runtime_std":58332240.99430344,"service":"brainlife/app-fsurf","__v":0},"gitinfo":{"desc":"Run freesurfer (v6) on Open Science Grid using fsurf command.","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":59877015.666666664,"runtime_std":35020234.91876788,"resources":[{"resource_id":"5931bee335530000253833d2","name":"osgconnect","_id":"642cf28bde14be11ff25b64a"}],"examples":0,"groups":10},"create_date":"2017-06-02T19:47:04.671Z","doi":"10.25663/bl.app.49"},{"name":"Deprecated - Laplace Beltrami Spectrum","github":"kitchell/app-LBspectrum","desc":"This application will calculate the Laplace Beltrami spectrum of 3D surfaces in the .vtk file format using the LBS function provided with Mindboggle (http://www.mindboggle.info/). This application computes the Laplace-Beltrami spectrum using a linear finite element method, following the definitions and steps given in Reuter et al.'s 2009 paper: \"Discrete Laplace-Beltrami Operators for Shape Analysis and Segmentation\". Options for normalization are: None, \"area\", \"index\", \"areaindex\". Normalization by area uses the area of the 2D structure as in Reuter et al. 2006. Normalization by index will divide the eigenvalues by their index to account for linear increase of Eigenvalue magnitude (Weyl's law in 2D) as suggested in Reuter et al. (2006) and used in BrainPrint (Wachinger et al. 2015). The default is areaindex, which will do both. References (please cite when using for publication): Martin Reuter et al. Discrete Laplace-Beltrami Operators for Shape Analysis and Segmentation. Computers & Graphics 33(3):381-390, 2009 Martin Reuter et al. Laplace-Beltrami spectra as \"Shape-DNA\" of surfaces and solids. Computer-Aided Design 38(4):342-366, 2006  ","stats":{"stars":0,"requested":8646,"users":3,"success_rate":73.63889256855212,"serviceinfo":{"_id":"5d729e1f78356a109788b333","counts":{"_id":"5e5c687b87cac77b08ab1b9e","failed":1990,"finished":5559,"removed":5996,"requested":8646,"running":7636,"running_sync":0,"stop_requested":365},"success_rate":73.63889256855212,"users":3,"readme_status":"too short","runtime_mean":37014831.05,"runtime_std":15884585.983855179,"service":"kitchell/app-LBspectrum","__v":0},"gitinfo":{"desc":"This application will calculate the Laplace Beltrami spectrum of 3D surfaces in the .vtk file format using the LBS function provided with Mindboggle (http://www.mindboggle.info/). This application computes the Laplace-Beltrami spectrum using a linear finite element method, following the definitions and steps given in Reuter et al.'s 2009 paper: \"Discrete Laplace-Beltrami Operators for Shape Analysis and Segmentation\". Options for normalization are: None, \"area\", \"index\", \"areaindex\". Normalization by area uses the area of the 2D structure as in Reuter et al. 2006. Normalization by index will divide the eigenvalues by their index to account for linear increase of Eigenvalue magnitude (Weyl's law in 2D) as suggested in Reuter et al. (2006) and used in BrainPrint (Wachinger et al. 2015). The default is areaindex, which will do both. References (please cite when using for publication): Martin Reuter et al. Discrete Laplace-Beltrami Operators for Shape Analysis and Segmentation. Computers & Graphics 33(3):381-390, 2009 Martin Reuter et al. Laplace-Beltrami spectra as \"Shape-DNA\" of surfaces and solids. Computer-Aided Design 38(4):342-366, 2006  ","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":37014831.05,"runtime_std":15884585.983855179,"resources":[],"examples":0,"groups":1},"create_date":"2017-06-08T18:38:50.968Z","doi":"10.25663/brainlife.app.143"},{"name":"HCP Pipeline","github":"soichih/app-bids-hcppipeline","desc":"Run HCP Pipeline powered by BIDS app","stats":{"stars":0,"requested":26,"users":3,"success_rate":27.77777777777778,"serviceinfo":{"_id":"5d729e1f78356a109788b33f","counts":{"_id":"5e5c687c87cac773c0ab1ba0","failed":13,"finished":5,"removed":12,"requested":26,"running":21,"running_sync":0,"stop_requested":3},"success_rate":27.77777777777778,"users":3,"readme_status":"too short","runtime_mean":32793107.6,"runtime_std":43886625.308774926,"service":"soichih/app-bids-hcppipeline","__v":0},"gitinfo":{"desc":"Run HCP Pipeline powered by BIDS app","tags":["pipeline"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":32793107.6,"runtime_std":43886625.308774926,"resources":[],"examples":0,"groups":1},"create_date":"2017-06-23T00:45:10.046Z","doi":"10.25663/bl.app.82"},{"name":"Connectome Evaluator ","github":"brainlife/app-connectome-evaluator","desc":"Estimate the quality of your diffusion-weighted data to map human connectomes.","stats":{"stars":1,"requested":1,"users":1,"serviceinfo":{"_id":"5d729e1f78356a109788b2c5","counts":{"_id":"5e5c687e87cac7c990ab1ba2","failed":56,"finished":174,"removed":239,"requested":263,"running":199,"running_sync":0,"stop_requested":15},"success_rate":75.65217391304347,"users":14,"readme_status":"too short","runtime_mean":171274.32,"runtime_std":45939.28686622811,"service":"brain-life/app-connectome-evaluator","__v":0},"gitinfo":{"desc":"Estimate the quality of your diffusion-weighted data to map human connectomes.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"resources":[],"examples":0,"groups":1},"create_date":"2017-06-30T00:26:23.064Z","doi":"10.25663/bl.app.102"},{"name":"Tract Profiles","github":"brainlife/app-tract-profile","desc":"This app takes in tracking data from the White Matter Segmentation app well as the nifti files of the user and gives tract profiles for each tracking file in a json format.","stats":{"stars":0,"requested":16,"users":3,"success_rate":0,"serviceinfo":{"_id":"5d729e1f78356a109788b327","counts":{"_id":"5e5c687e87cac79f8cab1ba3","failed":13,"finished":0,"removed":13,"requested":16,"running":11,"running_sync":0,"stop_requested":1},"success_rate":0,"users":3,"readme_status":"too short","service":"brain-life/app-tract-profile","__v":0},"gitinfo":{"desc":"This app takes in tracking data from the White Matter Segmentation app well as the nifti files of the user and gives tract profiles for each tracking file in a json format.","tags":["tracking"],"stats":{"stars":0},"contributors":[{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":null,"runtime_std":null,"resources":[],"examples":0},"create_date":"2017-07-10T14:27:05.150Z","doi":"10.25663/bl.app.86"},{"name":"WMC Figures (AFQ or WMA)","github":"kitchell/app-AFQ_figures","desc":"This service creates 4 figures of each AFQ tract: axial, left sagittal, right sagittal, coronal. Please choose the t1 image slices you would like displayed. The default slices work well for the HCP t1 images if they have not been re-ACPC aligned. If you have ACPC aligned your t1 images using the ACPC alignment app on Brain Life the following values are a good starting point: coronal = 105, sagittal = 89, axial = 65. The img_min and img_max values refer to the value range displayed for the t1 image. The value range is calulated as follow (mean + img_min * std, mean + img_max * std). The default values are a good starting place, adjust them if your t1 is too dark or too light.","stats":{"stars":0,"requested":2093,"users":41,"success_rate":80.65934065934066,"serviceinfo":{"_id":"5d729e1f78356a109788b32b","counts":{"_id":"5e5c687f87cac79ccaab1ba4","failed":201,"finished":949,"removed":1252,"requested":1388,"running":1140,"running_sync":0,"stop_requested":89},"success_rate":82.52173913043478,"users":12,"readme_status":"ok","runtime_mean":1916239.32,"runtime_std":162761.39941693048,"service":"kitchell/app-AFQ_figures","__v":0},"gitinfo":{"desc":"This service creates 4 figures of each AFQ tract: axial, left sagittal, right sagittal, coronal. Please choose the t1 image slices you would like displayed. The default slices work well for the HCP t1 images if they have not been re-ACPC aligned. If you have ACPC aligned your t1 images using the ACPC alignment app on Brain Life the following values are a good starting point: coronal = 105, sagittal = 89, axial = 65. The img_min and img_max values refer to the value range displayed for the t1 image. The value range is calulated as follow (mean + img_min * std, mean + img_max * std). The default values are a good starting place, adjust them if your t1 is too dark or too light.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":824849.84,"runtime_std":3312293.4410328493,"resources":[],"examples":0,"groups":36},"create_date":"2017-07-13T17:56:46.087Z","doi":"10.25663/brainlife.app.145"},{"name":"Plot 3D Surfaces ","github":"kitchell/app-plot3Dobjects","desc":"This service creates images of 3D surfaces of the major tracts segmented by AFQ or WMA in 4 views: axial, coronal, left and right sagittal.","stats":{"stars":0,"requested":9372,"users":5,"success_rate":94.54145469544892,"serviceinfo":{"_id":"5d729e1f78356a109788b315","counts":{"_id":"5e5c688087cac79d82ab1ba5","failed":396,"finished":6876,"removed":8192,"requested":9371,"running":7043,"running_sync":0,"stop_requested":30},"success_rate":94.55445544554455,"users":4,"readme_status":"ok","runtime_mean":361411.75,"runtime_std":151276.28163624165,"service":"kitchell/app-plot3Dobjects","__v":0},"gitinfo":{"desc":"This service creates images of 3D surfaces of the major tracts segmented by AFQ or WMA in 4 views: axial, coronal, left and right sagittal.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":361411.75,"runtime_std":151276.28163624165,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf2abde14be11ff25b65d"}],"examples":0,"groups":3},"create_date":"2017-07-17T15:43:22.155Z","doi":"10.25663/brainlife.app.131"},{"name":"Freesurfer Deface","github":"brainlife/app-deface","desc":"Runs freesurfer/mri_deface with talairach_mixed_with_skull.gca and face.gca","stats":{"stars":0,"requested":2422,"users":24,"success_rate":41.00985221674877,"serviceinfo":{"_id":"5d729e1f78356a109788b2ad","counts":{"_id":"5e5c688187cac703e0ab1ba6","failed":859,"finished":2196,"removed":6528,"requested":6993,"running":2969,"running_sync":0,"stop_requested":59},"success_rate":71.88216039279868,"users":24,"readme_status":"too short","runtime_mean":1513684.8,"runtime_std":1709238.5304946993,"service":"brain-life/app-deface","__v":0},"gitinfo":{"desc":"Runs freesurfer/mri_deface with talairach_mixed_with_skull.gca and face.gca","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":311229.25,"runtime_std":434405.3104510665,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf2b0de14be11ff25b684"}],"examples":1,"groups":31},"create_date":"2017-07-21T00:39:19.596Z","doi":"10.25663/brainlife.app.146"},{"name":"Test Gradient Flip for dtiInit processing","github":"brainlife/app-testgradientflip","desc":"application to test if the gradients (bvecs) need to be flipped","stats":{"stars":0,"requested":5,"users":2,"success_rate":0,"serviceinfo":{"_id":"5d729e1f78356a109788b331","counts":{"_id":"5e5c688187cac72711ab1ba7","failed":138,"finished":417,"removed":538,"requested":742,"running":539,"running_sync":0,"stop_requested":34},"success_rate":75.13513513513513,"users":20,"readme_status":"ok","runtime_mean":30679977.67,"runtime_std":26631234.265194666,"service":"kitchell/app-testgradientflip","__v":0},"gitinfo":{"desc":"This application will provide a recommendation on which axis you should flip the bvecs of your data, if it is necessary. It will perform fiber tracking using 4 different gradient flip options (no flip, x flip, y flip, and z flip) and report the most likely flip needed for your data. The flip recommendation is made based on the flip direction with the highest number of long fibers.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Steven O'Riley","email":null}]},"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf2b5de14be11ff25b687"}],"examples":0,"groups":2},"create_date":"2017-07-25T18:51:46.321Z","doi":"10.25663/bl.app.18"},{"name":"Clean WMC output","github":"brainlife/app-AFQclean","desc":"(deprecated by Remove Tract Outliers App) This service cleans the output from AFQ and WMA using AFQ's AFQ_removeFiberOutliers function. For more information on the inputs of this application, please read the documentation at the top of the function: https://github.com/yeatmanlab/AFQ/blob/master/functions/AFQ_removeFiberOutliers.m","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1e78356a109788b209","counts":{"_id":"5e5c688287cac7c174ab1ba8","failed":627,"finished":3584,"removed":3926,"requested":4382,"running":4023,"running_sync":0,"stop_requested":25},"success_rate":85.11042507717882,"users":7,"readme_status":"too short","runtime_mean":1411358.6,"runtime_std":1492658.6931826174,"service":"brainlife/app-AFQclean","__v":0},"gitinfo":{"desc":"(deprecated by Remove Tract Outliers App) This service cleans the output from AFQ and WMA using AFQ's AFQ_removeFiberOutliers function. For more information on the inputs of this application, please read the documentation at the top of the function: https://github.com/yeatmanlab/AFQ/blob/master/functions/AFQ_removeFiberOutliers.m","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Steven O'Riley","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":85.11042507717882,"users":7,"runtime_mean":1411358.6,"runtime_std":1492658.6931826174,"requested":4382,"resources":[],"examples":0,"groups":2},"create_date":"2017-07-31T20:00:06.462Z","doi":"10.25663/bl.app.11"},{"name":"MRIQC","github":"brainlife/app-mriqc","desc":"Runs MRIQC pipeline (http://mriqc.readthedocs.io/en/stable/reports/smri.html) from Poldrack Lab on selected T1 anatomy.","stats":{"stars":0,"requested":23763,"users":49,"success_rate":81.32886742483252,"serviceinfo":{"_id":"5d9a84741316625da551b273","counts":{"_id":"5e5c688387cac797e9ab1ba9","failed":2,"finished":31,"removed":32,"requested":39,"running":39,"running_sync":0,"stop_requested":6},"success_rate":93.93939393939394,"users":5,"readme_status":"too short","runtime_mean":8462088.741935484,"runtime_std":35030107.52730543,"service":"brainlife/app-mriqc","__v":0},"gitinfo":{"desc":"Runs MRIQC pipeline (http://mriqc.readthedocs.io/en/stable/reports/smri.html) from Poldrack Lab on selected T1 anatomy.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":699483.09,"runtime_std":511608.74011592305,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf2c0de14be11ff25b75c"}],"examples":2,"groups":74},"create_date":"2017-08-21T01:33:47.086Z","doi":"10.25663/bl.app.52"},{"name":"Quantitative Statistics of Classified Fiber Tracts","github":"brainlife/app-classifiedfibertractstats","desc":"This will give you the fiber count, mean length, standard deviation of length, total length, and volume of each fiber tract classified by AFQ or WMA.","stats":{"stars":0,"requested":5,"users":2,"success_rate":100,"serviceinfo":{"_id":"5d729e1f78356a109788b30d","counts":{"_id":"5e5c688487cac7cb91ab1baa","failed":389,"finished":12137,"removed":14521,"requested":17185,"running":12486,"running_sync":0,"stop_requested":32},"success_rate":96.89445952418968,"users":15,"readme_status":"ok","runtime_mean":1497857.82,"runtime_std":4074154.7970297043,"service":"kitchell/app-classifiedfibertractstats","__v":0},"gitinfo":{"desc":"This will give you the fiber count, mean length, standard deviation of length, total length, and volume of each fiber tract classified by AFQ or WMA.","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":26105.5,"runtime_std":5268.568330201289,"resources":[],"examples":0,"groups":2},"create_date":"2017-08-24T19:42:02.143Z","doi":"10.25663/bl.app.12"},{"name":"FreeSurfer Postprocessing","github":"brainlife/app-freesurfer-post","desc":"The converts labeled volumes to .nii.gz, creates white matter and corpus callosum masks, performs alignment to MNI space, and creates a 278 cortical labeled volume from Shen et al. 2013.","stats":{"stars":0,"requested":103,"users":9,"success_rate":87.62886597938144,"serviceinfo":{"_id":"5d729e1f78356a109788b2ed","counts":{"_id":"5e5c688487cac7272dab1bab","failed":12,"finished":85,"removed":84,"requested":103,"running":93,"running_sync":0,"stop_requested":3},"success_rate":87.62886597938144,"users":9,"readme_status":"too short","runtime_mean":2482078.117647059,"runtime_std":2443181.872810307,"service":"brain-life/app-freesurfer-post","__v":0},"gitinfo":{"desc":"The converts labeled volumes to .nii.gz, creates white matter and corpus callosum masks, performs alignment to MNI space, and creates a 278 cortical labeled volume from Shen et al. 2013.","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brent McPherson","email":null}]},"runtime_mean":2482078.117647059,"runtime_std":2443181.872810307,"resources":[],"examples":0},"create_date":"2017-09-15T16:33:14.335Z","doi":"10.25663/brainlife.app.106"},{"name":"White Matter Anatomy Segmentation with LiFE","github":"brainlife/app-wmaSeg","desc":"Classifies streamlines into known anatomical tracts.","stats":{"stars":1,"requested":39843,"users":59,"success_rate":67.8864679640525,"serviceinfo":{"_id":"5d729e1e78356a109788b20d","counts":{"_id":"5e5c688587cac71050ab1bac","failed":3425,"finished":9221,"removed":16901,"requested":18537,"running":12116,"running_sync":0,"stop_requested":445},"success_rate":72.91633718171754,"users":20,"readme_status":"ok","runtime_mean":14985593.77,"runtime_std":3690815.7786162673,"service":"brainlife/app-wmaSeg","__v":0},"gitinfo":{"desc":"Classifies streamlines into known anatomical tracts.","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lindsey Kitchell","email":null},{"name":"Daniel Bullock","email":null},{"name":"Franco Pestilli","email":null},{"name":"Steven O'Riley","email":null}]},"runtime_mean":8505411.39,"runtime_std":5350958.412636696,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf2d0de14be11ff25b765"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf2d0de14be11ff25b766"}],"examples":0,"groups":131},"create_date":"2017-09-18T16:24:34.704Z","doi":"10.25663/bl.app.40"},{"name":"Test App","github":"soichih/app-test","desc":"updated 3","stats":{"stars":0,"requested":111,"users":2,"success_rate":74.73684210526315,"serviceinfo":{"_id":"5d729e1f78356a109788b2cb","counts":{"_id":"5e5c688687cac7c561ab1bad","failed":24,"finished":65,"removed":65,"requested":103,"running":90,"running_sync":0,"stop_requested":6},"success_rate":73.03370786516854,"users":2,"readme_status":"too short","runtime_mean":312920.3076923077,"runtime_std":1463192.524602218,"service":"soichih/app-test","__v":0},"gitinfo":{"desc":"updated 3","tags":["test"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":295940.676056338,"runtime_std":1401348.9991926115,"resources":[],"examples":0,"groups":7},"create_date":"2017-09-22T03:00:44.283Z","doi":"10.25663/bl.app.45"},{"name":"Tract Analysis Profiles","github":"brainlife/app-tractanalysisprofiles","desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","stats":{"stars":1,"requested":19317,"users":42,"success_rate":77.25239616613419,"serviceinfo":{"_id":"5d729e1f78356a109788b2e3","counts":{"_id":"5e5c688787cac70f33ab1bae","failed":3076,"finished":18694,"removed":24434,"requested":28274,"running":21318,"running_sync":0,"stop_requested":275},"success_rate":85.8704639412035,"users":28,"readme_status":"ok","runtime_mean":387280.16,"runtime_std":1523501.9629271352,"service":"brain-life/app-tractanalysisprofiles","__v":0},"gitinfo":{"desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":2138024.52,"runtime_std":9002049.390707558,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf2dbde14be11ff25b791"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf2dbde14be11ff25b792"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf2dbde14be11ff25b793"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf2dbde14be11ff25b794"}],"examples":1,"groups":90},"create_date":"2017-09-26T13:54:11.760Z","doi":"10.25663/bl.app.43"},{"name":"Enhanced Ensemble Tractography","github":"brainlife/app-enhanced-ensemble-tracking","desc":"Performs ensemble tractography with MRTrix 0.2.12 with user specified values for lmax and curvatures across probabilistic, deterministic, and tensor methods. Additionally, it seeds and tracts extra streamlines through the corpus callosum.","stats":{"stars":0,"requested":112,"users":8,"success_rate":52,"serviceinfo":{"_id":"5d729e1f78356a109788b2d1","counts":{"_id":"5e5c688887cac71c69ab1baf","failed":48,"finished":52,"removed":52,"requested":112,"running":73,"running_sync":0,"stop_requested":16},"success_rate":52,"users":8,"readme_status":"too short","runtime_mean":3464330.5384615385,"runtime_std":10193242.592525076,"service":"brain-life/app-enhanced-ensemble-tracking","__v":0},"gitinfo":{"desc":"Performs ensemble tractography with MRTrix 0.2.12 with user specified values for lmax and curvatures across probabilistic, deterministic, and tensor methods. Additionally, it seeds and tracts extra streamlines through the corpus callosum.","tags":["tracking"],"stats":{"stars":0},"contributors":[{"name":"Brent McPherson","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":3464330.5384615385,"runtime_std":10193242.592525076,"resources":[],"examples":0},"create_date":"2017-10-03T20:43:31.073Z","doi":"10.25663/bl.app.51"},{"name":"AFQ Tract Classification","github":"brainlife/app-tractclassification","desc":"This service uses Automated fiber quantification AFQ and fe structure output from LiFE to identify major tract segments and quantify tissue properties along their trajectories. You can choose to have the zero weighted fibers (as determined by LiFE) removed before or after AFQ is applied. useinterhemisphericsplit is a variable from AFQ, which if set to true will cut fibers crossing between hemispheres with a midsaggital plane below z=-10. This is to get rid of CST fibers that appear to cross at the level of the brainstem. For more information about AFQ see https://github.com/yeatmanlab/AFQ/wiki","stats":{"stars":0,"requested":3423,"users":33,"success_rate":49.98354721948009,"serviceinfo":{"_id":"5d729e1e78356a109788b21b","counts":{"_id":"5e5c688987cac740d4ab1bb0","failed":352,"finished":255,"removed":787,"requested":809,"running":280,"running_sync":0,"stop_requested":22},"success_rate":42.00988467874794,"users":21,"readme_status":"too short","runtime_mean":4841074.02,"runtime_std":6487919.963962646,"service":"brainlife/app-tractclassification","__v":0},"gitinfo":{"desc":"This service uses Automated fiber quantification AFQ and fe structure output from LiFE to identify major tract segments and quantify tissue properties along their trajectories. You can choose to have the zero weighted fibers (as determined by LiFE) removed before or after AFQ is applied. useinterhemisphericsplit is a variable from AFQ, which if set to true will cut fibers crossing between hemispheres with a midsaggital plane below z=-10. This is to get rid of CST fibers that appear to cross at the level of the brainstem. For more information about AFQ see https://github.com/yeatmanlab/AFQ/wiki","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Steven O'Riley","email":null}]},"runtime_mean":506468.95,"runtime_std":549388.260618688,"resources":[],"examples":0,"groups":27},"create_date":"2017-10-12T23:22:29.220Z","doi":"10.25663/bl.app.13"},{"name":"Steklov Operator Spectrum","github":"kitchell/app-steklovspectrum","desc":"app to calculate the Steklov Operator Spectrum on 3D surfaces","stats":{"stars":0,"requested":20,"users":2,"success_rate":11.11111111111111,"serviceinfo":{"_id":"5d729e1f78356a109788b2c3","counts":{"_id":"5e5c688a87cac7b46cab1bb1","failed":16,"finished":2,"removed":14,"requested":20,"running":19,"running_sync":0,"stop_requested":1},"success_rate":11.11111111111111,"users":2,"readme_status":"too short","runtime_mean":7924069,"runtime_std":6676424,"service":"kitchell/app-steklovspectrum","__v":0},"gitinfo":{"desc":"app to calculate the Steklov Operator Spectrum on 3D surfaces","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":7924069,"runtime_std":6676424,"resources":[],"examples":0,"groups":1},"create_date":"2017-10-20T13:24:12.703Z","doi":"10.25663/brainlife.app.147"},{"name":"Fit NODDI model using AMICO (dtiinit) -  DEPRECATED","github":"brainlife/app-noddi-amico","desc":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs) and an optional brainmask of the DWI. Will output the four NODDI output files: neurite density index (ndi), orientation dispersion index (odi), isotropic volume fraction (isovf), and the directions (dirs).","stats":{"stars":1,"requested":17952,"users":31,"success_rate":80.29782359679267,"serviceinfo":{"_id":"5d729e1f78356a109788b2ff","counts":{"_id":"5e5c688a87cac7ea85ab1bb2","failed":1432,"finished":3375,"removed":7983,"requested":8628,"running":4929,"running_sync":0,"stop_requested":178},"success_rate":70.21011025587684,"users":12,"readme_status":"ok","runtime_mean":7179274.96,"runtime_std":6595445.539946354,"service":"brain-life/app-noddi-amico","__v":0},"gitinfo":{"desc":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs), and the single shell dwi file that has been aligned to the subject's T1 (i.e. dtiinit output) as input. The app will align the multi-shell data to the single-shell data (if dtiinit was used for tracking; otherwise single shell data is not necessary) in order to assure that NODDI outputs are in the same space as the tensor outputs for later analyses. Will output the five NODDI output files: FIT_ICVF_NEW, FIT_OD_NEW, FIT_ISOVF_NEW, FIT_dir, and config.pickle.","tags":["postprocessing"],"stats":{"stars":1},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":5453700.08,"runtime_std":14494456.081946442,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf2f0de14be11ff25b7a5"}],"examples":0,"groups":61},"create_date":"2017-11-01T17:33:30.599Z","doi":"10.25663/bl.app.35"},{"name":"Decimate and/or Convert 3D surfaces","github":"kitchell/app-decimatemesh","desc":"This application will reduce the number of vertices and faces on 3D surfaces by the percent reduction chosen. It can also be used to convert between filetypes.","stats":{"stars":0,"requested":3566,"users":3,"success_rate":95.58907228229937,"serviceinfo":{"_id":"5d729e1f78356a109788b2bd","counts":{"_id":"5e5c688b87cac77bf7ab1bb3","failed":154,"finished":3355,"removed":3381,"requested":3559,"running":3504,"running_sync":0,"stop_requested":7},"success_rate":95.61128526645768,"users":2,"readme_status":"ok","runtime_mean":163652.24,"runtime_std":265994.92539693776,"service":"kitchell/app-decimatemesh","__v":0},"gitinfo":{"desc":"This application will reduce the number of vertices and faces on 3D surfaces by the percent reduction chosen.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":180971.35,"runtime_std":291314.2735854312,"resources":[],"examples":1,"groups":3},"create_date":"2017-11-01T22:51:24.123Z","doi":"10.25663/brainlife.app.148"},{"name":"Register DWI to T1 using Vistasoft","github":"brainlife/app-vistasoft-registration","desc":"This app will register a DWI image to a T1w image and rotate the bvecs. Requires a DWI image (with bvals and bvecs) and an T1w image (either ACPC-aligned or native). Will output an aligned DWI image, the rotated bvecs, and the bvals files.","stats":{"stars":0,"requested":2773,"users":7,"success_rate":99.70845481049562,"serviceinfo":{"_id":"5d729e1f78356a109788b2ab","counts":{"_id":"5e5c688c87cac76891ab1bb4","failed":19,"finished":118,"removed":169,"requested":199,"running":184,"running_sync":0,"stop_requested":48},"success_rate":86.13138686131386,"users":14,"readme_status":"ok","runtime_mean":3734990.38,"runtime_std":6250171.746329549,"service":"brain-life/app-vistasoft-registration","__v":0},"gitinfo":{"desc":"This app will register a DWI image to a T1w image and rotate the bvecs. Requires a DWI image (with bvals and bvecs) and an T1w image (either ACPC-aligned or native). Will output an aligned DWI image, the rotated bvecs, and the bvals files.","tags":["diffusion-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":7906479.77,"runtime_std":23226601.48848959,"resources":[],"examples":1,"groups":8},"create_date":"2017-11-02T14:43:33.703Z","doi":"10.25663/bl.app.50"},{"name":"CONN preprocessing","github":"soichih/app-conn-preprocessing","desc":"fMRI preprocessing via CONN","stats":{"stars":1,"requested":266,"users":22,"success_rate":92.99065420560748,"serviceinfo":{"_id":"5d729e1f78356a109788b37b","counts":{"_id":"5e5c688d87cac7b0e1ab1bb5","failed":7,"finished":155,"removed":205,"requested":213,"running":177,"running_sync":0,"stop_requested":22},"success_rate":95.67901234567901,"users":11,"readme_status":"ok","runtime_mean":5263175.37,"runtime_std":12958374.504101079,"service":"soichih/app-conn-preprocessing","__v":0},"gitinfo":{"desc":"fMRI preprocessing via CONN","tags":["fmri-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lorenzo Pasquini","email":null}]},"runtime_mean":5518665.9,"runtime_std":15554406.820722286,"resources":[],"examples":1,"groups":16},"create_date":"2017-11-08T01:44:57.046Z","doi":"10.25663/bl.app.54"},{"name":"ACPC alignment via ART","github":"brainlife/app-acpcART","desc":"This app uses the Automatic Registration Toolbox (ART) to perform ACPC alignment of the T1 image. See https://www.nitrc.org/projects/art/ for more information.","stats":{"stars":0,"requested":23037,"users":62,"success_rate":71.78610915669917,"serviceinfo":{"_id":"5d729e1e78356a109788b231","counts":{"_id":"5e5c688e87cac7fdc3ab1bb6","failed":577,"finished":3221,"removed":5480,"requested":5782,"running":3839,"running_sync":0,"stop_requested":69},"success_rate":84.8077935755661,"users":21,"readme_status":"too short","runtime_mean":319906.39,"runtime_std":778869.994165148,"service":"brainlife/app-acpcART","__v":0},"gitinfo":{"desc":"This app uses the Automatic Registration Toolbox (ART) to perform ACPC alignment of the T1 image. See https://www.nitrc.org/projects/art/ for more information.","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":77784.98,"runtime_std":253976.86130381952,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf306de14be11ff25b8a2"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf306de14be11ff25b8a3"}],"examples":2,"groups":58},"create_date":"2017-11-16T20:03:58.889Z","doi":"10.25663/bl.app.16"},{"name":"Bias Field Correction (anat/t1w)","github":"kitchell/app-biasfieldcorrection","desc":"This application will correct for bias field issues in T1 images using ANTs N4BiasFieldCorrection algorithm","stats":{"stars":0,"requested":312,"users":20,"success_rate":86.02150537634408,"serviceinfo":{"_id":"5d729e1f78356a109788b33b","counts":{"_id":"5e5c688f87cac7c436ab1bb7","failed":11,"finished":80,"removed":85,"requested":101,"running":91,"running_sync":0,"stop_requested":1},"success_rate":87.91208791208791,"users":10,"readme_status":"ok","runtime_mean":184480.8625,"runtime_std":331632.5116014617,"service":"kitchell/app-biasfieldcorrection","__v":0},"gitinfo":{"desc":"This application will correct for bias field issues in T1 images using ANTs N4BiasFieldCorrection algorithm","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":184480.8625,"runtime_std":331632.5116014617,"resources":[],"examples":0,"groups":15},"create_date":"2017-11-17T18:43:06.250Z","doi":"10.25663/bl.app.14"},{"name":"Crop and Reorient T1","github":"brainlife/app-crop_reorient","desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","stats":{"stars":0,"requested":11099,"users":106,"success_rate":94.52861952861953,"serviceinfo":{"_id":"5d729e1e78356a109788b1d9","counts":{"_id":"5e5c688f87cac72589ab1bb8","failed":41,"finished":876,"removed":739,"requested":991,"running":923,"running_sync":0,"stop_requested":35},"success_rate":95.5288985823337,"users":21,"readme_status":"ok","runtime_mean":53647.3,"runtime_std":18009.497550181684,"service":"brainlife/app-crop_reorient","__v":0},"gitinfo":{"desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","tags":[],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":464343.13,"runtime_std":3265360.1856333264,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf311de14be11ff25b8d8"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf311de14be11ff25b8d9"}],"examples":1,"groups":163},"create_date":"2017-11-17T19:30:07.422Z","doi":"10.25663/bl.app.15"},{"name":"Denoising using Non Local Means (NLM)","github":"dipy/bl_apps_dipy_denoise_nlmeans","desc":"Brainlife wrapper app for dipy_denoise_nlmeans workflows.","stats":{"stars":0,"requested":287,"users":9,"success_rate":93.10344827586206,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c689187cac7fc01ab1bba","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":6479038.33,"runtime_std":2136157.1298478493,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf316de14be11ff25b909"}],"examples":0,"groups":8},"create_date":"2017-12-05T22:36:49.530Z","doi":"10.25663/bl.app.72"},{"name":"White Matter Mask","github":"kitchell/app-wmMask","desc":"This application will create a mask nifti file of the white matter of the T1 image using Freesurfer's aparc+aseg.mgz parcellation.","stats":{"stars":0,"requested":53,"users":19,"success_rate":50,"serviceinfo":{"_id":"5d729e1f78356a109788b249","counts":{"_id":"5e5c689287cac72a6dab1bbb","failed":5,"finished":22,"removed":27,"requested":34,"running":29,"running_sync":0,"stop_requested":0},"success_rate":81.48148148148148,"users":12,"readme_status":"ok","runtime_mean":14711235.727272727,"runtime_std":41494800.62649944,"service":"kitchell/app-wmMask","__v":0},"gitinfo":{"desc":"This application will create a mask nifti file of the white matter of the T1 image using Freesurfer's aparc+aseg.mgz parcellation.","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":14711235.727272727,"runtime_std":41494800.62649944,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf31cde14be11ff25b90d"}],"examples":0,"groups":11},"create_date":"2017-12-06T16:17:18.331Z","doi":"10.25663/bl.app.10"},{"name":"Check T1 Orientation","github":"brainlife/app-checkOrientation","desc":"This application checks and reports the orientation (neurological or radiological) of a nifti file.","stats":{"stars":0,"requested":1903,"users":10,"success_rate":82.43654822335026,"serviceinfo":{"_id":"5d729e1f78356a109788b2fb","counts":{"_id":"5e5c689387cac72649ab1bbc","failed":10,"finished":238,"removed":252,"requested":296,"running":249,"running_sync":0,"stop_requested":8},"success_rate":95.96774193548387,"users":24,"readme_status":"too short","runtime_mean":1629653.97,"runtime_std":6945459.606330997,"service":"brain-life/app-checkOrientation","__v":0},"gitinfo":{"desc":"This application checks and reports the orientation (neurological or radiological) of a nifti file.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":1349611.11,"runtime_std":7813534.724803086,"resources":[],"examples":0,"groups":15},"create_date":"2018-01-04T19:53:06.862Z","doi":"10.25663/bl.app.19"},{"name":"Check DWI Orientation","github":"brainlife/app-checkOrientation","desc":"This application checks and reports the orientation (neurological or radiological) of a nifti file.","stats":{"stars":0,"requested":1903,"users":10,"success_rate":82.43654822335026,"serviceinfo":{"_id":"5d729e1f78356a109788b2fb","counts":{"_id":"5e5c689487cac78ea9ab1bbd","failed":10,"finished":238,"removed":252,"requested":296,"running":249,"running_sync":0,"stop_requested":8},"success_rate":95.96774193548387,"users":24,"readme_status":"too short","runtime_mean":1629653.97,"runtime_std":6945459.606330997,"service":"brain-life/app-checkOrientation","__v":0},"gitinfo":{"desc":"This application checks and reports the orientation (neurological or radiological) of a nifti file.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":1349611.11,"runtime_std":7813534.724803086,"resources":[],"examples":0,"groups":15},"create_date":"2018-01-05T17:20:17.711Z","doi":"10.25663/bl.app.20"},{"name":"Check dtiInit Orientation","github":"brainlife/app-checkOrientation","desc":"This application checks and reports the orientation (neurological or radiological) of a nifti file.","stats":{"stars":0,"requested":1903,"users":10,"success_rate":82.43654822335026,"serviceinfo":{"_id":"5d729e1f78356a109788b2fb","counts":{"_id":"5e5c689487cac7088aab1bbe","failed":10,"finished":238,"removed":252,"requested":296,"running":249,"running_sync":0,"stop_requested":8},"success_rate":95.96774193548387,"users":24,"readme_status":"too short","runtime_mean":1629653.97,"runtime_std":6945459.606330997,"service":"brain-life/app-checkOrientation","__v":0},"gitinfo":{"desc":"This application checks and reports the orientation (neurological or radiological) of a nifti file.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":1349611.11,"runtime_std":7813534.724803086,"resources":[],"examples":0,"groups":15},"create_date":"2018-01-06T16:32:23.037Z","doi":"10.25663/bl.app.21"},{"name":"Segmentation with Median Otsu ","github":"dipy/bl_apps_dipy_median_otsu","desc":"Brainlife wrapper app for dipy_median_otsu workflows.","stats":{"stars":0,"requested":1175,"users":9,"success_rate":95.0965824665676,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c689587cac74675ab1bbf","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":56332.21,"runtime_std":153399.40732286384,"resources":[],"examples":2,"groups":28},"create_date":"2018-01-06T17:00:51.493Z","doi":"10.25663/bl.app.70"},{"name":"Laplace Beltrami Spectrum: Eigenvalues Only","github":"kitchell/app-LBspectrum_matlab","desc":"Application to calculate the Laplace Beltrami Spectrum and Eigenvectors using Matlab. ","stats":{"stars":1,"requested":17838,"users":6,"success_rate":85.35415909916455,"serviceinfo":{"_id":"5d729e1f78356a109788b36d","counts":{"_id":"5e5c689787cac75002ab1bc1","failed":2016,"finished":11747,"removed":16362,"requested":17836,"running":13648,"running_sync":0,"stop_requested":96},"success_rate":85.35203080723679,"users":4,"readme_status":"ok","runtime_mean":44779865.46,"runtime_std":43296674.825561434,"service":"kitchell/app-LBspectrum_matlab","__v":0},"gitinfo":{"desc":"Application to calculate the Laplace Beltrami Spectrum and Eigenvectors using Matlab. ","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":45068167.87,"runtime_std":43193467.33399912,"resources":[],"examples":1,"groups":5},"create_date":"2018-01-08T18:04:46.964Z","doi":"10.25663/bl.app.97"},{"name":"Plot Eigenfunctions","github":"kitchell/app-plotEigenfunctions","desc":"App to plot the eigenfunctions of the Laplace Beltrami Spectrum.","stats":{"stars":0,"requested":56,"users":1,"success_rate":88.88888888888889,"serviceinfo":{"_id":"5d729e1f78356a109788b371","counts":{"_id":"5e5c689887cac76981ab1bc2","failed":4,"finished":32,"removed":37,"requested":56,"running":38,"running_sync":0,"stop_requested":1},"success_rate":88.88888888888889,"users":1,"readme_status":"ok","runtime_mean":3131357.65625,"runtime_std":2685650.2090408164,"service":"kitchell/app-plotEigenfunctions","__v":0},"gitinfo":{"desc":"App to plot the eigenfunctions of the Laplace Beltrami Spectrum.","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":3131357.65625,"runtime_std":2685650.2090408164,"resources":[],"examples":0,"groups":1},"create_date":"2018-01-09T16:41:28.013Z","doi":"10.25663/bl.app.55"},{"name":"FSL Brain Extraction (BET) on T1","github":"brainlife/app-FSLBET","desc":"Brain Extraction via FSL's BET command","stats":{"stars":0,"requested":42857,"users":73,"success_rate":62.43668720054757,"serviceinfo":{"_id":"5d729e1f78356a109788b34b","counts":{"_id":"5e5c689987cac72c70ab1bc3","failed":53,"finished":1853,"removed":1955,"requested":2015,"running":1928,"running_sync":0,"stop_requested":40},"success_rate":97.2193074501574,"users":33,"readme_status":"too short","runtime_mean":964048.19,"runtime_std":2048880.6264796087,"service":"brain-life/app-FSLBET","__v":0},"gitinfo":{"desc":"Brain Extraction via FSL's BET command","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":29685.56,"runtime_std":9501.90325073877,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf342de14be11ff25bb68"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf342de14be11ff25bb69"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf342de14be11ff25bb6a"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf342de14be11ff25bb6b"}],"examples":4,"groups":115},"create_date":"2018-01-09T17:25:09.329Z","doi":"10.25663/bl.app.2"},{"name":"Convert tck+dwi to trk (MRtrix 2)","github":"brainlife/app-converttck2trk","desc":"Convert MRtrix TCK to TrackVis TRK files.","stats":{"stars":0,"requested":1706,"users":11,"success_rate":77.31958762886599,"serviceinfo":{"_id":"5d729e1f78356a109788b271","counts":{"_id":"5e5c689a87cac712e3ab1bc4","failed":374,"finished":1270,"removed":1486,"requested":1665,"running":1629,"running_sync":0,"stop_requested":9},"success_rate":77.25060827250608,"users":6,"readme_status":"ok","runtime_mean":477573.73,"runtime_std":529016.4441536738,"service":"brainlife/app-converttck2trk","__v":0},"gitinfo":{"desc":"Convert MRtrix TCK to TrackVis TRK files.","tags":[],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":463332.89,"runtime_std":530255.8169405009,"resources":[],"examples":0,"groups":8},"create_date":"2018-01-15T14:57:16.410Z","doi":"10.25663/bl.app.22"},{"name":"Dorsal Attention Network (archived)","github":"brain-life/app-DorsalAttentionNetwork","desc":"Index specific connections for a project","stats":{"stars":0,"requested":10,"users":2,"success_rate":0,"serviceinfo":{"_id":"5d729e1f78356a109788b355","counts":{"_id":"5e5c689b87cac738b2ab1bc5","failed":6,"finished":0,"removed":3,"requested":10,"running":3,"running_sync":0,"stop_requested":0},"success_rate":0,"users":2,"readme_status":"too short","service":"brain-life/app-DorsalAttentionNetwork","__v":0},"gitinfo":{"desc":"Index specific connections for a project","tags":[],"stats":{"stars":0},"contributors":[{"name":"Brent McPherson","email":null}]},"resources":[],"examples":0,"groups":1},"create_date":"2018-01-17T16:51:07.008Z","doi":"10.25663/brainlife.app.107"},{"name":"Laplace Beltrami Spectrum: Eigenvalues and Eigenvectors","github":"kitchell/app-LBspectrum_matlab","desc":"Application to calculate the Laplace Beltrami Spectrum and Eigenvectors using Matlab. ","stats":{"stars":1,"requested":17838,"users":6,"success_rate":85.35415909916455,"serviceinfo":{"_id":"5d729e1f78356a109788b36d","counts":{"_id":"5e5c689b87cac73326ab1bc6","failed":2016,"finished":11747,"removed":16362,"requested":17836,"running":13648,"running_sync":0,"stop_requested":96},"success_rate":85.35203080723679,"users":4,"readme_status":"ok","runtime_mean":44779865.46,"runtime_std":43296674.825561434,"service":"kitchell/app-LBspectrum_matlab","__v":0},"gitinfo":{"desc":"Application to calculate the Laplace Beltrami Spectrum and Eigenvectors using Matlab. ","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":45068167.87,"runtime_std":43193467.33399912,"resources":[],"examples":0,"groups":5},"create_date":"2018-01-21T17:56:12.460Z","doi":"10.25663/bl.app.96"},{"name":"old ensemble tracking","github":"brainlife/app-ensembletracking","desc":"This App creates a large set of candidate streamlines using an ensemble of algorithms and parameter values. All outputs will be then combined into a single track.tck output.","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1f78356a109788b2cf","counts":{"_id":"5e5c689c87cac74df3ab1bc7","failed":3487,"finished":8002,"removed":13974,"requested":22463,"running":16311,"running_sync":0,"stop_requested":341},"success_rate":69.64922969797198,"users":61,"readme_status":"ok","runtime_mean":6502764.34,"runtime_std":3757949.399415393,"service":"brain-life/app-ensembletracking","__v":0},"gitinfo":{"desc":"This service uses MRtrix 0.2.12 to do ensemble tracking using tensor and constrained spherical deconvolution (csd) algorithms. It generates a large set of candidate streamlines using a tensor-based deterministic model, csd-based deterministic model, and csd-based probabilistic model. The csd-based models can be computed at lmax values of 2, 4, 6, 8, 10, and 12. All candidate streamlines are combined into a single track.mat file. If you know the max lmax value for your data input the value for max_lmax, otherwise leave it blank and it will be calculated for you. If you wish to use just deterministic tracking (MRtrix streamtrack parameter SD_STREAM) check do_deterministic. If you wish to use just probabilistic tracking (MRtrix streamtrack parameter SD_PROB) check do_probabilistic If you wish to use the tensor tracking (MRtrix streamtrack parameter DT_STREAM) check do_tensor. By default it will use all three tracking methods. For more information about Ensemble Tractography see Takemura, H., Caiafa, C. F., Wandell, B. A., & Pestilli, F. (2016). Ensemble tractography. PLoS computational biology, 12(2), e1004692.","tags":["brain-connectome","diffusion-mri","mri","tracking","tractography","white-matter"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Brent McPherson","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":34.54641350210971,"users":13,"runtime_mean":1206734.29,"runtime_std":2026412.4706887305,"requested":2015,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf357de14be11ff25bba9"}],"examples":0,"groups":13},"create_date":"2018-01-30T19:50:25.981Z","doi":"10.25663/brainlife.app.149"},{"name":"dt6 To Nifti Converter","github":"brainlife/app-dt6tonifti","desc":"Will take a dt6 and create tensor (FA,MD,AD,RD) and Westin Shape Indices (cl, cp, cs) nifti images from a dt6.mat structure.","stats":{"stars":0,"requested":239,"users":4,"success_rate":96.20253164556962,"serviceinfo":{"_id":"5d729e1f78356a109788b323","counts":{"_id":"5e5c689d87cac7836eab1bc8","failed":108,"finished":4527,"removed":4571,"requested":4905,"running":4635,"running_sync":0,"stop_requested":16},"success_rate":97.66990291262137,"users":18,"readme_status":"ok","runtime_mean":1152835.42,"runtime_std":4937531.064418811,"service":"brain-life/app-dt6tonifti","__v":0},"gitinfo":{"desc":"Will take a dt6 and create tensor (FA,MD,AD,RD) and Westin Shape Indices (cl, cp, cs) nifti images from a dt6.mat structure.","tags":["convert"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":35569.06,"runtime_std":11117.940301890454,"resources":[],"examples":2,"groups":8},"create_date":"2018-02-04T19:50:36.637Z","doi":"10.25663/bl.app.48"},{"name":"mrtrix3 preprocess","github":"brainlife/app-mrtrix3-preproc","desc":"Run the recommended preprocessing procedure provided by mrtrix3. The options available mostly reflect the optimal DESIGNER pipeline that was recently proposed. This App runs for >15 on topup if both PA and AP dwi files are provided. It detects bvecs flipping (dwigradcheck) and update the gradient table accordingly.","stats":{"stars":0,"requested":53522,"users":85,"success_rate":68.44728292971057,"serviceinfo":{"_id":"5d729e1f78356a109788b367","counts":{"_id":"5e5c689e87cac7908eab1bc9","failed":2233,"finished":8226,"removed":10647,"requested":11756,"running":10569,"running_sync":0,"stop_requested":289},"success_rate":78.6499665359977,"users":24,"readme_status":"too short","runtime_mean":4331679.21,"runtime_std":7086272.954949098,"service":"brain-life/app-mrtrix3-preproc","__v":0},"gitinfo":{"desc":"Run the recommended preprocessing procedure provided by mrtrix3. The options available mostly reflect the optimal DESIGNER pipeline that was recently proposed. This App runs for >15 on topup if both PA and AP dwi files are provided.","tags":["diffusion-mri","mri","tractography"],"stats":{"stars":0},"contributors":[{"name":"Brent McPherson","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":5724997.08,"runtime_std":9406299.788806936,"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"642cf364de14be11ff25bfea"},{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf364de14be11ff25bfeb"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf364de14be11ff25bfec"}],"examples":5,"groups":221},"create_date":"2018-02-12T07:12:18.285Z","doi":"10.25663/bl.app.68"},{"name":"Mouse Segmentation Pipeline","github":"kathrynalpert/app-mouse_seg","desc":"Pipeline for mouse brain skull-stripping and ROI segmentation","stats":{"stars":0,"requested":23,"users":5,"success_rate":38.88888888888889,"serviceinfo":{"_id":"5d729e1f78356a109788b37d","counts":{"_id":"5e5c68a187cac77635ab1bcc","failed":3,"finished":7,"removed":7,"requested":14,"running":8,"running_sync":0,"stop_requested":0},"success_rate":70,"users":4,"readme_status":"too short","runtime_mean":3102458.4285714286,"runtime_std":1554118.2280425916,"service":"kathrynalpert/app-mouse_seg","__v":0},"gitinfo":{"desc":"Pipeline for mouse brain skull-stripping and ROI segmentation","tags":["pipeline"],"stats":{"stars":0},"contributors":[{"name":null,"email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":3102458.4285714286,"runtime_std":1554118.2280425916,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf369de14be11ff25bff3"}],"examples":0,"groups":3},"create_date":"2018-03-08T00:58:17.769Z","doi":"10.25663/bl.app.75"},{"name":"Freesurfer Labels to 3D Surfaces","github":"kitchell/app-3Dfreesurfs","desc":"This application will create a 3D surface for 87 freesurfer labels from the aparc+aseg.mgz file. ","stats":{"stars":0,"requested":1948,"users":21,"success_rate":84.76896748431261,"serviceinfo":{"_id":"5d729e1f78356a109788b383","counts":{"_id":"5e5c68a187cac70fe5ab1bcd","failed":253,"finished":1480,"removed":1721,"requested":1807,"running":1519,"running_sync":0,"stop_requested":2},"success_rate":85.40103866128102,"users":14,"readme_status":"ok","runtime_mean":23835989.59,"runtime_std":25927493.88505046,"service":"kitchell/app-3Dfreesurfs","__v":0},"gitinfo":{"desc":"This application will create a 3D surface for 87 freesurfer labels from the aparc+aseg.mgz file. ","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Steven O'Riley","email":null}]},"runtime_mean":20676283.97,"runtime_std":25373756.702320904,"resources":[],"examples":0,"groups":15},"create_date":"2018-03-13T19:30:02.173Z","doi":"10.25663/bl.app.98"},{"name":"HCP Pipeline (PreFreeSurfer)","github":"brainlife/app-hcp-prefreesurfer","desc":"BIDS app for HCP pre-FreeSurfer for BrainLife. Performs ACPC alignment, FNIRT-based brain extraction, and bias field correction. (Please see https://github.com/Washington-University/HCPpipelines/wiki/v3.4.0-Release-Notes,-Installation,-and-Usage#structural-preprocessing for more information on HCP structural pipelines.)","stats":{"stars":0,"requested":45,"users":5,"success_rate":0,"serviceinfo":{"_id":"5d729e1f78356a109788b345","counts":{"_id":"5e5c68a387cac70d92ab1bce","failed":16,"finished":21,"removed":33,"requested":47,"running":31,"running_sync":0,"stop_requested":0},"success_rate":56.75675675675676,"users":7,"readme_status":"no README.md","runtime_mean":2623391.1428571427,"runtime_std":1104606.8054193282,"service":"kathrynalpert/app-hcp-prefreesurfer","__v":0},"gitinfo":{"desc":"BIDS app for HCP pre-FreeSurfer for BrainLife. Performs ACPC alignment, FNIRT-based brain extraction, and bias field correction. (Please see https://github.com/Washington-University/HCPpipelines/wiki/v3.4.0-Release-Notes,-Installation,-and-Usage#structural-preprocessing for more information on HCP structural pipelines.)","tags":["pipeline"],"stats":{"stars":0},"contributors":[{"name":null,"email":null}]},"resources":[],"examples":0,"groups":5},"create_date":"2018-03-15T21:37:33.295Z","doi":"10.25663/bl.app.78"},{"name":"HCP Pipeline (FreeSurfer)","github":"brainlife/app-hcp-freesurfer","desc":"BIDS app for HCP FreeSurfer for BrainLife. Requires T1w_acpc_dc_restore.nii.gz, T1w_acpc_dc_restore_brain.nii.gz, and T2w_acpc_dc_restore.nii.gz from PreFS pipeline. (Please see https://github.com/Washington-University/HCPpipelines/wiki/v3.4.0-Release-Notes,-Installation,-and-Usage#structural-preprocessing for more information on HCP structural pipelines.)","stats":{"stars":0,"requested":2,"users":2,"success_rate":0,"serviceinfo":{"_id":"5d729e1f78356a109788b357","counts":{"_id":"5e5c68a487cac75565ab1bcf","failed":11,"finished":14,"removed":22,"requested":31,"running":24,"running_sync":0,"stop_requested":1},"success_rate":56.00000000000001,"users":5,"readme_status":"no README.md","runtime_mean":33284964.57142857,"runtime_std":9051124.883766728,"service":"kathrynalpert/app-hcp-freesurfer","__v":0},"gitinfo":{"desc":"BIDS app for HCP FreeSurfer for BrainLife. Requires T1w_acpc_dc_restore.nii.gz, T1w_acpc_dc_restore_brain.nii.gz, and T2w_acpc_dc_restore.nii.gz from PreFS pipeline. (Please see https://github.com/Washington-University/HCPpipelines/wiki/v3.4.0-Release-Notes,-Installation,-and-Usage#structural-preprocessing for more information on HCP structural pipelines.)","tags":["pipeline"],"stats":{"stars":0},"contributors":[{"name":null,"email":null}]},"resources":[],"examples":0,"groups":2},"create_date":"2018-03-16T14:05:04.737Z","doi":"10.25663/bl.app.79"},{"name":"HCP Pipeline (PostFreeSurfer)","github":"soichih/app-hcp-postfreesurfer","desc":"BIDS app for HCP post-FreeSurfer for BrainLife. Outputs include surface topologies and features resampled onto the high (164k) dimensional atlas space as well as myelin mappings. (Please see https://github.com/Washington-University/HCPpipelines/wiki/v3.4.0-Release-Notes,-Installation,-and-Usage#structural-preprocessing for more information on HCP structural pipelines.)","stats":{"stars":0,"requested":4,"users":2,"success_rate":25,"serviceinfo":{"_id":"5d729e1f78356a109788b381","counts":{"_id":"5e5c68a487cac7485cab1bd0","failed":16,"finished":18,"removed":31,"requested":49,"running":32,"running_sync":0,"stop_requested":0},"success_rate":52.94117647058824,"users":5,"readme_status":"no README.md","runtime_mean":2233282,"runtime_std":5226413.059791804,"service":"kathrynalpert/app-hcp-postfreesurfer","__v":0},"gitinfo":{"desc":"BIDS app for HCP post-FreeSurfer for BrainLife. Outputs include surface topologies and features resampled onto the high (164k) dimensional atlas space as well as myelin mappings. (Please see https://github.com/Washington-University/HCPpipelines/wiki/v3.4.0-Release-Notes,-Installation,-and-Usage#structural-preprocessing for more information on HCP structural pipelines.)","tags":["pipeline"],"stats":{"stars":0},"contributors":[{"name":null,"email":null}]},"runtime_mean":1402873,"runtime_std":0,"resources":[],"examples":0,"groups":3},"create_date":"2018-03-16T14:23:47.707Z","doi":"10.25663/bl.app.80"},{"name":"RACE-Track | MRTrix3 Anatomical Informed Tractography","github":"brainlife/app-mrtrix3-act","desc":"Runs mrtrix3 ACT (Anatomically Constrained Tractography) using either single- or multi-shell diffusion-weighted MRI data. ","stats":{"stars":0,"requested":17691,"users":58,"success_rate":49.32970902576142,"serviceinfo":{"_id":"5d729e1f78356a109788b299","counts":{"_id":"5e5c68a587cac70559ab1bd1","failed":3479,"finished":10104,"removed":17081,"requested":19150,"running":13580,"running_sync":0,"stop_requested":1002},"success_rate":74.38710152396378,"users":26,"readme_status":"too short","runtime_mean":3527763.1,"runtime_std":2413346.823899846,"service":"brain-life/app-mrtrix3-act","__v":0},"gitinfo":{"desc":"Runs mrtrix3 ACT (Anatomically Constrained Tractography) using either single- or multi-shell diffusion-weighted MRI data. ","tags":["tracking","tractography"],"stats":{"stars":0},"contributors":[{"name":"Brent McPherson","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":11606863.4,"runtime_std":9971625.491358008,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf386de14be11ff25c370"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf386de14be11ff25c371"}],"examples":5,"groups":124},"create_date":"2018-03-16T20:08:23.804Z","doi":"10.25663/bl.app.101"},{"name":"BIDS Tracula (under development)","github":"soichih/app-bids-tracula","desc":"BIDS app for FS Tracula for BrainLife. Implements Freesurfer's TRACULA (TRActs Constrained by UnderLying Anatomy) tool.","stats":{"stars":0,"requested":27,"users":6,"success_rate":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1f7","counts":{"_id":"5e5c68a687cac70779ab1bd2","failed":11,"finished":0,"removed":9,"requested":23,"running":9,"running_sync":0,"stop_requested":1},"success_rate":0,"users":4,"readme_status":"no README.md","service":"soichih/app-bids-tracula","__v":0},"gitinfo":{"desc":"BIDS app for FS Tracula for BrainLife. Implements Freesurfer's TRACULA (TRActs Constrained by UnderLying Anatomy) tool.","tags":[],"stats":{"stars":0},"contributors":[{"name":null,"email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"resources":[],"examples":0,"groups":4},"create_date":"2018-03-19T18:02:54.919Z","doi":"10.25663/bl.app.76"},{"name":"BIDS Mrtrix3 Connectome","github":"kathrynalpert/app-bids-mrtrix3_connectome","desc":"BIDS app for Mrtrix3 Connectome DTI processing for BrainLife. Generates subject connectomes from raw image data using tools provided in the *MRtrix3* software package. http://www.mrtrix.org/. Optional preprocessing includes FSL's topup analysis for spatial correction and requires at least 2 input DTI images.","stats":{"stars":1,"requested":1183,"users":15,"success_rate":39.34640522875817,"serviceinfo":{"_id":"5d729e1f78356a109788b2d5","counts":{"_id":"5e5c68a787cac7466dab1bd3","failed":141,"finished":34,"removed":555,"requested":588,"running":59,"running_sync":0,"stop_requested":2},"success_rate":19.428571428571427,"users":8,"readme_status":"no README.md","runtime_mean":20855814.44117647,"runtime_std":5221154.285834318,"service":"kathrynalpert/app-bids-mrtrix3_connectome","__v":0},"gitinfo":{"desc":"BIDS app for Mrtrix3 Connectome DTI processing for BrainLife. Generates subject connectomes from raw image data using tools provided in the *MRtrix3* software package. http://www.mrtrix.org/. Optional preprocessing includes FSL's topup analysis for spatial correction and requires at least 2 input DTI images.","tags":["pipeline"],"stats":{"stars":1},"contributors":[{"name":null,"email":null}]},"runtime_mean":22169336.41,"runtime_std":11103109.380038964,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf391de14be11ff25c389"}],"examples":1,"groups":15},"create_date":"2018-04-03T15:18:08.438Z","doi":"10.25663/bl.app.77"},{"name":"White Matter Anatomy Segmentation","github":"brainlife/app-wmaSeg","desc":"Classifies streamlines into known anatomical tracts.","stats":{"stars":1,"requested":39843,"users":59,"success_rate":67.8864679640525,"serviceinfo":{"_id":"5d729e1e78356a109788b20d","counts":{"_id":"5e5c68a887cac7b9faab1bd4","failed":3425,"finished":9221,"removed":16901,"requested":18537,"running":12116,"running_sync":0,"stop_requested":445},"success_rate":72.91633718171754,"users":20,"readme_status":"ok","runtime_mean":14985593.77,"runtime_std":3690815.7786162673,"service":"brainlife/app-wmaSeg","__v":0},"gitinfo":{"desc":"Classifies streamlines into known anatomical tracts.","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lindsey Kitchell","email":null},{"name":"Daniel Bullock","email":null},{"name":"Franco Pestilli","email":null},{"name":"Steven O'Riley","email":null}]},"runtime_mean":8505411.39,"runtime_std":5350958.412636696,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf396de14be11ff25c38c"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf396de14be11ff25c38d"}],"examples":0,"groups":131},"create_date":"2018-04-07T15:17:42.733Z","doi":"10.25663/bl.app.41"},{"name":"DSC evaluation (wmc - wmc)","github":"giulia-berto/app-compute-dsc","desc":"Compute the degree of overlap between two bundle masks using the Dice Similarity Coefficient (DSC) score.","stats":{"stars":0,"requested":334,"users":2,"success_rate":89.58990536277602,"serviceinfo":{"_id":"5d729e1f78356a109788b2f3","counts":{"_id":"5e5c3d9887cac745b2ab13a7","failed":69,"finished":676,"removed":739,"requested":926,"running":792,"running_sync":0,"stop_requested":45},"success_rate":90.73825503355705,"users":1,"readme_status":"too short","runtime_mean":638839.76,"runtime_std":456262.49373193324,"service":"giulia-berto/app-compute-dsc4hcp","__v":0},"gitinfo":{"desc":"Compute the Dice Similarity Coefficient (DSC) between corresponding tracts of the given segmentation and the ground truth when using HCP data.","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":244853.76,"runtime_std":174748.75208854116,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf39dde14be11ff25c447"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf39dde14be11ff25c448"}],"examples":1,"groups":5},"create_date":"2018-04-18T18:57:08.840Z","doi":"10.25663/bl.app.57"},{"name":"ANTs tensor registration based on FA","github":"giulia-berto/app-ants-FA-registration","desc":"FA-based non linear ANTs registration of the tensor to the FMRIB58_FA_1mm.nii.gz template or the IITmean_FA template.","stats":{"stars":0,"requested":927,"users":3,"success_rate":50.4907306434024,"serviceinfo":{"_id":"5d729e1f78356a109788b28b","counts":{"_id":"5e5c3d9987cac72a8bab13a8","failed":1,"finished":4,"removed":4,"requested":6,"running":5,"running_sync":0,"stop_requested":0},"success_rate":80,"users":1,"readme_status":"too short","runtime_mean":1842386.25,"runtime_std":68179.52391068377,"service":"giulia-berto/app-ants-transformation","__v":0},"gitinfo":{"desc":"Compute ANTs transformation between two subjects based on T1 and FA volumes.","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":1705428.66,"runtime_std":518701.36892996955,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf3a2de14be11ff25c491"}],"examples":1,"groups":5},"create_date":"2018-04-22T01:25:10.450Z","doi":"10.25663/brainlife.app.118"},{"name":"ANTs transformation and wmc registration with T1","github":"giulia-berto/app-ants-transformation-registration","desc":"Compute ANTs transformation between two subjects based on T1 or FA volumes and apply the transformation to the AFQ segmentation provided. ","stats":{"stars":0,"requested":27,"users":1,"success_rate":61.53846153846154,"serviceinfo":{"_id":"5d729e1f78356a109788b359","counts":{"_id":"5e5c3d9a87cac729c5ab13a9","failed":5,"finished":8,"removed":12,"requested":27,"running":14,"running_sync":0,"stop_requested":1},"success_rate":61.53846153846154,"users":1,"readme_status":"too short","runtime_mean":3008707.75,"runtime_std":2967110.560963298,"service":"giulia-berto/app-ants-transformation-registration","__v":0},"gitinfo":{"desc":"Compute ANTs transformation between two subjects based on T1 or FA volumes and apply the transformation to the AFQ segmentation provided. ","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":3008707.75,"runtime_std":2967110.560963298,"resources":[],"examples":0,"groups":1},"create_date":"2018-04-23T01:37:56.234Z","doi":"10.25663/bl.app.26"},{"name":"Reslice","github":"dipy/bl_apps_dipy_reslice","desc":"Brainlife wrapper app for dipy_reslice workflows.","stats":{"stars":0,"requested":1402,"users":5,"success_rate":99.84214680347277,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c3d9a87cac7e1a0ab13aa","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":388510.17,"runtime_std":953346.2336801682,"resources":[],"examples":1,"groups":7},"create_date":"2018-05-01T21:27:40.818Z","doi":"10.25663/bl.app.5"},{"name":"Bias Field Correction (dwi)","github":"kitchell/app-biasfieldcorrection","desc":"This application will correct for bias field issues in T1 images using ANTs N4BiasFieldCorrection algorithm","stats":{"stars":0,"requested":312,"users":20,"success_rate":86.02150537634408,"serviceinfo":{"_id":"5d729e1f78356a109788b33b","counts":{"_id":"5e5c3d9b87cac70dcaab13ab","failed":11,"finished":80,"removed":85,"requested":101,"running":91,"running_sync":0,"stop_requested":1},"success_rate":87.91208791208791,"users":10,"readme_status":"ok","runtime_mean":184480.8625,"runtime_std":331632.5116014617,"service":"kitchell/app-biasfieldcorrection","__v":0},"gitinfo":{"desc":"This application will correct for bias field issues in T1 images using ANTs N4BiasFieldCorrection algorithm","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":184480.8625,"runtime_std":331632.5116014617,"resources":[],"examples":0,"groups":15},"create_date":"2018-05-02T14:04:13.681Z","doi":"10.25663/bl.app.7"},{"name":"Fit DKI","github":"dipy/bl_apps_dipy_fit_dki","desc":"Brainlife wrapper app for dipy_fit_dki workflows. Fit a Diffusion Kurtosis Imaging model to multishell Diffusion-weighted data","stats":{"stars":0,"requested":511,"users":10,"success_rate":69.26713947990544,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c3d9c87cac7dfd9ab13ac","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":498319.79,"runtime_std":473676.3283006085,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf3b7de14be11ff25c536"}],"examples":0,"groups":18},"create_date":"2018-05-02T15:20:18.139Z","doi":"10.25663/bl.app.9"},{"name":"Multi-Atlas Transfer Tool - old (w/surface output)","github":"faskowit/app-multiAtlasTT","desc":"brainlife.io version of maTT","stats":{"stars":0,"requested":143270,"users":131,"success_rate":74.58521346754598,"serviceinfo":{"_id":"5d729e1f78356a109788b369","counts":{"_id":"5e5c3d9d87cac7c003ab13ad","failed":1185,"finished":18829,"removed":18563,"requested":22601,"running":19877,"running_sync":0,"stop_requested":105},"success_rate":94.07914459878086,"users":25,"readme_status":"too short","runtime_mean":791624.62,"runtime_std":456318.02287104074,"service":"faskowit/app-multiAtlasTT","__v":0},"gitinfo":{"desc":"brainlife.io version of maTT","tags":[],"stats":{"stars":0},"contributors":[{"name":"Josh Faskowitz","email":null},{"name":"Brent McPherson","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":1128900.81,"runtime_std":847363.4525348811,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf3bcde14be11ff25c6eb"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf3bcde14be11ff25c6ec"}],"examples":5,"groups":259},"create_date":"2018-05-03T16:12:34.843Z","doi":"10.25663/bl.app.23"},{"name":"ANTs transformation and wmc registration with FA","github":"giulia-berto/app-ants-transformation-registration","desc":"Compute ANTs transformation between two subjects based on T1 or FA volumes and apply the transformation to the AFQ segmentation provided. ","stats":{"stars":0,"requested":27,"users":1,"success_rate":61.53846153846154,"serviceinfo":{"_id":"5d729e1f78356a109788b359","counts":{"_id":"5e5c3d9e87cac722efab13ae","failed":5,"finished":8,"removed":12,"requested":27,"running":14,"running_sync":0,"stop_requested":1},"success_rate":61.53846153846154,"users":1,"readme_status":"too short","runtime_mean":3008707.75,"runtime_std":2967110.560963298,"service":"giulia-berto/app-ants-transformation-registration","__v":0},"gitinfo":{"desc":"Compute ANTs transformation between two subjects based on T1 or FA volumes and apply the transformation to the AFQ segmentation provided. ","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":3008707.75,"runtime_std":2967110.560963298,"resources":[],"examples":0,"groups":1},"create_date":"2018-05-07T14:51:57.044Z","doi":"10.25663/bl.app.27"},{"name":"DP Fit Model with dtiInit","github":"brain-life/app-dp-modelfit","desc":null,"stats":{"stars":0,"requested":27,"users":2,"success_rate":54.166666666666664,"serviceinfo":{"_id":"5d729e1f78356a109788b2a9","counts":{"_id":"5e5c3d9f87cac7608bab13af","failed":11,"finished":13,"removed":13,"requested":27,"running":19,"running_sync":0,"stop_requested":1},"success_rate":54.166666666666664,"users":2,"readme_status":"too short","runtime_mean":47315961.92307692,"runtime_std":47384718.75815917,"service":"brain-life/app-dp-modelfit","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":47315961.92307692,"runtime_std":47384718.75815917,"resources":[],"examples":0,"groups":1},"create_date":"2018-05-07T21:10:13.044Z","doi":"10.25663/bl.app.28"},{"name":"pRFLife mrTools","github":"brainlife/app-prf","desc":"This app will compute a population receptive field (i.e. pRF) analysis on a given time series. Inputs needed include: a time series nifti, a stimulus nifti, the measurements of the visual stimulus in space (stimimageunits), and dimensions of a mask (mask; optional). Outputs include: x.nii, y.nii, rfWidth.nii and r2.nii. Please see http://gru.stanford.edu/doku.php/mrTools/tutorialsprf for more detail.","stats":{"stars":0,"requested":35,"users":3,"success_rate":24.137931034482758,"serviceinfo":{"_id":"5d729e1e78356a109788b215","counts":{"_id":"5e5c3da087cac762a7ab13b1","failed":13,"finished":6,"removed":12,"requested":23,"running":19,"running_sync":0,"stop_requested":0},"success_rate":31.57894736842105,"users":2,"readme_status":"too short","service":"brainlife/app-prf","__v":0,"runtime_mean":28643087.666666668,"runtime_std":26318452.17967312},"gitinfo":{"desc":"pRF for BrainLife","tags":[],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Justin Gardner","email":null},{"name":"Steven O'Riley","email":null}]},"runtime_mean":27934812.14285714,"runtime_std":24427838.41657127,"resources":[],"examples":0,"groups":4},"create_date":"2018-05-16T20:44:33.056Z","doi":"10.25663/bl.app.31"},{"name":"Compute Volume of Binary Nifti images","github":"kitchell/app-binvolvolume","desc":"computes the volume of binary nifti images","stats":{"stars":0,"requested":385,"users":5,"success_rate":95,"serviceinfo":{"_id":"5d729e1f78356a109788b2af","counts":{"_id":"5e5c3da187cac71d7aab13b2","failed":14,"finished":259,"removed":261,"requested":277,"running":267,"running_sync":0,"stop_requested":1},"success_rate":94.87179487179486,"users":2,"readme_status":"ok","runtime_mean":1511337.12,"runtime_std":1535459.4813143804,"service":"kitchell/app-binvolvolume","__v":0},"gitinfo":{"desc":"computes the volume of binary nifti images","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":31642.66,"runtime_std":12377.717100677328,"resources":[],"examples":0,"groups":4},"create_date":"2018-05-17T23:24:26.925Z","doi":"10.25663/bl.app.32"},{"name":"ROI to ROI Tracking - deprecated","github":"brainlife/app-roi2roitracking","desc":"This app will perform ensemble tracking between 2 or more cortical regions of interest (ROIs) from either a freesurfer parcellation or an atlas parcellation. The app will automatically generate ROI niftis in diffusion space for tracking based on inputted ROI numbers. Inputs include: parcellation (freesurfer; atlas optional), dt6 from dtiinit, and ROI pairings. Outputs include a track.tck for each pairing of ROIs, a classification structure, and a fg_classified structure which can then be fed into other apps on the website (example: Clean WMC Output).","stats":{"stars":0,"requested":82,"users":3,"success_rate":4.411764705882353,"serviceinfo":{"_id":"5d729e1f78356a109788b2eb","counts":{"_id":"5e5c3da287cac78155ab13b3","failed":3381,"finished":11383,"removed":28448,"requested":30096,"running":14546,"running_sync":0,"stop_requested":509},"success_rate":77.0997019777838,"users":4,"readme_status":"ok","runtime_mean":5104239.9,"runtime_std":9812760.010720242,"service":"brain-life/app-roi2roitracking","__v":0},"gitinfo":{"desc":"This app will perform ensemble tracking between 2 or more cortical regions of interest (ROIs) from either a freesurfer parcellation or an atlas parcellation. The app will automatically generate ROI niftis in diffusion space for tracking based on inputted ROI numbers. Inputs include: parcellation (freesurfer; atlas optional), dt6 from dtiinit, and ROI pairings. Outputs include a track.tck for each pairing of ROIs, a classification structure, and a fg_classified structure which can then be fed into other apps on the website (example: Clean WMC Output).","tags":["tracking"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null},{"name":"Ilaria Sani","email":"ila.gina@virgilio.it"}]},"runtime_mean":48983551,"runtime_std":10404132.833534982,"resources":[],"examples":0,"groups":4},"create_date":"2018-05-20T22:28:20.022Z","doi":"10.25663/bl.app.34"},{"name":"Reconstruct Surfaces from LB Eigenfunctions","github":"kitchell/app-reconstructLBeigenfunction","desc":"This application will reconstruct the surfaces of each 3D model based on the selected number of eigenfunctions.","stats":{"stars":0,"requested":78,"users":2,"success_rate":76.47058823529412,"serviceinfo":{"_id":"5d729e1f78356a109788b2db","counts":{"_id":"5e5c3da387cac7ca5eab13b4","failed":16,"finished":52,"removed":52,"requested":78,"running":69,"running_sync":0,"stop_requested":4},"success_rate":76.47058823529412,"users":2,"readme_status":"ok","runtime_mean":8616369.461538462,"runtime_std":5782143.5322341435,"service":"kitchell/app-reconstructLBeigenfunction","__v":0},"gitinfo":{"desc":"This application will reconstruct the surfaces of each 3D model based on the selected number of eigenfunctions.","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":8616369.461538462,"runtime_std":5782143.5322341435,"resources":[],"examples":0,"groups":2},"create_date":"2018-05-24T01:26:30.574Z","doi":"10.25663/bl.app.36"},{"name":"ROI Generation (w/ dtiinit)","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"stars":0,"requested":13134,"users":27,"success_rate":83.53765323992994,"serviceinfo":{"_id":"5d729e1f78356a109788b2b7","counts":{"_id":"5e5c3da487cac765efab13b5","failed":788,"finished":6048,"removed":7078,"requested":7656,"running":6617,"running_sync":0,"stop_requested":49},"success_rate":88.47279110590989,"users":12,"readme_status":"ok","runtime_mean":5580586.29,"runtime_std":23419021.556393724,"service":"brain-life/app-roiGenerator","__v":0},"gitinfo":{"desc":"This app will generate nifti files for specific ROIs, or every ROI, for a parcellation (either freesurfer or atlas).","tags":[],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf3e1de14be11ff25c790"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf3e1de14be11ff25c791"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf3e1de14be11ff25c792"}],"examples":0,"groups":58},"create_date":"2018-05-24T01:49:30.447Z","doi":"10.25663/bl.app.37"},{"name":"Convert Pial (Cortical) and White Matter Surfaces from Freesurfer","github":"kitchell/app-3DPialWM_freesurfer","desc":"This application converts Freesurfer's pial and white matter surfaces to different file types. It will convert the lh/rh.pial, lh/rh.white, lh/rh.smoothwm, lh/rh.inflated files into your choice of file type (stl, vtk, gii, mgz)","stats":{"stars":0,"requested":1336,"users":14,"success_rate":91.33383571966843,"serviceinfo":{"_id":"5d729e1f78356a109788b29b","counts":{"_id":"5e5c3da587cac7ddc0ab13b6","failed":95,"finished":1127,"removed":1124,"requested":1228,"running":1144,"running_sync":0,"stop_requested":0},"success_rate":92.22585924713584,"users":10,"readme_status":"ok","runtime_mean":1504967.96,"runtime_std":3072887.269125021,"service":"kitchell/app-3DPialWM_freesurfer","__v":0},"gitinfo":{"desc":"This application converts Freesurfer's pial and white matter surfaces to different file types. It will convert the lh/rh.pial, lh/rh.white, lh/rh.smoothwm, lh/rh.inflated files into your choice of file type (stl, vtk, gii, mgz)","tags":["convert"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":5275247.54,"runtime_std":11936274.070740825,"resources":[],"examples":1,"groups":12},"create_date":"2018-05-25T16:53:39.754Z","doi":"10.25663/bl.app.38"},{"name":"Posterior Associative White Matter Tracts Segmentation","github":"brainlife/app-wmaSeg","desc":"Classifies streamlines into known anatomical tracts.","stats":{"stars":1,"requested":39843,"users":59,"success_rate":67.8864679640525,"serviceinfo":{"_id":"5d729e1e78356a109788b20d","counts":{"_id":"5e5c3da687cac74ea5ab13b8","failed":3425,"finished":9221,"removed":16901,"requested":18537,"running":12116,"running_sync":0,"stop_requested":445},"success_rate":72.91633718171754,"users":20,"readme_status":"ok","runtime_mean":14985593.77,"runtime_std":3690815.7786162673,"service":"brainlife/app-wmaSeg","__v":0},"gitinfo":{"desc":"Classifies streamlines into known anatomical tracts.","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lindsey Kitchell","email":null},{"name":"Daniel Bullock","email":null},{"name":"Franco Pestilli","email":null},{"name":"Steven O'Riley","email":null}]},"runtime_mean":8505411.39,"runtime_std":5350958.412636696,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf3ecde14be11ff25c7e6"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf3ecde14be11ff25c7e7"}],"examples":0,"groups":131},"create_date":"2018-04-07T15:17:42.733Z","doi":"10.25663/bl.app.46"},{"name":"Plot tract measures","github":"giulia-berto/app-plot-tract-measures","desc":"Compute and plot total number of fibers, total number of nodes and average length of some tracts.","stats":{"stars":0,"requested":482,"users":2,"success_rate":78.00511508951406,"serviceinfo":{"_id":"5d729e1f78356a109788b303","counts":{"_id":"5e5c3da887cac73f7dab13b9","failed":86,"finished":305,"removed":316,"requested":482,"running":384,"running_sync":0,"stop_requested":5},"success_rate":78.00511508951406,"users":2,"readme_status":"no README.md","runtime_mean":303397.44,"runtime_std":177194.31238774676,"service":"giulia-berto/app-plot-tract-measures","__v":0},"gitinfo":{"desc":"Compute and plot total number of fibers, total number of nodes and average length of some tracts.","tags":[],"stats":{"stars":0},"contributors":[]},"runtime_mean":303397.44,"runtime_std":177194.31238774676,"resources":[],"examples":0,"groups":1},"create_date":"2018-06-08T10:04:14.442Z","doi":"10.25663/bl.app.58"},{"name":"Fit DTI","github":"dipy/bl_apps_dipy_fit_dti","desc":"Brainlife wrapper app for dipy_fit_dti workflows.","stats":{"stars":0,"requested":2626,"users":13,"success_rate":46.84256055363322,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c3da887cac70a9bab13ba","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":27849.68,"runtime_std":29091.43433689031,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf3f9de14be11ff25ca01"}],"examples":4,"groups":34},"create_date":"2018-06-11T22:44:54.991Z","doi":"10.25663/bl.app.60"},{"name":"Fit CSA","github":"dipy/bl_apps_dipy_fit_csa","desc":"Brainlife wrapper app for dipy_fit_csa workflows","stats":{"stars":0,"requested":163,"users":6,"success_rate":98.14814814814815,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c3da987cac786d7ab13bb","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":637961.91,"runtime_std":538398.7297441944,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf3fede14be11ff25ca2f"}],"examples":1,"groups":5},"create_date":"2018-06-11T22:49:42.618Z","doi":"10.25663/bl.app.61"},{"name":"Fit CSD","github":"dipy/bl_apps_dipy_fit_csd","desc":"Brainlife wrapper app for dipy_fit_csd workflows.","stats":{"stars":0,"requested":834,"users":13,"success_rate":78.08219178082192,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c3dab87cac7457eab13bc","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":453613.57,"runtime_std":566215.4412860047,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf404de14be11ff25caf6"}],"examples":2,"groups":18},"create_date":"2018-06-11T22:52:25.572Z","doi":"10.25663/bl.app.62"},{"name":"DWI Info","github":"dipy/bl_apps_dipy_info","desc":"Brainlife wrapper app for dipy_info workflows.","stats":{"stars":0,"requested":7,"users":2,"success_rate":100,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c3dac87cac721ceab13bd","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":64824,"runtime_std":38893.390218219174,"resources":[],"examples":0,"groups":2},"create_date":"2018-06-11T22:59:25.625Z","doi":"10.25663/bl.app.63"},{"name":"DP Profile with dtiInit","github":"brain-life/app-dp-profile","desc":null,"stats":{"stars":1,"requested":116,"users":2,"success_rate":69.6969696969697,"serviceinfo":{"_id":"5d729e1f78356a109788b2a7","counts":{"_id":"5e5c3dad87cac74c8dab13be","failed":30,"finished":69,"removed":46,"requested":116,"running":108,"running_sync":0,"stop_requested":17},"success_rate":69.6969696969697,"users":2,"readme_status":"too short","runtime_mean":27309476.68115942,"runtime_std":16119854.14207645,"service":"brain-life/app-dp-profile","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":1},"contributors":[{"name":"Cesar Caiafa","email":"ccaiafa@gmail.com"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":27309476.68115942,"runtime_std":16119854.14207645,"resources":[],"examples":0,"groups":1},"create_date":"2018-06-13T15:50:22.675Z","doi":"10.25663/bl.app.64"},{"name":"Tensor Mask","github":"dipy/bl_apps_dipy_mask","desc":"Brainlife wrapper app for dipy_mask workflows.","stats":{"stars":0,"requested":133,"users":6,"success_rate":88.88888888888889,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c3dae87cac7e68eab13bf","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":4094572.25,"runtime_std":13283063.972576123,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf414de14be11ff25cb24"}],"examples":1,"groups":4},"create_date":"2018-06-13T19:49:18.543Z","doi":"10.25663/bl.app.65"},{"name":"Tracking using Deterministic algorithm","github":"dipy/bl_apps_dipy_track","desc":"Brainlife wrapper app for dipy_track workflows.","stats":{"stars":0,"requested":849,"users":12,"success_rate":96.84343434343434,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c3daf87cac794d5ab13c0","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":3502445.35,"runtime_std":4220463.651326779,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf41ade14be11ff25cb84"}],"examples":0,"groups":14},"create_date":"2018-06-13T19:58:03.928Z","doi":"10.25663/bl.app.66"},{"name":"Fit MAPMRI","github":"dipy/bl_apps_dipy_fit_mapmri","desc":"Brainlife wrapper app for dipy_fit_mapmri workflows.","stats":{"stars":0,"requested":12,"users":2,"success_rate":36.36363636363637,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c3db087cac7647dab13c1","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":16267104.75,"runtime_std":4083623.5805641646,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf41fde14be11ff25cb88"}],"examples":0,"groups":2},"create_date":"2018-06-13T20:10:38.805Z","doi":"10.25663/bl.app.67"},{"name":"clever","github":"mandymejia/app-clever","desc":"Clever","stats":{"stars":0,"requested":201,"users":3,"success_rate":22.950819672131146,"serviceinfo":{"_id":"5d729e1f78356a109788b26b","counts":{"_id":"5e5c3db287cac75142ab13c3","failed":74,"finished":7,"removed":8,"requested":95,"running":93,"running_sync":0,"stop_requested":12},"success_rate":8.641975308641975,"users":3,"readme_status":"too short","service":"mandymejia/app-clever","__v":0,"runtime_mean":629681.75,"runtime_std":437885.69517533627},"gitinfo":{"desc":"Clever","tags":[],"stats":{"stars":0},"contributors":[{"name":"Damon Pham","email":"damondpham@gmail.com"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":3756366.6666666665,"runtime_std":5414504.945903389,"resources":[],"examples":0,"groups":4},"create_date":"2018-06-19T21:29:58.865Z","doi":"10.25663/bl.app.71"},{"name":"DP Remove Tracts with dtiInit","github":"brain-life/app-dp-removetract","desc":null,"stats":{"stars":0,"requested":3,"users":1,"success_rate":100,"serviceinfo":{"_id":"5d729e1f78356a109788b2a5","counts":{"_id":"5e5c3db287cac711fdab13c4","failed":0,"finished":3,"removed":3,"requested":3,"running":3,"running_sync":0,"stop_requested":0},"success_rate":100,"users":1,"readme_status":"too short","runtime_mean":4545888.666666667,"runtime_std":5847269.297008096,"service":"brain-life/app-dp-removetract","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":4545888.666666667,"runtime_std":5847269.297008096,"resources":[],"examples":0,"groups":1},"create_date":"2018-06-29T18:50:15.387Z","doi":"10.25663/bl.app.81"},{"name":"Volume-based Multiple Linear Regression","github":"brainlife/app-socr-mlra","desc":"SOCR / Volume-based Multiple Linear Regression Analysis","stats":{"stars":0,"requested":347,"users":5,"success_rate":96.72131147540983,"serviceinfo":{"_id":"5d729e1f78356a109788b255","counts":{"_id":"5e5c3db387cac76a3cab13c5","failed":0,"finished":7,"removed":7,"requested":9,"running":7,"running_sync":0,"stop_requested":0},"success_rate":100,"users":3,"readme_status":"too short","runtime_mean":8178746.571428572,"runtime_std":13238948.16180075,"service":"brain-life/app-socr-mlra","__v":0},"gitinfo":{"desc":"SOCR / Volume-based Multiple Linear Regression Analysis","tags":[],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":318400.23,"runtime_std":613013.5496871476,"resources":[],"examples":1,"groups":6},"create_date":"2018-07-19T14:46:51.757Z","doi":"10.25663/bl.app.84"},{"name":"Check Gradient Flip","github":"brainlife/app-testflip","desc":"This app will quickly check the dwi image to see if any bvecs directions needs to be flipped. The algorithm finds bvecs that are pointing toward certain direction and find the volume slice within 4D DWI data and see how many image slices indeed seems to contain features that are orthogonal to the bvecs directions. Inconclusive output from this App usually means you have some data quality issue with your dwi.","stats":{"stars":0,"requested":173,"users":10,"success_rate":96.29629629629629,"serviceinfo":{"_id":"5d729e1f78356a109788b279","counts":{"_id":"5e5c3db487cac7d77fab13c6","failed":14,"finished":118,"removed":113,"requested":143,"running":133,"running_sync":0,"stop_requested":1},"success_rate":89.39393939393939,"users":16,"readme_status":"ok","runtime_mean":5599684,"runtime_std":23684325.233460553,"service":"brain-life/app-testflip","__v":0},"gitinfo":{"desc":"This app will quickly check the dwi image to see if any bvecs directions needs to be flipped. The algorithm finds bvecs that are pointing toward certain direction and find the volume slice within 4D DWI data and see how many image slices indeed seems to contain features that are orthogonal to the bvecs directions. Inconclusive output from this App usually means you have some data quality issue with your dwi.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":1699165.3,"runtime_std":9454758.711211141,"resources":[],"examples":4,"groups":19},"create_date":"2018-07-25T17:31:31.023Z","doi":"10.25663/bl.app.85"},{"name":"Network Neuro Aggregator","github":"brainlife/app-networkneuro-agg","desc":"This App will take multiple outputs from networkneuro (the connectivity matrices) and aggregate them by calculating the mean and sdev across all matrices.","stats":{"stars":0,"requested":30,"users":8,"success_rate":79.16666666666666,"serviceinfo":{"_id":"5d729e1f78356a109788b2a1","counts":{"_id":"5e5c3db487cac75fbaab13c7","failed":3,"finished":11,"removed":14,"requested":20,"running":13,"running_sync":0,"stop_requested":0},"success_rate":78.57142857142857,"users":6,"readme_status":"too short","runtime_mean":977260.7272727273,"runtime_std":1053239.1528133226,"service":"brainlife/app-networkneuro-agg","__v":0},"gitinfo":{"desc":"This App will take multiple outputs from networkneuro (the connectivity matrices) and aggregate them by calculating the mean and sdev across all matrices.","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":618304.7368421053,"runtime_std":917758.8931167191,"resources":[],"examples":1,"groups":7},"create_date":"2018-08-14T21:27:32.619Z","doi":"10.25663/bl.app.89"},{"name":"Tract Profile Aggregator","github":"brainlife/app-tractprofiles-agg","desc":"Tract Profile Output Aggregator","stats":{"stars":0,"requested":14,"users":4,"success_rate":64.28571428571429,"serviceinfo":{"_id":"5d729e1e78356a109788b1f9","counts":{"_id":"5e5c3db587cac72491ab13c8","failed":4,"finished":8,"removed":7,"requested":12,"running":11,"running_sync":0,"stop_requested":0},"success_rate":66.66666666666666,"users":2,"readme_status":"empty","runtime_mean":1992114.875,"runtime_std":4353723.755432568,"service":"brainlife/app-tractprofiles-agg","__v":0},"gitinfo":{"desc":"Tract Profile Output Aggregator","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":1802518.4444444445,"runtime_std":4139611.5541793993,"resources":[],"examples":0,"groups":3},"create_date":"2018-08-15T17:17:44.634Z","doi":"10.25663/bl.app.90"},{"name":"DP Fit Model with DWI","github":"brain-life/app-dp-modelfit","desc":null,"stats":{"stars":0,"requested":27,"users":2,"success_rate":54.166666666666664,"serviceinfo":{"_id":"5d729e1f78356a109788b2a9","counts":{"_id":"5e5c3db587cac75ec7ab13c9","failed":11,"finished":13,"removed":13,"requested":27,"running":19,"running_sync":0,"stop_requested":1},"success_rate":54.166666666666664,"users":2,"readme_status":"too short","runtime_mean":47315961.92307692,"runtime_std":47384718.75815917,"service":"brain-life/app-dp-modelfit","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":47315961.92307692,"runtime_std":47384718.75815917,"resources":[],"examples":0,"groups":1},"create_date":"2018-08-21T14:35:16.145Z","doi":"10.25663/bl.app.91"},{"name":"DP Profile with DWI","github":"brain-life/app-dp-profile","desc":null,"stats":{"stars":1,"requested":116,"users":2,"success_rate":69.6969696969697,"serviceinfo":{"_id":"5d729e1f78356a109788b2a7","counts":{"_id":"5e5c3db687cac71146ab13ca","failed":30,"finished":69,"removed":46,"requested":116,"running":108,"running_sync":0,"stop_requested":17},"success_rate":69.6969696969697,"users":2,"readme_status":"too short","runtime_mean":27309476.68115942,"runtime_std":16119854.14207645,"service":"brain-life/app-dp-profile","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":1},"contributors":[{"name":"Cesar Caiafa","email":"ccaiafa@gmail.com"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":27309476.68115942,"runtime_std":16119854.14207645,"resources":[],"examples":0,"groups":1},"create_date":"2018-08-21T15:04:15.803Z","doi":"10.25663/bl.app.92"},{"name":"DP Remove Tracts with DWI","github":"brain-life/app-dp-removetract","desc":null,"stats":{"stars":0,"requested":3,"users":1,"success_rate":100,"serviceinfo":{"_id":"5d729e1f78356a109788b2a5","counts":{"_id":"5e5c3db787cac77e01ab13cb","failed":0,"finished":3,"removed":3,"requested":3,"running":3,"running_sync":0,"stop_requested":0},"success_rate":100,"users":1,"readme_status":"too short","runtime_mean":4545888.666666667,"runtime_std":5847269.297008096,"service":"brain-life/app-dp-removetract","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":4545888.666666667,"runtime_std":5847269.297008096,"resources":[],"examples":0,"groups":1},"create_date":"2018-08-21T15:08:20.024Z","doi":"10.25663/bl.app.93"},{"name":"Freesurfer Group Analysis","github":"brainlife/app-freesurfer-agg","desc":"Do some basic group analysis on freesurfer outputs","stats":{"stars":0,"requested":29,"users":11,"success_rate":45.83333333333333,"serviceinfo":{"_id":"5d729e1f78356a109788b29d","counts":{"_id":"5e5c3db887cac78b76ab13cc","failed":1,"finished":11,"removed":15,"requested":15,"running":11,"running_sync":0,"stop_requested":0},"success_rate":91.66666666666666,"users":6,"readme_status":"too short","runtime_mean":193613,"runtime_std":167896.7124925863,"service":"brainlife/app-freesurfer-agg","__v":0},"gitinfo":{"desc":"Do some basic group analysis on freesurfer outputs","tags":[],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":193613,"runtime_std":167896.7124925863,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf453de14be11ff25cc44"}],"examples":0,"groups":9},"create_date":"2018-08-23T19:48:25.197Z","doi":"10.25663/bl.app.94"},{"name":"TractSeg","github":"brainlife/app-tractseg","desc":"Brainlife App for MIC-DKFZ/TractSeg. A tool for fast and accurate white matter bundle segmentation from Diffusion MRI using pretrained pytorch ML model.","stats":{"stars":0,"requested":18958,"users":75,"success_rate":72.25153595952295,"serviceinfo":{"_id":"5d729e1f78356a109788b297","counts":{"_id":"5e5c3db887cac71751ab13cd","failed":1970,"finished":3685,"removed":5706,"requested":6806,"running":5581,"running_sync":0,"stop_requested":277},"success_rate":65.16357206012378,"users":38,"readme_status":"ok","runtime_mean":7740929.19,"runtime_std":13531350.077703223,"service":"brainlife/app-tractseg","__v":0},"gitinfo":{"desc":"Brainlife App for MIC-DKFZ/TractSeg. A tool for fast and accurate white matter bundle segmentation from Diffusion MRI using pretrained pytorch ML model.","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lindsey Kitchell","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":3566537.1,"runtime_std":3455392.223018305,"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"642cf459de14be11ff25cc59"},{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf459de14be11ff25cc5a"}],"examples":0,"groups":100},"create_date":"2018-08-26T16:40:20.035Z","doi":"10.25663/bl.app.95"},{"name":"Align T1 to ACPC Plane (HCP-based)","github":"brainlife/app-hcp-acpc-alignment","desc":"This app will align a T1w image to the ACPC plane (specifically, the MNI152_T1_1mm template from FSL using a 6 DOF alignment via FSL commands. This protocol was adapted from the HCP Preprocessing Pipeline (https://github.com/Washington-University/HCPpipelines.git). Requires a T1w image input and outputs an acpc_aligned T1w image.","stats":{"stars":1,"requested":99085,"users":148,"success_rate":87.43401733114742,"serviceinfo":{"_id":"5d729e1f78356a109788b29f","counts":{"_id":"5e5c3db987cac715c3ab13ce","failed":259,"finished":6239,"removed":6417,"requested":7347,"running":6560,"running_sync":0,"stop_requested":264},"success_rate":96.01415820252386,"users":56,"readme_status":"ok","runtime_mean":1274538.2,"runtime_std":2614641.7180160973,"service":"brain-life/app-hcp-acpc-alignment","__v":0},"gitinfo":{"desc":"This app will align a T1w image to the ACPC plane (specifically, the MNI152_T1_1mm template from FSL using a 6 DOF alignment via FSL commands. This protocol was adapted from the HCP Preprocessing Pipeline (https://github.com/Washington-University/HCPpipelines.git). Requires a T1w image input and outputs an acpc_aligned T1w image.","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Josh Faskowitz","email":null}]},"runtime_mean":34232313.61,"runtime_std":84465148.88505387,"resources":[],"examples":3,"groups":296},"create_date":"2018-09-10T20:37:01.031Z","doi":"10.25663/bl.app.99"},{"name":"Convert trk to tck","github":"brainlife/app-trk2tck","desc":"Convert trk (trackvis) file to tck (mrtrix) format","stats":{"stars":0,"requested":283,"users":23,"success_rate":90.97472924187726,"serviceinfo":{"_id":"5d729e1f78356a109788b295","counts":{"_id":"5e5c3dba87cac776b1ab13cf","failed":2,"finished":62,"removed":64,"requested":66,"running":63,"running_sync":0,"stop_requested":0},"success_rate":96.875,"users":6,"readme_status":"too short","runtime_mean":502999.4032258064,"runtime_std":790245.7297544911,"service":"brainlife/app-trk2tck","__v":0},"gitinfo":{"desc":"Convert trk (trackvis) file to tck (mrtrix) format","tags":["convert"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":3053238.83,"runtime_std":29030376.999969296,"resources":[],"examples":3,"groups":24},"create_date":"2018-09-12T16:34:40.208Z","doi":"10.25663/bl.app.100"},{"name":"Ensemble Tracking (dwi)","github":"brainlife/app-ensembletracking","desc":"This App creates a large set of candidate streamlines using an ensemble of algorithms and parameter values. All outputs will be then combined into a single track.tck output.","stats":{"stars":0,"requested":2015,"users":13,"success_rate":34.54641350210971,"serviceinfo":{"_id":"5d729e1f78356a109788b2cf","counts":{"_id":"5e5c3dbb87cac795c6ab13d0","failed":3486,"finished":8001,"removed":13974,"requested":22462,"running":16310,"running_sync":0,"stop_requested":341},"success_rate":69.6526508226691,"users":61,"readme_status":"ok","runtime_mean":6517627.81,"runtime_std":3750518.3309636554,"service":"brain-life/app-ensembletracking","__v":0},"gitinfo":{"desc":"This service uses MRtrix 0.2.12 to do ensemble tracking using tensor and constrained spherical deconvolution (csd) algorithms. It generates a large set of candidate streamlines using a tensor-based deterministic model, csd-based deterministic model, and csd-based probabilistic model. The csd-based models can be computed at lmax values of 2, 4, 6, 8, 10, and 12. All candidate streamlines are combined into a single track.mat file. If you know the max lmax value for your data input the value for max_lmax, otherwise leave it blank and it will be calculated for you. If you wish to use just deterministic tracking (MRtrix streamtrack parameter SD_STREAM) check do_deterministic. If you wish to use just probabilistic tracking (MRtrix streamtrack parameter SD_PROB) check do_probabilistic If you wish to use the tensor tracking (MRtrix streamtrack parameter DT_STREAM) check do_tensor. By default it will use all three tracking methods. For more information about Ensemble Tractography see Takemura, H., Caiafa, C. F., Wandell, B. A., & Pestilli, F. (2016). Ensemble tractography. PLoS computational biology, 12(2), e1004692.","tags":["brain-connectome","diffusion-mri","mri","tracking","tractography","white-matter"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Brent McPherson","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":1206734.29,"runtime_std":2026412.4706887305,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf468de14be11ff25cf14"}],"examples":0,"groups":13},"create_date":"2018-09-25T14:01:45.332Z","doi":"10.25663/bl.app.103"},{"name":"LiFE (dwi)","github":"brainlife/app-life","desc":"LiFE (Linear Fasicle Evaluation) predicts the measured diffusion signal using the orientation of the fascicles present in a connectome. LiFE uses the difference between the measured and predicted diffusion signals to measure prediction error. The connectome model prediction error is used to compute two metrics to evaluate the evidence supporting properties of the connectome.","stats":{"stars":1,"requested":11930,"users":38,"success_rate":87.2557928214448,"serviceinfo":{"_id":"5d729e1e78356a109788b1ff","counts":{"_id":"5e5c3dbc87cac7c863ab13d1","failed":126,"finished":188,"removed":197,"requested":340,"running":304,"running_sync":0,"stop_requested":8},"success_rate":59.87261146496815,"users":20,"readme_status":"ok","runtime_mean":4337540.8,"runtime_std":5967128.320774562,"service":"brainlife/app-life","__v":0},"gitinfo":{"desc":"LiFE (Linear Fasicle Evaluation) predicts the measured diffusion signal using the orientation of the fascicles present in a connectome. LiFE uses the difference between the measured and predicted diffusion signals to measure prediction error. The connectome model prediction error is used to compute two metrics to evaluate the evidence supporting properties of the connectome.","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lindsey Kitchell","email":null},{"name":"Ariel Rokem","email":"arokem@gmail.com"},{"name":"Steven O'Riley","email":null},{"name":"Brent McPherson","email":null},{"name":"Brian Wandell","email":null}]},"runtime_mean":10802537.57,"runtime_std":31841149.15570827,"resources":[],"examples":1,"groups":52},"create_date":"2018-09-25T14:22:41.720Z","doi":"10.25663/bl.app.104"},{"name":"MRtrix2 Tracking (dwi)","github":"brainlife/app-tracking","desc":"This service uses mrtrix 2.0 to track using three methods DTI-based Deterministic, CSD-based Probabilistic and Deterministic. It generates three separate tractograms (TCK), one for each algorithm.","stats":{"stars":0,"requested":772,"users":10,"success_rate":0,"serviceinfo":{"_id":"5d729e1f78356a109788b349","counts":{"_id":"5e5c3dbe87cac79585ab13d2","failed":131,"finished":611,"removed":924,"requested":1041,"running":913,"running_sync":0,"stop_requested":232},"success_rate":82.34501347708894,"users":25,"readme_status":"ok","runtime_mean":4947548.36,"runtime_std":4929968.26576655,"service":"brain-life/app-tracking","__v":0},"gitinfo":{"desc":"This service uses mrtrix 2.0 to track using three methods DTI-based Deterministic, CSD-based Probabilistic and Deterministic. It generates three separate tractograms (TCK), one for each algorithm.","tags":["tracking"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Lindsey Kitchell","email":null},{"name":"Paolo Avesani","email":null}]},"resources":[],"examples":0,"groups":12},"create_date":"2018-09-25T21:28:33.734Z","doi":"10.25663/bl.app.105"},{"name":"noop","github":"brainlife/app-noop","desc":"Service that does nothing (exist to do inter-resource transfer)","stats":{"stars":0,"requested":298087,"users":544,"success_rate":98.85701795682293,"serviceinfo":{"_id":"5d729e1e78356a109788b227","counts":{"_id":"5e5c3dbf87cac75d2bab13d3","failed":8,"finished":25399,"removed":19922,"requested":25456,"running":0,"running_sync":25375,"stop_requested":0},"success_rate":99.96851261463377,"users":124,"readme_status":"no README.md","runtime_mean":180.57,"runtime_std":63.274205644954556,"service":"brainlife/app-noop","__v":0},"gitinfo":{"desc":"Service that does nothing (exist to do inter-resource transfer)","tags":[],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":118.46,"runtime_std":39.72893655762761,"resources":[{"resource_id":"5979f579abf0be0023d11be4","name":"brainlife upload / validator","_id":"642cf479de14be11ff25d015"}],"examples":0,"groups":1053},"create_date":"2018-10-09T19:49:29.436Z","doi":"10.25663/brainlife.app.110"},{"name":"DWI preproc and nonlinear registration to T1","github":"brainlife/app-dwi2t1-nonlinear","desc":"App for running mrtrix3 dwipreproc and then performing nonlinear registration of dwi to T1 (by running ANTs affine+nonlinear registration of CSF masks of mean b0 and T1). Bvectors are rotated with the affine transform. App is recommended for bringing dwi to T1 space if no phase encoding contrast between b=0 images was collected (so mrtrix3 dwipreproc cannot perform inhomogeneity field estimation).","stats":{"stars":0,"requested":64,"users":6,"success_rate":0,"serviceinfo":{"_id":"5d729e1f78356a109788b291","counts":{"_id":"5e5c3dc087cac77c0cab13d4","failed":31,"finished":100,"removed":122,"requested":142,"running":130,"running_sync":0,"stop_requested":1},"success_rate":76.33587786259542,"users":9,"readme_status":"no README.md","runtime_mean":3905717.72,"runtime_std":1050945.3065085365,"service":"kathrynalpert/app-dwi2t1-nonlinear","__v":0},"gitinfo":{"desc":"App for running mrtrix3 dwipreproc and then performing nonlinear registration of dwi to T1 (by running ANTs affine+nonlinear registration of CSF masks of mean b0 and T1). Bvectors are rotated with the affine transform. App is recommended for bringing dwi to T1 space if no phase encoding contrast between b=0 images was collected (so mrtrix3 dwipreproc cannot perform inhomogeneity field estimation).","tags":["pipeline"],"stats":{"stars":0},"contributors":[{"name":null,"email":null}]},"resources":[],"examples":0,"groups":6},"create_date":"2018-10-11T17:37:32.183Z","doi":"10.25663/brainlife.app.111"},{"name":"HRSC: High Resolution Structural Connectome Processing","github":"kathrynalpert/app-hrsc","desc":"App for running high resolution structural connectome processing from Pierre Besson","stats":{"stars":0,"requested":107,"users":1,"success_rate":87.96296296296296,"serviceinfo":{"_id":"5d729e1f78356a109788b28f","counts":{"_id":"5e5c3dc087cac798a2ab13d5","failed":13,"finished":95,"removed":106,"requested":107,"running":106,"running_sync":0,"stop_requested":0},"success_rate":87.96296296296296,"users":1,"readme_status":"too short","runtime_mean":109380665.53684211,"runtime_std":14702553.00414274,"service":"kathrynalpert/app-hrsc","__v":0},"gitinfo":{"desc":"App for running high resolution structural connectome processing from Pierre Besson","tags":[],"stats":{"stars":0},"contributors":[{"name":null,"email":null}]},"runtime_mean":109380665.53684211,"runtime_std":14702553.00414274,"resources":[],"examples":0,"groups":1},"create_date":"2018-10-11T20:37:33.724Z","doi":"10.25663/brainlife.app.112"},{"name":"RecoBundles","github":"dipy/bl_apps_dipy_recobundles","desc":"Brainlife wrapper app for dipy_recobundles workflows.","stats":{"stars":0,"requested":801,"users":8,"success_rate":1.6786570743405276,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c3dc187cac76fccab13d6","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":3352681.285714286,"runtime_std":2555161.9765768116,"resources":[],"examples":0,"groups":9},"create_date":"2018-10-11T21:08:23.865Z","doi":"10.25663/brainlife.app.113"},{"name":"Crop and Reorient T2","github":"brainlife/app-crop_reorient","desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","stats":{"stars":0,"requested":11099,"users":106,"success_rate":94.52861952861953,"serviceinfo":{"_id":"5d729e1e78356a109788b1d9","counts":{"_id":"5e5c3dc287cac72d7cab13d7","failed":41,"finished":875,"removed":737,"requested":989,"running":921,"running_sync":0,"stop_requested":34},"success_rate":95.52401746724891,"users":21,"readme_status":"ok","runtime_mean":53713.3,"runtime_std":18049.17478473739,"service":"brainlife/app-crop_reorient","__v":0},"gitinfo":{"desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","tags":[],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":464343.13,"runtime_std":3265360.1856333264,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf48ede14be11ff25d05c"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf48ede14be11ff25d05d"}],"examples":0,"groups":163},"create_date":"2018-10-12T18:04:17.247Z","doi":"10.25663/brainlife.app.114"},{"name":"Align T2 to ACPC Plane (HCP-based)","github":"brainlife/app-hcp-acpc-alignment","desc":"This app will align a T1w image to the ACPC plane (specifically, the MNI152_T1_1mm template from FSL using a 6 DOF alignment via FSL commands. This protocol was adapted from the HCP Preprocessing Pipeline (https://github.com/Washington-University/HCPpipelines.git). Requires a T1w image input and outputs an acpc_aligned T1w image.","stats":{"stars":1,"serviceinfo":{"_id":"5d729e1f78356a109788b29f","counts":{"_id":"5e5c3dc387cac75d4eab13d8","failed":259,"finished":6239,"removed":6417,"requested":7347,"running":6560,"running_sync":0,"stop_requested":264},"success_rate":96.01415820252386,"users":56,"readme_status":"ok","runtime_mean":1274538.2,"runtime_std":2614641.7180160973,"service":"brain-life/app-hcp-acpc-alignment","__v":0},"success_rate":87.43401733114742,"users":148,"runtime_mean":34232313.61,"runtime_std":84465148.88505387,"requested":99085,"resources":[],"examples":2,"groups":296},"create_date":"2018-10-12T19:06:56.774Z","doi":"10.25663/brainlife.app.116"},{"name":"Noddi Amico - Deprecated","github":"brainlife/app-noddi-amico","desc":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs) and an optional brainmask of the DWI. Will output the four NODDI output files: neurite density index (ndi), orientation dispersion index (odi), isotropic volume fraction (isovf), and the directions (dirs).","stats":{"stars":1,"requested":17952,"users":31,"success_rate":80.29782359679267,"serviceinfo":{"_id":"5d729e1f78356a109788b2ff","counts":{"_id":"5e5c3dc487cac7f6bdab13d9","failed":1432,"finished":3375,"removed":7983,"requested":8628,"running":4929,"running_sync":0,"stop_requested":178},"success_rate":70.21011025587684,"users":12,"readme_status":"ok","runtime_mean":7179274.96,"runtime_std":6595445.539946354,"service":"brain-life/app-noddi-amico","__v":0},"gitinfo":{"desc":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs), and the single shell dwi file that has been aligned to the subject's T1 (i.e. dtiinit output) as input. The app will align the multi-shell data to the single-shell data (if dtiinit was used for tracking; otherwise single shell data is not necessary) in order to assure that NODDI outputs are in the same space as the tensor outputs for later analyses. Will output the five NODDI output files: FIT_ICVF_NEW, FIT_OD_NEW, FIT_ISOVF_NEW, FIT_dir, and config.pickle.","tags":["postprocessing"],"stats":{"stars":1},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":5453700.08,"runtime_std":14494456.081946442,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf499de14be11ff25d179"}],"examples":0,"groups":61},"create_date":"2018-10-17T21:39:30.368Z","doi":"10.25663/brainlife.app.117"},{"name":"Compute SNR on Corpus Callosum","github":"brainlife/app-snr_in_cc","desc":"Brainlife.io app that computes the signal-to-noise ratio in the corpus callosum","stats":{"stars":1,"requested":6489,"users":11,"success_rate":54.428186368887175,"serviceinfo":{"_id":"5d729e1f78356a109788b277","counts":{"_id":"5e5c3dc587cac7e7f2ab13da","failed":789,"finished":3502,"removed":3901,"requested":4372,"running":4273,"running_sync":0,"stop_requested":11},"success_rate":81.61267769750641,"users":13,"readme_status":"ok","runtime_mean":274705.08,"runtime_std":341073.32374334644,"service":"davhunt/app-snr_in_cc","__v":0},"gitinfo":{"desc":"Brainlife.io app that computes the signal-to-noise ratio in the corpus callosum","tags":[],"stats":{"stars":1},"contributors":[{"name":"David Hunt","email":"davhunt@indiana.edu"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":17328848.99,"runtime_std":169048839.4389433,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf4a0de14be11ff25d339"}],"examples":3,"groups":21},"create_date":"2018-10-19T19:29:09.781Z","doi":"10.25663/brainlife.app.120"},{"name":"Network Matrices","github":"bcmcpher/app-networkmatrices","desc":"more flexible network app","stats":{"stars":1,"requested":20939,"users":37,"success_rate":85.72527050035701,"serviceinfo":{"_id":"5d729e1f78356a109788b287","counts":{"_id":"5e5c3dc687cac727ffab13db","failed":1480,"finished":12919,"removed":14506,"requested":15311,"running":13950,"running_sync":0,"stop_requested":42},"success_rate":89.72150843808598,"users":11,"readme_status":"too short","runtime_mean":4361727.83,"runtime_std":6852602.1100817975,"service":"bcmcpher/app-networkmatrices","__v":0},"gitinfo":{"desc":"more flexible network app","tags":[],"stats":{"stars":0},"contributors":[{"name":"Brent McPherson","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":5625229.72,"runtime_std":3786630.1376958624,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf4a6de14be11ff25d447"}],"examples":2,"groups":46},"create_date":"2018-10-22T15:42:34.499Z","doi":"10.25663/brainlife.app.121"},{"name":"Anatomically-informed multi-LAP (deprecated)","github":"giulia-berto/app-multi-lap-anat","desc":"White matter bundle segmentation as Anatomically-Informed multiple Linear Assignment Problems (multi-LAP-anat).","stats":{"stars":1,"serviceinfo":{"_id":"5d729e1f78356a109788b283","counts":{"_id":"5e5c3dc787cac77ccfab13dc","failed":150,"finished":806,"removed":741,"requested":1024,"running":982,"running_sync":0,"stop_requested":39},"success_rate":84.30962343096235,"users":1,"readme_status":"ok","runtime_mean":19688102.98,"runtime_std":11191394.632128878,"service":"giulia-berto/app-multi-lap-anat","__v":0},"gitinfo":{"desc":"White matter bundle segmentation as Anatomically-Informed multiple Linear Assignment Problems (multi-LAP-anat).","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"success_rate":83.97502601456816,"users":1,"runtime_mean":19616098.84,"runtime_std":11230532.48671157,"requested":1036,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf4abde14be11ff25d44c"}],"examples":0,"groups":4},"create_date":"2018-10-27T13:53:33.162Z","doi":"10.25663/brainlife.app.122"},{"name":"Resample tck","github":"giulia-berto/app-resample-tck","desc":"Code to resample a tck file with a give step size or number of points.","stats":{"stars":0,"requested":1192,"users":3,"success_rate":81.53380423814329,"serviceinfo":{"_id":"5d729e1f78356a109788b27b","counts":{"_id":"5e5c3dc887cac77901ab13dd","failed":174,"finished":616,"removed":801,"requested":928,"running":836,"running_sync":0,"stop_requested":52},"success_rate":77.9746835443038,"users":2,"readme_status":"no README.md","runtime_mean":294682.24,"runtime_std":138262.99233656997,"service":"giulia-berto/app-resample-tck","__v":0},"gitinfo":{"desc":"Code to resample a tck file with a give step size.","tags":[],"stats":{"stars":0},"contributors":[]},"runtime_mean":263805.13,"runtime_std":122656.52682655373,"resources":[],"examples":0,"groups":5},"create_date":"2018-11-02T11:59:30.127Z","doi":"10.25663/brainlife.app.124"},{"name":"WMC to TRK conversion and resample","github":"giulia-berto/app-convert-wmc2trk","desc":"Code to convert wmc to trk.","stats":{"stars":0,"requested":484,"users":1,"success_rate":93.95833333333333,"serviceinfo":{"_id":"5d729e1f78356a109788b281","counts":{"_id":"5e5c3dc887cac76244ab13de","failed":29,"finished":451,"removed":467,"requested":484,"running":483,"running_sync":0,"stop_requested":3},"success_rate":93.95833333333333,"users":1,"readme_status":"no README.md","runtime_mean":1976976,"runtime_std":2352177.4127568654,"service":"giulia-berto/app-convert-wmc2trk","__v":0},"gitinfo":{"desc":"Code to convert wmc to trk.","tags":[],"stats":{"stars":0},"contributors":[]},"runtime_mean":1976976,"runtime_std":2352177.4127568654,"resources":[],"examples":0,"groups":2},"create_date":"2018-11-02T14:58:32.501Z","doi":"10.25663/brainlife.app.125"},{"name":"Generate Equivolumetric Surfaces","github":"davhunt/surface_tools","desc":"Computes n equally spaced offset surfaces between the white and pial surfaces with equal ratios between areas of successive surfaces, which samples the same layers in gyri and sulci.","stats":{"stars":1,"requested":90,"users":3,"success_rate":33.33333333333333,"serviceinfo":{"_id":"5d729e1f78356a109788b26f","counts":{"_id":"5e5c3dc987cac76e25ab13df","failed":49,"finished":26,"removed":82,"requested":86,"running":76,"running_sync":0,"stop_requested":1},"success_rate":34.66666666666667,"users":3,"readme_status":"ok","runtime_mean":198971,"runtime_std":212886.16087097963,"service":"davhunt/surface_tools","__v":0},"gitinfo":{"desc":"Computes n equally spaced offset surfaces between the white and pial surfaces with equal ratios between areas of successive surfaces, which samples the same layers in gyri and sulci.","tags":[],"stats":{"stars":1},"contributors":[{"name":"David Hunt","email":"davhunt@indiana.edu"},{"name":null,"email":null},{"name":"Richard","email":null}]},"runtime_mean":198971,"runtime_std":212886.16087097963,"resources":[],"examples":0,"groups":5},"create_date":"2018-11-16T17:29:31.877Z","doi":"10.25663/brainlife.app.126"},{"name":"Convert wmc to multiple trk","github":"brainlife/app-wmctotrk","desc":"Convert a white matter classification (wmc) structure to a tractogram as a single trk file","stats":{"stars":0,"requested":9895,"users":12,"success_rate":26.120173446211027,"serviceinfo":{"_id":"5d729e1f78356a109788b267","counts":{"_id":"5e5c3dca87cac74394ab13e0","failed":258,"finished":2521,"removed":2717,"requested":2955,"running":2713,"running_sync":0,"stop_requested":23},"success_rate":90.71608492263404,"users":8,"readme_status":"ok","runtime_mean":143537.25,"runtime_std":65204.11269028588,"service":"brainlife/app-wmctotrk","__v":0},"gitinfo":{"desc":"Convert a white matter classification (wmc) structure to a tractogram as a single trk file","tags":["convert"],"stats":{"stars":0},"contributors":[{"name":"David Hunt","email":"davhunt@indiana.edu"},{"name":"Paolo Avesani","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":419381.53,"runtime_std":2228292.1456072563,"resources":[],"examples":1,"groups":12},"create_date":"2018-11-22T00:19:33.964Z","doi":"10.25663/brainlife.app.127"},{"name":"Track between multiple brain regions from atlas","github":"brainlife/app-track-between-multiple-regions","desc":null,"stats":{"stars":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1eb","counts":{"_id":"5e5c3dcb87cac73ad6ab13e1","failed":26,"finished":0,"removed":17,"requested":28,"running":28,"running_sync":0,"stop_requested":2},"success_rate":0,"users":5,"readme_status":"ok","service":"brainlife/app-ROIs2ROIStracking","__v":0},"gitinfo":{"desc":null,"tags":["tractography"],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null},{"name":"Ilaria Sani","email":"ila.gina@virgilio.it"}]},"success_rate":0,"users":2,"requested":6,"resources":[],"examples":0,"groups":2},"create_date":"2018-12-03T21:49:56.732Z","doi":"10.25663/brainlife.app.128"},{"name":"Convert wmc to trk","github":"brainlife/app-wmctotrk","desc":"Convert a white matter classification (wmc) structure to a tractogram as a single trk file","stats":{"stars":0,"requested":9895,"users":12,"success_rate":26.120173446211027,"serviceinfo":{"_id":"5d729e1f78356a109788b267","counts":{"_id":"5e5c3dcd87cac77665ab13e2","failed":258,"finished":2521,"removed":2717,"requested":2955,"running":2713,"running_sync":0,"stop_requested":23},"success_rate":90.71608492263404,"users":8,"readme_status":"ok","runtime_mean":143537.25,"runtime_std":65204.11269028588,"service":"brainlife/app-wmctotrk","__v":0},"gitinfo":{"desc":"Convert a white matter classification (wmc) structure to a tractogram as a single trk file","tags":["convert"],"stats":{"stars":0},"contributors":[{"name":"David Hunt","email":"davhunt@indiana.edu"},{"name":"Paolo Avesani","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":419381.53,"runtime_std":2228292.1456072563,"resources":[],"examples":0,"groups":12},"create_date":"2018-12-04T18:12:06.670Z","doi":"10.25663/brainlife.app.129"},{"name":"Segment tracts between multiple brain regions from atlas","github":"brainlife/app-segment-tracts-between-multiple-regions","desc":"Tract Segmentation from input tractography using ROIs","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1ed","counts":{"_id":"5e5c3dce87cac78ecdab13e3","failed":14,"finished":0,"removed":15,"requested":21,"running":17,"running_sync":0,"stop_requested":4},"success_rate":0,"users":2,"readme_status":"ok","service":"brainlife/app-segment-tracts-between-multiple-regions","__v":0},"gitinfo":{"desc":"Allows tracking between different regions of the brain.","tags":["diffusion-mri","segmentation","tractography"],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"success_rate":0,"users":6,"requested":34,"resources":[],"examples":0,"groups":6},"create_date":"2018-12-05T23:57:51.341Z","doi":"10.25663/brainlife.app.130"},{"name":"Convert tck to trk in DWI space","github":"brainlife/app-convert-tck-to-trk","desc":"Convert a tractogram in tck format to a trk format file","stats":{"stars":0,"requested":4446,"users":21,"success_rate":61.50558842866535,"serviceinfo":{"_id":"5d729e1f78356a109788b269","counts":{"_id":"5e5c3dcf87cac71b7fab13e4","failed":1151,"finished":1476,"removed":3587,"requested":3708,"running":2547,"running_sync":0,"stop_requested":27},"success_rate":56.18576322801675,"users":9,"readme_status":"ok","runtime_mean":569326.2,"runtime_std":2650461.83215067,"service":"brainlife/app-convert-tck-to-trk","__v":0},"gitinfo":{"desc":"Convert a tractogram in tck format to a trk format file","tags":["convert"],"stats":{"stars":0},"contributors":[{"name":"Paolo Avesani","email":null}]},"runtime_mean":2840609.76,"runtime_std":10877368.561151642,"resources":[],"examples":2,"groups":28},"create_date":"2018-12-07T18:07:34.180Z","doi":"10.25663/brainlife.app.132"},{"name":"Convert tck to trk in T1 space","github":"brainlife/app-convert-tck-to-trk","desc":"Convert a tractogram in tck format to a trk format file","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1f78356a109788b269","counts":{"_id":"5e5c3dd087cac73c86ab13e5","failed":1151,"finished":1476,"removed":3587,"requested":3708,"running":2547,"running_sync":0,"stop_requested":27},"success_rate":56.18576322801675,"users":9,"readme_status":"ok","runtime_mean":569326.2,"runtime_std":2650461.83215067,"service":"brainlife/app-convert-tck-to-trk","__v":0},"gitinfo":{"desc":"Convert a tractogram in tck format to a trk format file","tags":["convert"],"stats":{"stars":0},"contributors":[{"name":"Paolo Avesani","email":null}]},"success_rate":61.50558842866535,"users":21,"runtime_mean":2840609.76,"runtime_std":10877368.561151642,"requested":4446,"resources":[],"examples":0,"groups":28},"create_date":"2018-12-10T14:58:56.860Z","doi":"10.25663/brainlife.app.133"},{"name":"Track between multiple brain regions from ROI directory","github":"brainlife/app-track-between-multiple-regions","desc":null,"stats":{"stars":0,"requested":6,"users":2,"success_rate":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1eb","counts":{"_id":"5e5c3dd087cac7f87bab13e6","failed":26,"finished":0,"removed":17,"requested":28,"running":28,"running_sync":0,"stop_requested":2},"success_rate":0,"users":5,"readme_status":"ok","service":"brainlife/app-ROIs2ROIStracking","__v":0},"gitinfo":{"desc":null,"tags":["tractography"],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null},{"name":"Ilaria Sani","email":"ila.gina@virgilio.it"}]},"resources":[],"examples":0,"groups":2},"create_date":"2018-12-03T21:49:56.732Z","doi":"10.25663/brainlife.app.135"},{"name":"Segment tracts between multiple brain regions from ROI directory","github":"brainlife/app-segment-tracts-between-multiple-regions","desc":"Tract Segmentation from input tractography using ROIs","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1ed","counts":{"_id":"5e5c3dd287cac741e9ab13e7","failed":14,"finished":0,"removed":15,"requested":21,"running":17,"running_sync":0,"stop_requested":4},"success_rate":0,"users":2,"readme_status":"ok","service":"brainlife/app-segment-tracts-between-multiple-regions","__v":0},"gitinfo":{"desc":"Allows tracking between different regions of the brain.","tags":["diffusion-mri","segmentation","tractography"],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"success_rate":0,"users":6,"requested":34,"resources":[],"examples":0,"groups":6},"create_date":"2018-12-05T23:57:51.341Z","doi":"10.25663/brainlife.app.136"},{"name":"FSL DTIFIT - OLD","github":"brainlife/app-fslDTIFIT","desc":" This app will fit the diffusion tensor model (DTI) to a diffusion MRI image using FSL's dtifit commmand.","stats":{"stars":0,"requested":7990,"users":53,"success_rate":90.53836234687299,"serviceinfo":{"_id":"5d729e1f78356a109788b265","counts":{"_id":"5e5c3dd387cac7433dab13e8","failed":26,"finished":422,"removed":585,"requested":758,"running":455,"running_sync":0,"stop_requested":31},"success_rate":94.19642857142857,"users":11,"readme_status":"ok","runtime_mean":68459,"runtime_std":28634.25960593359,"service":"brainlife/app-fslDTIFIT","__v":0},"gitinfo":{"desc":" This app will fit the diffusion tensor model (DTI) to a diffusion MRI image using FSL's dtifit commmand.","tags":["diffusion-mri"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"runtime_mean":70382.66,"runtime_std":182924.66367880633,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf4edde14be11ff25d5f9"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf4edde14be11ff25d5fa"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf4edde14be11ff25d5fb"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf4edde14be11ff25d5fc"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf4edde14be11ff25d5fd"}],"examples":1,"groups":86},"create_date":"2018-12-21T22:20:40.172Z","doi":"10.25663/brainlife.app.137"},{"name":"Tractography quality check","github":"brainlife/app-tractographyQualityCheck","desc":"Compute many statistics from your input tractogram and any (optionally input) associated classification structure.  These statistics can be used to facilitate quality assurance on your tractography and segmentation, or as part of subject/group level quantative analysis for a research project. See the output section of README.MD for more details.","stats":{"stars":0,"requested":39939,"users":34,"success_rate":80.88005301524188,"serviceinfo":{"_id":"5d729e1f78356a109788b24f","counts":{"_id":"5e5c3dd487cac7e9c4ab13e9","failed":5766,"finished":9082,"removed":13663,"requested":16042,"running":10542,"running_sync":0,"stop_requested":343},"success_rate":61.166487068965516,"users":12,"readme_status":"ok","runtime_mean":8166187.08,"runtime_std":16929923.436678406,"service":"brainlife/app-tractographyQualityCheck","__v":0},"gitinfo":{"desc":"A quality check application for tractography, segmentatations, and LiFE structures","tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":32749303.59,"runtime_std":47565668.53729795,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf4f2de14be11ff25d601"}],"examples":0,"groups":75},"create_date":"2019-01-08T20:59:16.039Z","doi":"10.25663/brainlife.app.139"},{"name":"Generate ROIs from an atlas","github":"brainlife/app-ROIsfromAtlas","desc":null,"stats":{"stars":0,"requested":971,"users":14,"success_rate":88.79892037786774,"serviceinfo":{"_id":"5d729e1f78356a109788b253","counts":{"_id":"5e5c3dd587cac75d3eab13ea","failed":44,"finished":45,"removed":85,"requested":98,"running":93,"running_sync":0,"stop_requested":4},"success_rate":50.56179775280899,"users":6,"readme_status":"no README.md","runtime_mean":16224554.8,"runtime_std":32069300.72016451,"service":"brainlife/app-ROIsfromAtlas","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":8652688.48,"runtime_std":11883434.223251697,"resources":[],"examples":4,"groups":25},"create_date":"2019-01-09T19:37:21.715Z","doi":"10.25663/brainlife.app.140"},{"name":"Shape Signature","github":"soichih/app-shapesignature","desc":" This App takes tract masks and convert them to series of numerical values that chracaterizes each masks.  The numerical values are generated from the flattened output of 3D convolutional layers of the model trained to classify tract names. Output values could be used as a \"shape signature\" and compared against other similar shaped tracts.","stats":{"stars":0,"requested":29,"users":4,"success_rate":44.44444444444444,"serviceinfo":{"_id":"5d729e1f78356a109788b25b","counts":{"_id":"5e5c3dd587cac7564fab13eb","failed":12,"finished":9,"removed":8,"requested":21,"running":20,"running_sync":0,"stop_requested":0},"success_rate":42.857142857142854,"users":1,"readme_status":"ok","runtime_mean":123736.11111111111,"runtime_std":127565.68790796411,"service":"soichih/app-shapesignature","__v":0},"gitinfo":{"desc":" This App takes tract masks and convert them to series of numerical values that chracaterizes each masks.  The numerical values are generated from the flattened output of 3D convolutional layers of the model trained to classify tract names. Output values could be used as a \"shape signature\" and compared against other similar shaped tracts.","tags":[],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":130233.83333333333,"runtime_std":122727.6647621563,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf4fede14be11ff25d6d9"}],"examples":0,"groups":5},"create_date":"2019-01-10T21:05:19.896Z","doi":"10.25663/brainlife.app.141"},{"name":"Segment tractogram into fiber categories","github":"brainlife/app-streamlineCategorySegmentation","desc":"Automatically segment a tractogram into categories (i.e. fronto-parietal tracts, parieto-temporal tracts, etc). THIS APPLICATION IS HIGHLY RECOMMENDED AS A MEANS OF RUNNING AN INITIAL QUALITY ASSURANCE CHECK ON YOUR GENERATED TRACTOGRAPHY OR AS A SANITY CHECK ON PROBLEMATIC SEGMENTATIONS.","stats":{"stars":0,"requested":6317,"users":27,"success_rate":76.00512163892445,"serviceinfo":{"_id":"5d729e1f78356a109788b257","counts":{"_id":"5e5c3dd687cac737a4ab13ec","failed":630,"finished":2538,"removed":2930,"requested":3538,"running":3151,"running_sync":0,"stop_requested":76},"success_rate":80.11363636363636,"users":14,"readme_status":"ok","runtime_mean":4701550.01,"runtime_std":5896154.965123517,"service":"brainlife/app-streamlineCategorySegmentation","__v":0},"gitinfo":{"desc":"anatomy","tags":["anatomy","white-matter-segmentation"],"stats":{"stars":0},"contributors":[{"name":"Franco Pestilli","email":null},{"name":"Daniel Bullock","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Sophia Vinci-Booher","email":null}]},"runtime_mean":9626059.63,"runtime_std":20298759.815652583,"resources":[],"examples":0,"groups":36},"create_date":"2019-01-16T23:11:30.869Z","doi":"10.25663/brainlife.app.151"},{"name":"Align DWI to Dtiinit","github":"brainlife/app-dwiToDtiinit","desc":"This app will align DWI data to a DTIINIT DWI dataset in order to fit models that require multi-shell data to tracking","stats":{"stars":0,"requested":271,"users":2,"success_rate":96.66666666666667,"serviceinfo":{"_id":"5d729e1f78356a109788b259","counts":{"_id":"5e5c3ddc87cac76e42ab13ed","failed":1,"finished":43,"removed":44,"requested":44,"running":44,"running_sync":0,"stop_requested":0},"success_rate":97.72727272727273,"users":1,"readme_status":"ok","runtime_mean":461485.74418604653,"runtime_std":165362.0856416965,"service":"brainlife/app-dwiToDtiinit","__v":0},"gitinfo":{"desc":"This app will align DWI data to a DTIINIT DWI dataset in order to fit models that require multi-shell data to tracking","tags":["preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"runtime_mean":76730.02,"runtime_std":20387.570866084076,"resources":[],"examples":1,"groups":3},"create_date":"2019-01-29T17:05:25.561Z","doi":"10.25663/brainlife.app.153"},{"name":"ROI Generation (old)","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1f78356a109788b2b7","counts":{"_id":"5e5c3ddd87cac71c73ab13ee","failed":788,"finished":6048,"removed":7078,"requested":7656,"running":6617,"running_sync":0,"stop_requested":49},"success_rate":88.47279110590989,"users":12,"readme_status":"ok","runtime_mean":5580586.29,"runtime_std":23419021.556393724,"service":"brain-life/app-roiGenerator","__v":0},"gitinfo":{"desc":"This app will generate nifti files for specific ROIs, or every ROI, for a parcellation (either freesurfer or atlas).","tags":[],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"success_rate":83.53765323992994,"users":27,"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"requested":13134,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf50ede14be11ff25d798"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf50ede14be11ff25d799"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf50ede14be11ff25d79a"}],"examples":0,"groups":58},"create_date":"2019-02-01T23:39:05.808Z","doi":"10.25663/brainlife.app.154"},{"name":"FSL Top-up & Eddy","github":"brainlife/app-FSLTopupEddy","desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","stats":{"stars":0,"requested":3399,"users":24,"success_rate":58.620689655172406,"serviceinfo":{"_id":"5d729e1f78356a109788b251","counts":{"_id":"5e5c3dde87cac78efdab13ef","failed":27,"finished":181,"removed":241,"requested":276,"running":246,"running_sync":0,"stop_requested":42},"success_rate":87.01923076923077,"users":10,"readme_status":"ok","runtime_mean":9414714.88,"runtime_std":4859929.9095257055,"service":"brainlife/app-FSLTopupEddy","__v":0},"gitinfo":{"desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","tags":["preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"runtime_mean":5133032.47,"runtime_std":8164410.893760923,"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"642cf514de14be11ff25d7a5"}],"examples":1,"groups":45},"create_date":"2019-02-02T00:06:39.938Z","doi":"10.25663/brainlife.app.155"},{"name":"FSL Brain Extraction (BET) on T2","github":"brainlife/app-FSLBET","desc":"Brain Extraction via FSL's BET command","stats":{"stars":0,"requested":42857,"users":73,"success_rate":62.43668720054757,"serviceinfo":{"_id":"5d729e1f78356a109788b34b","counts":{"_id":"5e5c3ddf87cac7412dab13f0","failed":53,"finished":1853,"removed":1955,"requested":2015,"running":1928,"running_sync":0,"stop_requested":40},"success_rate":97.2193074501574,"users":33,"readme_status":"too short","runtime_mean":964048.19,"runtime_std":2048880.6264796087,"service":"brain-life/app-FSLBET","__v":0},"gitinfo":{"desc":"Brain Extraction via FSL's BET command","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":29685.56,"runtime_std":9501.90325073877,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf519de14be11ff25d7c3"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf519de14be11ff25d7c4"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf519de14be11ff25d7c5"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf519de14be11ff25d7c6"}],"examples":1,"groups":115},"create_date":"2019-02-04T22:08:32.862Z","doi":"10.25663/brainlife.app.156"},{"name":"Remove Tract Outliers","github":"brainlife/app-removeTractOutliers","desc":"This is a brainlife.io wrapper app for mbaComputeFibersOutliers algorithm. It takes an existing tract classification and prune classified fibers that are unlike other fibers within the same tract.","stats":{"stars":0,"requested":25084,"users":28,"success_rate":89.8527676601857,"serviceinfo":{"_id":"5d729e1e78356a109788b21f","counts":{"_id":"5e5c3ddf87cac74cbaab13f1","failed":157,"finished":5210,"removed":5514,"requested":5650,"running":5347,"running_sync":0,"stop_requested":66},"success_rate":97.074715856158,"users":6,"readme_status":"too short","runtime_mean":6928469.15,"runtime_std":7026262.31425993,"service":"brainlife/app-removeTractOutliers","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":5779644.26,"runtime_std":11803082.118968282,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf51ede14be11ff25d7ca"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf51ede14be11ff25d7cb"}],"examples":0,"groups":81},"create_date":"2019-02-05T18:56:37.235Z","doi":"10.25663/brainlife.app.157"},{"name":"Noddi Matlab","github":"brainlife/app-noddi-matlab","desc":null,"stats":{"stars":0,"requested":23,"users":4,"success_rate":0,"serviceinfo":{"_id":"5d729e1f78356a109788b24b","counts":{"_id":"5e5c3de087cac70757ab13f2","failed":11,"finished":0,"removed":17,"requested":23,"running":9,"running_sync":0,"stop_requested":3},"success_rate":0,"users":4,"readme_status":"too short","service":"brainlife/app-noddi-matlab","__v":0},"gitinfo":{"desc":null,"tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"resources":[],"examples":0,"groups":2},"create_date":"2019-02-06T04:09:03.498Z","doi":"10.25663/brainlife.app.158"},{"name":"fMRIPrep - Volume Output","github":"brainlife/app-fmriprep","desc":"fMRIPrep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting.","stats":{"stars":1,"requested":87343,"users":193,"success_rate":44.30148573311729,"serviceinfo":{"_id":"5d729e1e78356a109788b1d7","counts":{"_id":"5e5c3de287cac79fd6ab13f4","failed":345,"finished":893,"removed":868,"requested":1485,"running":1265,"running_sync":0,"stop_requested":90},"success_rate":72.13247172859451,"users":26,"readme_status":"ok","runtime_mean":8657706.8,"runtime_std":2072534.0096058971,"service":"brainlife/app-fmriprep","__v":0},"gitinfo":{"desc":"runs fmriprep for brainlife","tags":["brain","fmri","mri","preprocessing"],"stats":{"stars":1},"contributors":[{"name":"Josh Faskowitz","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":7291092.28,"runtime_std":4463267.395332778,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf52bde14be11ff25ddc1"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf52bde14be11ff25ddc2"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf52bde14be11ff25ddc3"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf52bde14be11ff25ddc4"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf52bde14be11ff25ddc5"}],"examples":5,"groups":378},"create_date":"2019-02-11T19:01:51.983Z","doi":"10.25663/brainlife.app.160"},{"name":"Convert brainmask from dtiinit","github":"brainlife/app-make-mask-from-dtiinit","desc":null,"stats":{"stars":0,"requested":77,"users":2,"success_rate":60.37735849056604,"serviceinfo":{"_id":"5d729e1f78356a109788b243","counts":{"_id":"5e5c3de387cac77701ab13f6","failed":3,"finished":20,"removed":46,"requested":47,"running":29,"running_sync":0,"stop_requested":5},"success_rate":86.95652173913044,"users":1,"readme_status":"too short","runtime_mean":458576.45,"runtime_std":293098.24109340453,"service":"brainlife/app-make-mask-from-dtiinit","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"runtime_mean":1230559.34375,"runtime_std":1839912.9367781356,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf530de14be11ff25ddcd"}],"examples":0,"groups":2},"create_date":"2019-02-13T03:41:16.567Z","doi":"10.25663/brainlife.app.162"},{"name":"FSL Brain Extraction (BET) on DWI","github":"brainlife/app-FSLBET","desc":"Brain Extraction via FSL's BET command","stats":{"stars":0,"requested":42857,"users":73,"success_rate":62.43668720054757,"serviceinfo":{"_id":"5d729e1f78356a109788b34b","counts":{"_id":"5e5c3de487cac760c9ab13f7","failed":53,"finished":1853,"removed":1955,"requested":2015,"running":1928,"running_sync":0,"stop_requested":40},"success_rate":97.2193074501574,"users":33,"readme_status":"too short","runtime_mean":964048.19,"runtime_std":2048880.6264796087,"service":"brain-life/app-FSLBET","__v":0},"gitinfo":{"desc":"Brain Extraction via FSL's BET command","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":29685.56,"runtime_std":9501.90325073877,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf538de14be11ff25e16c"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf538de14be11ff25e16d"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf538de14be11ff25e16e"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf538de14be11ff25e16f"}],"examples":5,"groups":115},"create_date":"2019-02-13T05:23:15.689Z","doi":"10.25663/brainlife.app.163"},{"name":"mrtrix3 act sift","github":"brainlife/app-mrtrix3-act","desc":"Runs mrtrix3 ACT (Anatomically Constrained Tractography) using either single- or multi-shell diffusion-weighted MRI data. ","stats":{"stars":0,"requested":17691,"users":58,"success_rate":49.32970902576142,"serviceinfo":{"_id":"5d729e1f78356a109788b299","counts":{"_id":"5e5c3de587cac71ef5ab13f8","failed":3479,"finished":10104,"removed":17081,"requested":19150,"running":13580,"running_sync":0,"stop_requested":1002},"success_rate":74.38710152396378,"users":26,"readme_status":"too short","runtime_mean":3527763.1,"runtime_std":2413346.823899846,"service":"brain-life/app-mrtrix3-act","__v":0},"gitinfo":{"desc":"Runs mrtrix3 ACT (Anatomically Constrained Tractography) using either single- or multi-shell diffusion-weighted MRI data. ","tags":["tracking","tractography"],"stats":{"stars":0},"contributors":[{"name":"Brent McPherson","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":11606863.4,"runtime_std":9971625.491358008,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf53dde14be11ff25e173"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf53dde14be11ff25e174"}],"examples":0,"groups":124},"create_date":"2019-02-15T20:09:39.357Z","doi":"10.25663/brainlife.app.166"},{"name":"fMRI to Connectivity Matrices","github":"faskowit/app-fmri-2-mat","desc":"fmriprep outputs to connectivity matrices ","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1d1","counts":{"_id":"5e5c3de687cac70678ab13f9","failed":65,"finished":409,"removed":327,"requested":541,"running":494,"running_sync":0,"stop_requested":28},"success_rate":86.28691983122363,"users":8,"readme_status":"ok","runtime_mean":814507.84,"runtime_std":1581039.47136238,"service":"faskowit/app-fmri-2-mat","__v":0},"gitinfo":{"desc":"fmriprep outputs to connectivity matrices ","tags":[],"stats":{"stars":0},"contributors":[{"name":"Josh Faskowitz","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"success_rate":54.54330055680606,"users":67,"runtime_mean":591949.28,"runtime_std":2744109.496301108,"requested":9537,"resources":[{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf545de14be11ff25e52a"}],"examples":5,"groups":97},"create_date":"2019-02-24T03:18:14.498Z","doi":"10.25663/brainlife.app.167"},{"name":"Attention ROI warp","github":"brainlife/VisWMROIWarp","desc":null,"stats":{"stars":0,"requested":591,"users":2,"success_rate":92.32081911262799,"serviceinfo":{"_id":"5d729e1f78356a109788b23f","counts":{"_id":"5e5c3de787cac709c6ab13fa","failed":45,"finished":541,"removed":540,"requested":591,"running":581,"running_sync":0,"stop_requested":0},"success_rate":92.32081911262799,"users":2,"readme_status":"no README.md","runtime_mean":33937525.85,"runtime_std":120381276.51463279,"service":"brainlife/VisWMROIWarp","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Ilaria Sani","email":"ila.gina@virgilio.it"}]},"runtime_mean":33937525.85,"runtime_std":120381276.51463279,"resources":[],"examples":0,"groups":2},"create_date":"2019-02-24T18:52:19.433Z","doi":"10.25663/brainlife.app.168"},{"name":"Warp ROIs from subject space to MNI space","github":"brainlife/app-subj2reference","desc":"This app warps your input set of ROIS to a reference space. As it is currently set up, the master branch of this app warps to MNI space.","stats":{"stars":0,"requested":8222,"users":3,"success_rate":92.16520650813517,"serviceinfo":{"_id":"5d729e1e78356a109788b21d","counts":{"_id":"5e5c3de887cac73417ab13fb","failed":200,"finished":5941,"removed":5982,"requested":6324,"running":5965,"running_sync":0,"stop_requested":7},"success_rate":96.74320143299137,"users":1,"readme_status":"no README.md","runtime_mean":350899991.56,"runtime_std":1365274067.2197254,"service":"brainlife/app-subj2reference","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null}]},"runtime_mean":11480175.27,"runtime_std":12104814.882031843,"resources":[],"examples":2,"groups":6},"create_date":"2019-02-24T22:24:37.125Z","doi":"10.25663/brainlife.app.169"},{"name":"wmaSeg - Giulia's patch","github":"giulia-berto/app-wmaSeg","desc":"Classifies streamlines into known anatomical tracts.","stats":{"stars":0,"requested":180,"users":1,"success_rate":57.446808510638306,"serviceinfo":{"_id":"5d729e1f78356a109788b23d","counts":{"_id":"5e5c3de987cac7c70fab13fc","failed":60,"finished":81,"removed":140,"requested":180,"running":149,"running_sync":0,"stop_requested":9},"success_rate":57.446808510638306,"users":1,"readme_status":"ok","runtime_mean":12844639.617283951,"runtime_std":1862573.1766037191,"service":"giulia-berto/app-wmaSeg","__v":0},"gitinfo":{"desc":"Classifies streamlines into known anatomical tracts.","tags":[],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lindsey Kitchell","email":null},{"name":"Franco Pestilli","email":null},{"name":"Steven O'Riley","email":null},{"name":"Daniel Bullock","email":null}]},"runtime_mean":12844639.617283951,"runtime_std":1862573.1766037191,"resources":[],"examples":0,"groups":1},"create_date":"2019-03-04T17:44:09.802Z","doi":"10.25663/brainlife.app.170"},{"name":"Peaks extraction with MRtrix","github":"giulia-berto/app-extract-peaks","desc":"App to extract the peaks of a spherical harmonic function at each voxel  using the MRtrix command sh2peaks.","stats":{"stars":0,"requested":165,"users":3,"success_rate":39.58333333333333,"serviceinfo":{"_id":"5d729e1e78356a109788b239","counts":{"_id":"5e5c3dec87cac73080ab13fe","failed":176,"finished":553,"removed":686,"requested":814,"running":788,"running_sync":0,"stop_requested":65},"success_rate":75.85733882030178,"users":1,"readme_status":"no README.md","runtime_mean":5070024.94,"runtime_std":1633575.6997710194,"service":"giulia-berto/app-compute-peaks","__v":0},"gitinfo":{"desc":"App to extract the peaks of a spherical harmonic function at each voxel.","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":11404663.684210526,"runtime_std":9146063.250029532,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf55cde14be11ff25e869"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf55cde14be11ff25e86a"}],"examples":2,"groups":5},"create_date":"2019-03-07T21:14:53.333Z","doi":"10.25663/brainlife.app.172"},{"name":"multi-LAP and multi-NN (deprecated)","github":"giulia-berto/app-multi-lap","desc":"White matter bundle segmentation as multiple Linear Assignment Problems (multi-LAP).","stats":{"stars":0,"requested":609,"users":1,"success_rate":79.14110429447852,"serviceinfo":{"_id":"5d729e1e78356a109788b22f","counts":{"_id":"5e5c3ded87cac790ddab13ff","failed":99,"finished":384,"removed":462,"requested":594,"running":499,"running_sync":0,"stop_requested":55},"success_rate":79.5031055900621,"users":1,"readme_status":"too short","runtime_mean":11729742.59,"runtime_std":6514231.5668496685,"service":"giulia-berto/app-multi-lap","__v":0},"gitinfo":{"desc":"White matter bundle segmentation as multiple Linear Assignment Problems (multi-LAP).","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":12036686.96,"runtime_std":8066802.534735993,"resources":[],"examples":0,"groups":3},"create_date":"2019-03-23T11:34:30.387Z","doi":"10.25663/brainlife.app.174"},{"name":"app-repeat-tracking","github":"bcmcpher/app-repeat-tracking","desc":"repeat of fixed parameters for OHBM 2019 submission","stats":{"stars":0,"requested":6155,"users":2,"success_rate":58.98962408572886,"serviceinfo":{"_id":"5d729e1e78356a109788b22b","counts":{"_id":"5e5c3ded87cac7c3a4ab1400","failed":2405,"finished":3464,"removed":4214,"requested":6145,"running":5357,"running_sync":0,"stop_requested":359},"success_rate":59.0219798943602,"users":2,"readme_status":"no README.md","runtime_mean":37910281.14,"runtime_std":19848677.144017108,"service":"bcmcpher/app-repeat-tracking","__v":0},"gitinfo":{"desc":"repeat of fixed parameters for OHBM 2019 submission","tags":[],"stats":{"stars":0},"contributors":[{"name":"Brent McPherson","email":null}]},"runtime_mean":38107838.32,"runtime_std":20075808.416652452,"resources":[{"resource_id":"5931bee335530000253833d2","name":"osgconnect","_id":"642cf567de14be11ff25e86f"}],"examples":0,"groups":3},"create_date":"2019-04-01T19:11:21.215Z","doi":"10.25663/brainlife.app.175"},{"name":"app-repeat-tracking-osg","github":"bcmcpher/app-repeat-tracking","desc":"repeat of fixed parameters for OHBM 2019 submission","stats":{"stars":0,"requested":6155,"users":2,"success_rate":58.98962408572886,"serviceinfo":{"_id":"5d729e1e78356a109788b22b","counts":{"_id":"5e5c3dee87cac7a751ab1401","failed":2405,"finished":3464,"removed":4214,"requested":6145,"running":5357,"running_sync":0,"stop_requested":359},"success_rate":59.0219798943602,"users":2,"readme_status":"no README.md","runtime_mean":37910281.14,"runtime_std":19848677.144017108,"service":"bcmcpher/app-repeat-tracking","__v":0},"gitinfo":{"desc":"repeat of fixed parameters for OHBM 2019 submission","tags":[],"stats":{"stars":0},"contributors":[{"name":"Brent McPherson","email":null}]},"runtime_mean":38107838.32,"runtime_std":20075808.416652452,"resources":[{"resource_id":"5931bee335530000253833d2","name":"osgconnect","_id":"642cf56cde14be11ff25e872"}],"examples":0,"groups":3},"create_date":"2019-04-04T20:11:30.433Z","doi":"10.25663/brainlife.app.176"},{"name":"AnalyzepRF on volume","github":"davhunt/app-analyzePRF","desc":null,"stats":{"stars":0,"requested":176,"users":4,"success_rate":62.22222222222222,"serviceinfo":{"_id":"5d729e1e78356a109788b225","counts":{"_id":"5e5c3dee87cac755dcab1402","failed":33,"finished":31,"removed":64,"requested":71,"running":63,"running_sync":0,"stop_requested":4},"success_rate":48.4375,"users":2,"readme_status":"ok","runtime_mean":43105379.87096774,"runtime_std":90548576.05385062,"service":"davhunt/app-analyzePRF","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"David Hunt","email":"davhunt@indiana.edu"},{"name":"Kendrick Kay","email":"kendrick@post.harvard.edu"}]},"runtime_mean":27308314.833333332,"runtime_std":64367789.480450355,"resources":[],"examples":1,"groups":4},"create_date":"2019-04-10T19:07:35.451Z","doi":"10.25663/brainlife.app.177"},{"name":"multi-LAP and multi-NN with trk","github":"giulia-berto/app-multi-lap","desc":"White matter bundle segmentation as multiple Linear Assignment Problems (multi-LAP).","stats":{"stars":0,"requested":609,"users":1,"success_rate":79.14110429447852,"serviceinfo":{"_id":"5d729e1e78356a109788b22f","counts":{"_id":"5e5c3def87cac7a9cbab1403","failed":99,"finished":384,"removed":462,"requested":594,"running":499,"running_sync":0,"stop_requested":55},"success_rate":79.5031055900621,"users":1,"readme_status":"too short","runtime_mean":11729742.59,"runtime_std":6514231.5668496685,"service":"giulia-berto/app-multi-lap","__v":0},"gitinfo":{"desc":"White matter bundle segmentation as multiple Linear Assignment Problems (multi-LAP).","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":12036686.96,"runtime_std":8066802.534735993,"resources":[],"examples":0,"groups":3},"create_date":"2019-04-11T11:13:41.649Z","doi":"10.25663/brainlife.app.179"},{"name":"ROC curve (deprecated)","github":"giulia-berto/app-plot-roc-curve","desc":null,"stats":{"stars":0,"requested":84,"users":2,"success_rate":70.37037037037037,"serviceinfo":{"_id":"5d729e1e78356a109788b221","counts":{"_id":"5e5c3df087cac7b042ab1404","failed":23,"finished":57,"removed":56,"requested":82,"running":82,"running_sync":0,"stop_requested":2},"success_rate":71.25,"users":1,"readme_status":"no README.md","runtime_mean":140748.50877192983,"runtime_std":183446.30834882264,"service":"giulia-berto/app-plot-roc-curve","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":140748.50877192983,"runtime_std":183446.30834882264,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf57bde14be11ff25e89e"}],"examples":0,"groups":2},"create_date":"2019-04-12T17:22:07.626Z","doi":"10.25663/brainlife.app.180"},{"name":"Generate tract endpoint maps","github":"brainlife/app-endpointMapGeneration","desc":"This app will generate endpoint maps for all tracts in an input classification structure.  User can specify what sort of decay/smoothing algorithm can be used (or none) and whether the output is to be normalized (e.g. max density voxel in tract endpoint mask = 1).","stats":{"stars":0,"requested":20514,"users":10,"success_rate":75.65422132526068,"serviceinfo":{"_id":"5d729e1e78356a109788b223","counts":{"_id":"5e5c3df087cac70df9ab1405","failed":1153,"finished":6909,"removed":8575,"requested":9022,"running":7857,"running_sync":0,"stop_requested":43},"success_rate":85.69833788141901,"users":5,"readme_status":"ok","runtime_mean":232893653.1,"runtime_std":1128125841.5110195,"service":"brainlife/app-endpointMapGeneration","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":2145912.31,"runtime_std":5242550.737893386,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf580de14be11ff25e8a1"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf580de14be11ff25e8a2"}],"examples":0,"groups":18},"create_date":"2019-04-16T21:41:54.126Z","doi":"10.25663/brainlife.app.182"},{"name":"app-repeat-network-osg","github":"bcmcpher/app-repeat-tracking","desc":"repeat of fixed parameters for OHBM 2019 submission","stats":{"stars":0,"requested":6155,"users":2,"success_rate":58.98962408572886,"serviceinfo":{"_id":"5d729e1e78356a109788b22b","counts":{"_id":"5e5c3df187cac73d17ab1406","failed":2405,"finished":3464,"removed":4214,"requested":6145,"running":5357,"running_sync":0,"stop_requested":359},"success_rate":59.0219798943602,"users":2,"readme_status":"no README.md","runtime_mean":37910281.14,"runtime_std":19848677.144017108,"service":"bcmcpher/app-repeat-tracking","__v":0},"gitinfo":{"desc":"repeat of fixed parameters for OHBM 2019 submission","tags":[],"stats":{"stars":0},"contributors":[{"name":"Brent McPherson","email":null}]},"runtime_mean":38107838.32,"runtime_std":20075808.416652452,"resources":[{"resource_id":"5931bee335530000253833d2","name":"osgconnect","_id":"642cf586de14be11ff25e8bf"}],"examples":1,"groups":3},"create_date":"2019-04-22T21:56:54.119Z","doi":"10.25663/brainlife.app.183"},{"name":"FSL Brain Extraction (BET) on fMRI","github":"brainlife/app-FSLBET","desc":"Brain Extraction via FSL's BET command","stats":{"stars":0,"requested":42857,"users":73,"success_rate":62.43668720054757,"serviceinfo":{"_id":"5d729e1f78356a109788b34b","counts":{"_id":"5e5c3df287cac70a68ab1407","failed":53,"finished":1853,"removed":1955,"requested":2015,"running":1928,"running_sync":0,"stop_requested":40},"success_rate":97.2193074501574,"users":33,"readme_status":"too short","runtime_mean":964048.19,"runtime_std":2048880.6264796087,"service":"brain-life/app-FSLBET","__v":0},"gitinfo":{"desc":"Brain Extraction via FSL's BET command","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":29685.56,"runtime_std":9501.90325073877,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf58bde14be11ff25e93b"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf58bde14be11ff25e93c"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf58bde14be11ff25e93d"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf58bde14be11ff25e93e"}],"examples":1,"groups":115},"create_date":"2019-04-24T14:59:17.875Z","doi":"10.25663/brainlife.app.184"},{"name":"Tract Analysis Profiles - Deprecated","github":"brainlife/app-tractanalysisprofiles","desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","stats":{"stars":1,"requested":19317,"users":42,"success_rate":77.25239616613419,"serviceinfo":{"_id":"5d729e1f78356a109788b2e3","counts":{"_id":"5e5c3df287cac714b6ab1408","failed":2993,"finished":18141,"removed":24430,"requested":27631,"running":20684,"running_sync":0,"stop_requested":275},"success_rate":85.83798618340114,"users":28,"readme_status":"ok","runtime_mean":254811.88,"runtime_std":243210.8932301463,"service":"brain-life/app-tractanalysisprofiles","__v":0},"gitinfo":{"desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":2138024.52,"runtime_std":9002049.390707558,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf590de14be11ff25e9c5"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf590de14be11ff25e9c6"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf590de14be11ff25e9c7"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf590de14be11ff25e9c8"}],"examples":1,"groups":90},"create_date":"2019-04-25T19:55:58.436Z","doi":"10.25663/brainlife.app.185"},{"name":"TractSeg","github":"brainlife/app-tractseg","desc":"Brainlife App for MIC-DKFZ/TractSeg. A tool for fast and accurate white matter bundle segmentation from Diffusion MRI using pretrained pytorch ML model.","stats":{"stars":0,"requested":18958,"users":75,"success_rate":72.25153595952295,"serviceinfo":{"_id":"5d729e1f78356a109788b297","counts":{"_id":"5e5c3df487cac70ffdab1409","failed":1970,"finished":3685,"removed":5706,"requested":6806,"running":5581,"running_sync":0,"stop_requested":277},"success_rate":65.16357206012378,"users":38,"readme_status":"ok","runtime_mean":7740929.19,"runtime_std":13531350.077703223,"service":"brainlife/app-tractseg","__v":0},"gitinfo":{"desc":"Brainlife App for MIC-DKFZ/TractSeg. A tool for fast and accurate white matter bundle segmentation from Diffusion MRI using pretrained pytorch ML model.","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lindsey Kitchell","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":3566537.1,"runtime_std":3455392.223018305,"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"642cf597de14be11ff25eb9e"},{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf597de14be11ff25eb9f"}],"examples":5,"groups":100},"create_date":"2019-04-27T03:31:05.108Z","doi":"10.25663/brainlife.app.186"},{"name":"pRFs / Benson14-Retinotopy - Deprecated","github":"davhunt/app-benson14-retinotopy","desc":"Brainlife.io app for Noah Benson's neuropythy library, retinotopy from T1 anatomy","stats":{"stars":1,"requested":4375,"users":37,"success_rate":89.41355674028941,"serviceinfo":{"_id":"5d729e1e78356a109788b217","counts":{"_id":"5e5c3df487cac70c8eab140a","failed":236,"finished":1075,"removed":1358,"requested":1514,"running":1340,"running_sync":0,"stop_requested":85},"success_rate":81.99847444698703,"users":7,"readme_status":"ok","runtime_mean":6119739.02,"runtime_std":32301530.45499196,"service":"davhunt/app-benson14-retinotopy","__v":0},"gitinfo":{"desc":"Brainlife.io app for Noah Benson's neuropythy library, retinotopy from T1 anatomy","tags":[],"stats":{"stars":1},"contributors":[{"name":"Noah C. Benson","email":"nben@nyu.edu"},{"name":"David Hunt","email":"davhunt@indiana.edu"},{"name":"Ariel Rokem","email":"arokem@gmail.com"},{"name":"Gio Piantoni","email":"github@gpiantoni.com"},{"name":"Michael Waskom","email":null}]},"runtime_mean":463545.55,"runtime_std":249080.80947312567,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf59dde14be11ff25ec60"}],"examples":2,"groups":54},"create_date":"2019-04-27T21:44:31.326Z","doi":"10.25663/brainlife.app.187"},{"name":"White Matter Anatomy Segmentation","github":"brainlife/app-wmaSeg","desc":"Classifies streamlines into known anatomical tracts.","stats":{"stars":1,"serviceinfo":{"_id":"5d729e1e78356a109788b20d","counts":{"_id":"5e5c3df687cac756adab140b","failed":3425,"finished":9221,"removed":16901,"requested":18537,"running":12116,"running_sync":0,"stop_requested":445},"success_rate":72.91633718171754,"users":20,"readme_status":"ok","runtime_mean":14985593.77,"runtime_std":3690815.7786162673,"service":"brainlife/app-wmaSeg","__v":0},"gitinfo":{"desc":"Classifies streamlines into known anatomical tracts.","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lindsey Kitchell","email":null},{"name":"Daniel Bullock","email":null},{"name":"Franco Pestilli","email":null},{"name":"Steven O'Riley","email":null}]},"success_rate":67.8864679640525,"users":59,"runtime_mean":8505411.39,"runtime_std":5350958.412636696,"requested":39843,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf5a9de14be11ff25f4fe"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf5a9de14be11ff25f4ff"}],"examples":5,"groups":131},"create_date":"2019-04-29T18:14:12.749Z","doi":"10.25663/brainlife.app.188"},{"name":"Tractography quality check","github":"brainlife/app-tractographyQualityCheck","desc":"Compute many statistics from your input tractogram and any (optionally input) associated classification structure.  These statistics can be used to facilitate quality assurance on your tractography and segmentation, or as part of subject/group level quantative analysis for a research project. See the output section of README.MD for more details.","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1f78356a109788b24f","counts":{"_id":"5e5c3df787cac742c9ab140c","failed":5766,"finished":9082,"removed":13663,"requested":16042,"running":10542,"running_sync":0,"stop_requested":343},"success_rate":61.166487068965516,"users":12,"readme_status":"ok","runtime_mean":8166187.08,"runtime_std":16929923.436678406,"service":"brainlife/app-tractographyQualityCheck","__v":0},"gitinfo":{"desc":"A quality check application for tractography, segmentatations, and LiFE structures","tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"success_rate":80.88005301524188,"users":34,"runtime_mean":32749303.59,"runtime_std":47565668.53729795,"requested":39939,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf5b8de14be11ff2600f7"}],"examples":5,"groups":75},"create_date":"2019-05-01T16:17:56.953Z","doi":"10.25663/brainlife.app.189"},{"name":"WMA Tract Segmentation with Atlas","github":"brainlife/app-segment-tracts-between-multiple-regions","desc":"Tract Segmentation from input tractography using ROIs","stats":{"stars":0,"requested":34,"users":6,"success_rate":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1ed","counts":{"_id":"5e5c3df887cac7a065ab140d","failed":14,"finished":0,"removed":15,"requested":21,"running":17,"running_sync":0,"stop_requested":4},"success_rate":0,"users":2,"readme_status":"ok","service":"brainlife/app-segment-tracts-between-multiple-regions","__v":0},"gitinfo":{"desc":"Allows tracking between different regions of the brain.","tags":["diffusion-mri","segmentation","tractography"],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"resources":[],"examples":0,"groups":6},"create_date":"2019-05-01T16:43:54.420Z","doi":"10.25663/brainlife.app.190"},{"name":"WMA Tract Segmentation with ROIs","github":"brainlife/app-segment-tracts-between-multiple-regions","desc":"Tract Segmentation from input tractography using ROIs","stats":{"stars":0,"requested":34,"users":6,"success_rate":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1ed","counts":{"_id":"5e5c3df987cac74531ab140e","failed":14,"finished":0,"removed":15,"requested":21,"running":17,"running_sync":0,"stop_requested":4},"success_rate":0,"users":2,"readme_status":"ok","service":"brainlife/app-segment-tracts-between-multiple-regions","__v":0},"gitinfo":{"desc":"Allows tracking between different regions of the brain.","tags":["diffusion-mri","segmentation","tractography"],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"resources":[],"examples":0,"groups":6},"create_date":"2019-05-01T16:49:58.345Z","doi":"10.25663/brainlife.app.191"},{"name":"Track between multiple brain regions from atlas (new wmc output)","github":"brainlife/app-track-between-multiple-regions","desc":null,"stats":{"stars":0,"requested":6,"users":2,"success_rate":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1eb","counts":{"_id":"5e5c3dfa87cac70f64ab140f","failed":26,"finished":0,"removed":17,"requested":28,"running":28,"running_sync":0,"stop_requested":2},"success_rate":0,"users":5,"readme_status":"ok","service":"brainlife/app-ROIs2ROIStracking","__v":0},"gitinfo":{"desc":null,"tags":["tractography"],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null},{"name":"Ilaria Sani","email":"ila.gina@virgilio.it"}]},"resources":[],"examples":0,"groups":2},"create_date":"2019-05-01T18:38:35.692Z","doi":"10.25663/brainlife.app.192"},{"name":"Track between multiple brain regions from ROI directory (new wmc output)","github":"brainlife/app-track-between-multiple-regions","desc":null,"stats":{"stars":0,"requested":6,"users":2,"success_rate":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1dd","counts":{"_id":"5e5c3dfc87cac7783fab1410","failed":5,"finished":0,"removed":3,"requested":5,"running":5,"running_sync":0,"stop_requested":0},"success_rate":0,"users":2,"readme_status":"ok","service":"brainlife/app-track-between-multiple-regions","__v":0},"gitinfo":{"desc":null,"tags":["tractography"],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null},{"name":"Ilaria Sani","email":"ila.gina@virgilio.it"}]},"resources":[],"examples":0,"groups":2},"create_date":"2019-05-01T18:40:12.855Z","doi":"10.25663/brainlife.app.193"},{"name":"Generate tract endpoint maps","github":"brainlife/app-endpointMapGeneration","desc":"This app will generate endpoint maps for all tracts in an input classification structure.  User can specify what sort of decay/smoothing algorithm can be used (or none) and whether the output is to be normalized (e.g. max density voxel in tract endpoint mask = 1).","stats":{"stars":0,"requested":20514,"users":10,"success_rate":75.65422132526068,"serviceinfo":{"_id":"5d729e1e78356a109788b223","counts":{"_id":"5e5c3dfd87cac7676fab1411","failed":1153,"finished":6909,"removed":8575,"requested":9022,"running":7857,"running_sync":0,"stop_requested":43},"success_rate":85.69833788141901,"users":5,"readme_status":"ok","runtime_mean":232893653.1,"runtime_std":1128125841.5110195,"service":"brainlife/app-endpointMapGeneration","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":2145912.31,"runtime_std":5242550.737893386,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf5d8de14be11ff260671"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf5d8de14be11ff260672"}],"examples":3,"groups":18},"create_date":"2019-05-01T18:51:00.197Z","doi":"10.25663/brainlife.app.194"},{"name":"Remove Tract Outliers","github":"brainlife/app-removeTractOutliers","desc":"This is a brainlife.io wrapper app for mbaComputeFibersOutliers algorithm. It takes an existing tract classification and prune classified fibers that are unlike other fibers within the same tract.","stats":{"stars":0,"requested":25084,"users":28,"success_rate":89.8527676601857,"serviceinfo":{"_id":"5d729e1e78356a109788b21f","counts":{"_id":"5e5c3dfd87cac77038ab1412","failed":157,"finished":5210,"removed":5514,"requested":5650,"running":5347,"running_sync":0,"stop_requested":66},"success_rate":97.074715856158,"users":6,"readme_status":"too short","runtime_mean":6928469.15,"runtime_std":7026262.31425993,"service":"brainlife/app-removeTractOutliers","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":5779644.26,"runtime_std":11803082.118968282,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf5e7de14be11ff2611dc"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf5e7de14be11ff2611dd"}],"examples":5,"groups":81},"create_date":"2019-05-01T18:59:44.993Z","doi":"10.25663/brainlife.app.195"},{"name":"White matter tracts statistics and quality control ","github":"brainlife/app-groupTractPlots","desc":null,"stats":{"stars":0,"requested":23,"users":4,"success_rate":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1e7","counts":{"_id":"5e5c3dfe87cac77a73ab1413","failed":22,"finished":0,"removed":5,"requested":22,"running":20,"running_sync":0,"stop_requested":0},"success_rate":0,"users":3,"readme_status":"no README.md","service":"brainlife/app-groupTractPlots","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null}]},"resources":[],"examples":0,"groups":3},"create_date":"2019-05-02T20:38:35.451Z","doi":"10.25663/brainlife.app.196"},{"name":"Remove First B0 (temp)","github":"brainlife/app-removeFirstB0","desc":null,"stats":{"stars":0,"requested":80,"users":2,"success_rate":100,"serviceinfo":{"_id":"5d729e1e78356a109788b20f","counts":{"_id":"5e5c3dff87cac738f9ab1414","failed":0,"finished":77,"removed":80,"requested":80,"running":77,"running_sync":0,"stop_requested":0},"success_rate":100,"users":2,"readme_status":"too short","runtime_mean":273422.97402597405,"runtime_std":205939.08727147238,"service":"brainlife/app-removeFirstB0","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"runtime_mean":273422.97402597405,"runtime_std":205939.08727147238,"resources":[],"examples":0,"groups":1},"create_date":"2019-05-07T18:19:20.302Z","doi":"10.25663/brainlife.app.197"},{"name":"Convert wmc-deprecated to wmc","github":"brainlife/app-convert-wmc2wmc","desc":"App to convert the old wmc-deprecated datatype to the new wmc datatype","stats":{"stars":0,"requested":1493,"users":4,"success_rate":98.26388888888889,"serviceinfo":{"_id":"5d729e1e78356a109788b207","counts":{"_id":"5e5c3e0087cac71ee9ab1416","failed":2,"finished":982,"removed":1254,"requested":1261,"running":991,"running_sync":0,"stop_requested":8},"success_rate":99.79674796747967,"users":3,"readme_status":"no README.md","runtime_mean":80080.4,"runtime_std":30559.238362563952,"service":"brainlife/app-convert-wmc2wmc","__v":0},"gitinfo":{"desc":"App to convert the old wmc-deprecated datatype to the new wmc datatype","tags":[],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":209618.79,"runtime_std":109550.99221251214,"resources":[],"examples":1,"groups":5},"create_date":"2019-05-20T20:23:54.331Z","doi":"10.25663/brainlife.app.201"},{"name":"ANTs tractogram registration in MNI space","github":"giulia-berto/app-ants-mni","desc":"ANTs transformation and tractogram registration in MNI space, using as the reference template the MNI152 T1 at 1.25 mm. WARNING: all the given inputs should be in the same anatomical space.","stats":{"stars":0,"requested":392,"users":8,"success_rate":77.74294670846395,"serviceinfo":{"_id":"5d729e1e78356a109788b205","counts":{"_id":"5e5c3e0187cac7d0f4ab1417","failed":64,"finished":191,"removed":174,"requested":261,"running":241,"running_sync":0,"stop_requested":0},"success_rate":74.90196078431373,"users":1,"readme_status":"no README.md","runtime_mean":1325627.87,"runtime_std":2061983.1164898155,"service":"giulia-berto/app-ants-mni","__v":0},"gitinfo":{"desc":"ANTs transformation based on T1 and tractogram registration in MNI space","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":1822201.34,"runtime_std":2410720.516909752,"resources":[],"examples":0,"groups":12},"create_date":"2019-05-23T22:08:52.761Z","doi":"10.25663/brainlife.app.202"},{"name":"TractSeg training","github":"FBK-NILab/TractSeg-BrainLife","desc":"Automatic White Matter Bundle Segmentation","stats":{"stars":0,"requested":687,"users":3,"success_rate":77.83687943262412,"serviceinfo":{"_id":"5d729e1e78356a109788b1f5","counts":{"_id":"5e5c3e0287cac7447eab1419","failed":123,"finished":333,"removed":418,"requested":577,"running":517,"running_sync":0,"stop_requested":84},"success_rate":73.02631578947368,"users":3,"readme_status":"no README.md","runtime_mean":102083.93,"runtime_std":68121.49101498806,"service":"FBK-NILab/TractSeg-BrainLife","__v":0},"gitinfo":{"desc":"Automatic White Matter Bundle Segmentation","tags":[],"stats":{"stars":0},"contributors":[{"name":"Jakob Wasserthal","email":null},{"name":null,"email":null},{"name":"Pietro Astolfi","email":"pietroastolfi92@gmail.com"},{"name":"Matthias Greiner","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":248676.14,"runtime_std":140231.90157371605,"resources":[],"examples":0,"groups":3},"create_date":"2019-05-30T16:43:45.226Z","doi":"10.25663/brainlife.app.204"},{"name":"TractSeg test","github":"FBK-NILab/TractSeg-BrainLife","desc":"Automatic White Matter Bundle Segmentation","stats":{"stars":0,"requested":687,"users":3,"success_rate":77.83687943262412,"serviceinfo":{"_id":"5d729e1e78356a109788b1f5","counts":{"_id":"5e5c3e0387cac7d5a9ab141a","failed":123,"finished":333,"removed":418,"requested":577,"running":517,"running_sync":0,"stop_requested":84},"success_rate":73.02631578947368,"users":3,"readme_status":"no README.md","runtime_mean":102083.93,"runtime_std":68121.49101498806,"service":"FBK-NILab/TractSeg-BrainLife","__v":0},"gitinfo":{"desc":"Automatic White Matter Bundle Segmentation","tags":[],"stats":{"stars":0},"contributors":[{"name":"Jakob Wasserthal","email":null},{"name":null,"email":null},{"name":"Pietro Astolfi","email":"pietroastolfi92@gmail.com"},{"name":"Matthias Greiner","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":248676.14,"runtime_std":140231.90157371605,"resources":[],"examples":1,"groups":3},"create_date":"2019-05-30T16:54:17.360Z","doi":"10.25663/brainlife.app.205"},{"name":"AFQ Tract Classification with LiFE","github":"brainlife/app-tractclassification","desc":"This service uses Automated fiber quantification AFQ and fe structure output from LiFE to identify major tract segments and quantify tissue properties along their trajectories. You can choose to have the zero weighted fibers (as determined by LiFE) removed before or after AFQ is applied. useinterhemisphericsplit is a variable from AFQ, which if set to true will cut fibers crossing between hemispheres with a midsaggital plane below z=-10. This is to get rid of CST fibers that appear to cross at the level of the brainstem. For more information about AFQ see https://github.com/yeatmanlab/AFQ/wiki","stats":{"stars":0,"requested":3423,"users":33,"success_rate":49.98354721948009,"serviceinfo":{"_id":"5d729e1e78356a109788b21b","counts":{"_id":"5e5c3e0487cac7a1ccab141b","failed":352,"finished":255,"removed":787,"requested":809,"running":280,"running_sync":0,"stop_requested":22},"success_rate":42.00988467874794,"users":21,"readme_status":"too short","runtime_mean":4841074.02,"runtime_std":6487919.963962646,"service":"brainlife/app-tractclassification","__v":0},"gitinfo":{"desc":"This service uses Automated fiber quantification AFQ and fe structure output from LiFE to identify major tract segments and quantify tissue properties along their trajectories. You can choose to have the zero weighted fibers (as determined by LiFE) removed before or after AFQ is applied. useinterhemisphericsplit is a variable from AFQ, which if set to true will cut fibers crossing between hemispheres with a midsaggital plane below z=-10. This is to get rid of CST fibers that appear to cross at the level of the brainstem. For more information about AFQ see https://github.com/yeatmanlab/AFQ/wiki","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Steven O'Riley","email":null}]},"runtime_mean":506468.95,"runtime_std":549388.260618688,"resources":[],"examples":2,"groups":27},"create_date":"2019-06-05T20:25:10.787Z","doi":"10.25663/brainlife.app.206"},{"name":"AFQ Tract Classification","github":"brainlife/app-tractclassification","desc":"This service uses Automated fiber quantification AFQ and fe structure output from LiFE to identify major tract segments and quantify tissue properties along their trajectories. You can choose to have the zero weighted fibers (as determined by LiFE) removed before or after AFQ is applied. useinterhemisphericsplit is a variable from AFQ, which if set to true will cut fibers crossing between hemispheres with a midsaggital plane below z=-10. This is to get rid of CST fibers that appear to cross at the level of the brainstem. For more information about AFQ see https://github.com/yeatmanlab/AFQ/wiki","stats":{"stars":0,"requested":3423,"users":33,"success_rate":49.98354721948009,"serviceinfo":{"_id":"5d729e1e78356a109788b21b","counts":{"_id":"5e5c3e0587cac70210ab141c","failed":352,"finished":255,"removed":787,"requested":809,"running":280,"running_sync":0,"stop_requested":22},"success_rate":42.00988467874794,"users":21,"readme_status":"too short","runtime_mean":4841074.02,"runtime_std":6487919.963962646,"service":"brainlife/app-tractclassification","__v":0},"gitinfo":{"desc":"This service uses Automated fiber quantification AFQ and fe structure output from LiFE to identify major tract segments and quantify tissue properties along their trajectories. You can choose to have the zero weighted fibers (as determined by LiFE) removed before or after AFQ is applied. useinterhemisphericsplit is a variable from AFQ, which if set to true will cut fibers crossing between hemispheres with a midsaggital plane below z=-10. This is to get rid of CST fibers that appear to cross at the level of the brainstem. For more information about AFQ see https://github.com/yeatmanlab/AFQ/wiki","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Steven O'Riley","email":null}]},"runtime_mean":506468.95,"runtime_std":549388.260618688,"resources":[],"examples":0,"groups":27},"create_date":"2019-06-05T20:26:22.330Z","doi":"10.25663/brainlife.app.207"},{"name":"rsHRF","github":"brainlife/app-rsHRF","desc":"Hemodynamic Response Function Retrieval and Deconvolution (RS-HRF)","stats":{"stars":0,"requested":95,"users":9,"success_rate":64.28571428571429,"serviceinfo":{"_id":"5d729e1e78356a109788b1e5","counts":{"_id":"5e5c3e0687cac72726ab141d","failed":22,"finished":49,"removed":50,"requested":74,"running":73,"running_sync":0,"stop_requested":2},"success_rate":69.01408450704226,"users":6,"readme_status":"ok","runtime_mean":3654761.5714285714,"runtime_std":4487192.076110282,"service":"brainlife/app-rsHRF","__v":0},"gitinfo":{"desc":"Hemodynamic Response Function Retrieval and Deconvolution (RS-HRF)","tags":[],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":6322722.12962963,"runtime_std":12536752.285248613,"resources":[],"examples":0,"groups":10},"create_date":"2019-06-06T18:15:11.483Z","doi":"10.25663/brainlife.app.208"},{"name":"multi-LAP","github":"giulia-berto/app-multi-lap","desc":"White matter bundle segmentation as multiple Linear Assignment Problems (multi-LAP).","stats":{"stars":0,"requested":609,"users":1,"success_rate":79.14110429447852,"serviceinfo":{"_id":"5d729e1e78356a109788b22f","counts":{"_id":"5e5c3e0787cac79650ab141e","failed":99,"finished":384,"removed":462,"requested":594,"running":499,"running_sync":0,"stop_requested":55},"success_rate":79.5031055900621,"users":1,"readme_status":"too short","runtime_mean":11729742.59,"runtime_std":6514231.5668496685,"service":"giulia-berto/app-multi-lap","__v":0},"gitinfo":{"desc":"White matter bundle segmentation as multiple Linear Assignment Problems (multi-LAP).","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":12036686.96,"runtime_std":8066802.534735993,"resources":[],"examples":0,"groups":3},"create_date":"2019-06-27T12:52:22.265Z","doi":"10.25663/brainlife.app.209"},{"name":"multi-LAP with trk","github":"giulia-berto/app-multi-lap","desc":"White matter bundle segmentation as multiple Linear Assignment Problems (multi-LAP).","stats":{"stars":0,"requested":609,"users":1,"success_rate":79.14110429447852,"serviceinfo":{"_id":"5d729e1e78356a109788b22f","counts":{"_id":"5e5c3e0887cac71284ab141f","failed":99,"finished":384,"removed":462,"requested":594,"running":499,"running_sync":0,"stop_requested":55},"success_rate":79.5031055900621,"users":1,"readme_status":"too short","runtime_mean":11729742.59,"runtime_std":6514231.5668496685,"service":"giulia-berto/app-multi-lap","__v":0},"gitinfo":{"desc":"White matter bundle segmentation as multiple Linear Assignment Problems (multi-LAP).","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":12036686.96,"runtime_std":8066802.534735993,"resources":[],"examples":0,"groups":3},"create_date":"2019-07-04T16:48:35.581Z","doi":"10.25663/brainlife.app.210"},{"name":"DSC evaluation (wmc - trk)","github":"giulia-berto/app-compute-dsc4hcp","desc":"Compute the degree of overlap between two bundle masks using the Dice Similarity Coefficient (DSC) score.","stats":{"stars":0,"requested":929,"users":1,"success_rate":90.37433155080214,"serviceinfo":{"_id":"5d729e1f78356a109788b2f3","counts":{"_id":"5e5c3e0887cac79dd2ab1420","failed":69,"finished":676,"removed":739,"requested":926,"running":792,"running_sync":0,"stop_requested":45},"success_rate":90.73825503355705,"users":1,"readme_status":"too short","runtime_mean":638839.76,"runtime_std":456262.49373193324,"service":"giulia-berto/app-compute-dsc4hcp","__v":0},"gitinfo":{"desc":"Compute the Dice Similarity Coefficient (DSC) between corresponding tracts of the given segmentation and the ground truth when using HCP data.","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":638839.76,"runtime_std":456262.49373193324,"resources":[],"examples":0,"groups":3},"create_date":"2019-07-11T15:39:07.765Z","doi":"10.25663/brainlife.app.211"},{"name":"DSC evaluation (mask - mask)","github":"giulia-berto/app-compute-dsc","desc":"Compute the degree of overlap between two bundle masks using the Dice Similarity Coefficient (DSC) score.","stats":{"stars":0,"requested":334,"users":2,"success_rate":89.58990536277602,"serviceinfo":{"_id":"5d729e1f78356a109788b2f3","counts":{"_id":"5e5c3e0987cac7ea51ab1421","failed":69,"finished":676,"removed":739,"requested":926,"running":792,"running_sync":0,"stop_requested":45},"success_rate":90.73825503355705,"users":1,"readme_status":"too short","runtime_mean":638839.76,"runtime_std":456262.49373193324,"service":"giulia-berto/app-compute-dsc4hcp","__v":0},"gitinfo":{"desc":"Compute the Dice Similarity Coefficient (DSC) between corresponding tracts of the given segmentation and the ground truth when using HCP data.","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":244853.76,"runtime_std":174748.75208854116,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf62ede14be11ff261492"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf62ede14be11ff261493"}],"examples":0,"groups":5},"create_date":"2019-07-12T12:53:11.189Z","doi":"10.25663/brainlife.app.212"},{"name":"Trekker - v1.0","github":"brainlife/app-trekker","desc":"Brainlife App (wrapper) for dMRI based fiber tracking using parallel transport tractography https://dmritrekker.github.io","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1ef","counts":{"_id":"5e5c3e0b87cac74b8dab1423","failed":20,"finished":46,"removed":62,"requested":80,"running":77,"running_sync":0,"stop_requested":11},"success_rate":69.6969696969697,"users":7,"readme_status":"ok","runtime_mean":8788731.347826088,"runtime_std":10752209.709381515,"service":"brainlife/app-trekker","__v":0},"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking using parallel transport tractography https://dmritrekker.github.io","tags":[],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"success_rate":62.55144032921811,"users":11,"runtime_mean":37888004.83,"runtime_std":23561585.448650327,"requested":342,"resources":[],"examples":0,"groups":12},"create_date":"2019-07-17T05:09:56.759Z","doi":"10.25663/brainlife.app.214"},{"name":"Nobrainer - BrainParcellation","github":"brainlife/app-nobrainer","desc":"brainlife wrapper for https://github.com/neuronets/kwyk -Bayesian Neural Network for brain parcellation and uncertainty estimation. ","stats":{"stars":2,"serviceinfo":{"_id":"5d729e1e78356a109788b1df","counts":{"_id":"5e5c3e0c87cac7ddd4ab1424","failed":30,"finished":22,"removed":45,"requested":58,"running":47,"running_sync":0,"stop_requested":3},"success_rate":42.30769230769231,"users":6,"readme_status":"ok","runtime_mean":4506876.7727272725,"runtime_std":5949601.183849483,"service":"ngoyal95/kwyk_neuronet","__v":0},"gitinfo":{"desc":"This App uses a pretrained deep neural network to predict FreeSurfer segmentations in minutes. The network was trained and evaluated on a large dataset (n = 11,148) obtained by combining data from more than a hundred sites. This App also produces the prediction uncertainty of the network at each voxel using two different uncertainty measures (entropy and variance). For more information please read https://arxiv.org/abs/1812.01719.","tags":["segmentation"],"stats":{"stars":1},"contributors":[{"name":"Jakub Kaczmarzyk","email":"jakub.kaczmarzyk@gmail.com"},{"name":"john lee","email":null},{"name":"Nikhil Goyal","email":"nikhil.r.goyal@gmail.com"},{"name":"Satrajit Ghosh","email":null},{"name":"Patrick McClure","email":null},{"name":null,"email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"success_rate":0.055643141982750624,"users":6,"runtime_mean":957431.3333333334,"runtime_std":1267734.1566918604,"requested":10833,"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"642cf639de14be11ff2614d1"}],"examples":0,"groups":7},"create_date":"2019-08-14T18:44:21.295Z","doi":"10.25663/brainlife.app.218"},{"name":"mergeTCK","github":"svincibo/app-mergeTCK","desc":"Merge multiple TCK files into one TCK file.","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1d5","counts":{"_id":"5e5c3e0e87cac716c2ab1425","failed":7,"finished":21,"removed":18,"requested":31,"running":31,"running_sync":0,"stop_requested":3},"success_rate":75,"users":3,"readme_status":"ok","runtime_mean":204854.38095238095,"runtime_std":76518.54276577497,"service":"svincibo/app-mergeTCK","__v":0},"gitinfo":{"desc":"Merge multiple TCK files into one TCK file.","tags":[],"stats":{"stars":0},"contributors":[{"name":"Sophia Vinci-Booher","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":78.48101265822784,"users":4,"runtime_mean":783905.6935483871,"runtime_std":2803960.445063879,"requested":86,"resources":[],"examples":0,"groups":11},"create_date":"2019-08-20T17:13:05.780Z","doi":"10.25663/brainlife.app.219"},{"name":"Segment thalamic nuclei","github":"brainlife/app-segment-thalamic-nuclei","desc":"This app will segment the thalamus into its multiple components using the developer version of Freesurfer's segmentThalamicNuclei.sh function (http://freesurfer.net/fswiki/ThalamicNuclei). This app takes a Freesurfer segmentation in as an input and generates .mgz files with the appropriate thalamic segmentation inside the Freesurfer directory as an output.","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1db","counts":{"_id":"5e5c3e1087cac76e98ab1427","failed":106,"finished":926,"removed":1403,"requested":1479,"running":985,"running_sync":0,"stop_requested":15},"success_rate":89.72868217054264,"users":5,"readme_status":"ok","runtime_mean":1950079.2,"runtime_std":1938600.008409801,"service":"brainlife/app-segment-thalamic-nuclei","__v":0},"gitinfo":{"desc":"This app will segment the thalamus into its multiple components using the developer version of Freesurfer's segmentThalamicNuclei.sh function (http://freesurfer.net/fswiki/ThalamicNuclei). This app takes a Freesurfer segmentation in as an input and generates .mgz files with the appropriate thalamic segmentation inside the Freesurfer directory as an output.","tags":["analysis","anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"success_rate":91.83818310858764,"users":19,"runtime_mean":1935732.3,"runtime_std":3375213.611408445,"requested":4567,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf644de14be11ff2615de"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf644de14be11ff2615df"}],"examples":5,"groups":34},"create_date":"2019-08-24T05:12:17.413Z","doi":"10.25663/brainlife.app.222"},{"name":"ROI Generation (thalamic nuclei)","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1f78356a109788b2b7","counts":{"_id":"5e5c3e1187cac7d75fab1428","failed":788,"finished":6048,"removed":7078,"requested":7656,"running":6617,"running_sync":0,"stop_requested":49},"success_rate":88.47279110590989,"users":12,"readme_status":"ok","runtime_mean":5580586.29,"runtime_std":23419021.556393724,"service":"brain-life/app-roiGenerator","__v":0},"gitinfo":{"desc":"This app will generate nifti files for specific ROIs, or every ROI, for a parcellation (either freesurfer or atlas).","tags":[],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"success_rate":83.53765323992994,"users":27,"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"requested":13134,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf64ade14be11ff261607"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf64ade14be11ff261608"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf64ade14be11ff261609"}],"examples":0,"groups":58},"create_date":"2019-08-24T05:36:56.074Z","doi":"10.25663/brainlife.app.223"},{"name":"Track the Human Optic RAdiation (THORA) - Trekker","github":"brainlife/app-trekker-roi-tracking","desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1e3","counts":{"_id":"5e5c3e1387cac7bdc0ab142a","failed":112,"finished":147,"removed":309,"requested":392,"running":302,"running_sync":0,"stop_requested":65},"success_rate":56.75675675675676,"users":7,"readme_status":"ok","runtime_mean":18540062.42,"runtime_std":10967451.73775354,"service":"brainlife/app-trekker-roi-tracking","__v":0},"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":45.722171113155476,"users":16,"runtime_mean":36733933.86,"runtime_std":20438070.958943717,"requested":6027,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf650de14be11ff2616f6"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf650de14be11ff2616f7"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf650de14be11ff2616f8"}],"examples":1,"groups":27},"create_date":"2019-08-27T20:45:00.120Z","doi":"10.25663/brainlife.app.226"},{"name":"Anatomically-informed multi-LAP","github":"giulia-berto/app-multi-lap-anat","desc":"White matter bundle segmentation as Anatomically-Informed multiple Linear Assignment Problems (multi-LAP-anat).","stats":{"stars":1,"serviceinfo":{"_id":"5d729e1f78356a109788b283","counts":{"_id":"5e5c3e1387cac75940ab142b","failed":150,"finished":806,"removed":741,"requested":1024,"running":982,"running_sync":0,"stop_requested":39},"success_rate":84.30962343096235,"users":1,"readme_status":"ok","runtime_mean":19688102.98,"runtime_std":11191394.632128878,"service":"giulia-berto/app-multi-lap-anat","__v":0},"gitinfo":{"desc":"White matter bundle segmentation as Anatomically-Informed multiple Linear Assignment Problems (multi-LAP-anat).","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"success_rate":83.97502601456816,"users":1,"runtime_mean":19616098.84,"runtime_std":11230532.48671157,"requested":1036,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf656de14be11ff2616fc"}],"examples":0,"groups":4},"create_date":"2019-09-04T10:26:40.524Z","doi":"10.25663/brainlife.app.227"},{"name":"Classifyber","github":"FBK-NILab/app-classifyber","desc":"Linear classification of single streamlines.","stats":{"stars":2,"serviceinfo":{"_id":"5e3b5bba3b3f0a0c99d7d0a2","counts":{"_id":"5e5c3e1487cac7ec9aab142c","failed":30,"finished":30,"removed":3,"requested":84,"running":85,"running_sync":0,"stop_requested":24},"success_rate":50,"users":1,"readme_status":"ok","service":"FBK-NILab/app-classifyber","__v":0,"runtime_mean":22420538.133333333,"runtime_std":20062322.87835786},"gitinfo":{"desc":"Linear classification of single streamlines.","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"success_rate":46.26865671641791,"users":4,"runtime_mean":23490576.48387097,"runtime_std":20587921.063224338,"requested":94,"resources":[],"examples":0,"groups":4},"create_date":"2019-09-04T14:32:04.629Z","doi":"10.25663/brainlife.app.228"},{"name":"NODDI Amico (single shell) - Deprecated","github":"brainlife/app-noddi-amico","desc":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs) and an optional brainmask of the DWI. Will output the four NODDI output files: neurite density index (ndi), orientation dispersion index (odi), isotropic volume fraction (isovf), and the directions (dirs).","stats":{"stars":1,"serviceinfo":{"_id":"5d729e1f78356a109788b2ff","counts":{"_id":"5e5c3e1587cac77fc5ab142d","failed":1432,"finished":3375,"removed":7983,"requested":8628,"running":4929,"running_sync":0,"stop_requested":178},"success_rate":70.21011025587684,"users":12,"readme_status":"ok","runtime_mean":7179274.96,"runtime_std":6595445.539946354,"service":"brain-life/app-noddi-amico","__v":0},"success_rate":80.29782359679267,"users":31,"runtime_mean":5453700.08,"runtime_std":14494456.081946442,"requested":17952,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf660de14be11ff261701"}],"examples":0,"groups":61},"create_date":"2019-09-10T22:03:44.769Z","doi":"10.25663/brainlife.app.229"},{"name":"Convert wmc to trk","github":"brainlife/app-wmctotrk","desc":"Convert a white matter classification (wmc) structure to a tractogram as a single trk file","stats":{"stars":0,"requested":9895,"users":12,"success_rate":26.120173446211027,"serviceinfo":{"_id":"5d729e1f78356a109788b267","counts":{"_id":"5e5c3e1787cac72f19ab142f","failed":258,"finished":2521,"removed":2717,"requested":2955,"running":2713,"running_sync":0,"stop_requested":23},"success_rate":90.71608492263404,"users":8,"readme_status":"ok","runtime_mean":143537.25,"runtime_std":65204.11269028588,"service":"brainlife/app-wmctotrk","__v":0},"gitinfo":{"desc":"Convert a white matter classification (wmc) structure to a tractogram as a single trk file","tags":["convert"],"stats":{"stars":0},"contributors":[{"name":"David Hunt","email":"davhunt@indiana.edu"},{"name":"Paolo Avesani","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":419381.53,"runtime_std":2228292.1456072563,"resources":[],"examples":0,"groups":12},"create_date":"2019-09-24T04:14:06.432Z","doi":"10.25663/brainlife.app.231"},{"name":"Bundle segmented tracks by eccentricity - Deprecated","github":"brainlife/app-eccentricity-classification","desc":null,"stats":{"stars":0,"serviceinfo":{"_id":"5d953e85978f7c1dd0300e9a","counts":{"_id":"5e5c3e1887cac71536ab1430","failed":4,"finished":1,"removed":7,"requested":8,"running":7,"running_sync":0,"stop_requested":2},"success_rate":20,"users":1,"readme_status":"too short","runtime_mean":1288773,"runtime_std":0,"service":"brainlife/app-eccentricity-classification","__v":0},"success_rate":72.15189873417721,"users":1,"runtime_mean":845065.18,"runtime_std":765765.3651332945,"requested":301,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf66bde14be11ff26176d"}],"examples":0,"groups":3},"create_date":"2019-10-02T02:32:23.325Z","doi":"10.25663/brainlife.app.232"},{"name":"Track The Human Optic RAdiation (THORA): Trekker - Eccentricity","github":"brainlife/app-trekker-roi-tracking","desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1e3","counts":{"_id":"5e5c3e1987cac7be13ab1431","failed":112,"finished":147,"removed":309,"requested":392,"running":302,"running_sync":0,"stop_requested":65},"success_rate":56.75675675675676,"users":7,"readme_status":"ok","runtime_mean":18540062.42,"runtime_std":10967451.73775354,"service":"brainlife/app-trekker-roi-tracking","__v":0},"success_rate":45.722171113155476,"users":16,"runtime_mean":36733933.86,"runtime_std":20438070.958943717,"requested":6027,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf671de14be11ff2617c2"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf671de14be11ff2617c3"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf671de14be11ff2617c4"}],"examples":0,"groups":27},"create_date":"2019-10-03T17:42:21.650Z","doi":"10.25663/brainlife.app.233"},{"name":"DWI Debias - Deprecated","github":"brainlife/app-dwi-debias","desc":"Performs mrtrix's dwibiascorrect on dwi data","stats":{"stars":0,"serviceinfo":{"_id":"5d9fca22f8e42548a397d340","counts":{"_id":"5e5c3e1987cac76c55ab1432","failed":3,"finished":77,"removed":81,"requested":84,"running":79,"running_sync":0,"stop_requested":1},"success_rate":96.25,"users":2,"readme_status":"too short","runtime_mean":1234820.974025974,"runtime_std":1892409.1523325774,"service":"brainlife/app-dwi-debias","__v":0},"success_rate":77.8048780487805,"users":6,"runtime_mean":85627.02,"runtime_std":83766.37883434858,"requested":418,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf676de14be11ff2617c8"}],"examples":0,"groups":9},"create_date":"2019-10-10T02:46:34.488Z","doi":"10.25663/brainlife.app.234"},{"name":"ROI Generation (no merge)","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1f78356a109788b2b7","counts":{"_id":"5e5c3e1a87cac77086ab1433","failed":788,"finished":6048,"removed":7078,"requested":7656,"running":6617,"running_sync":0,"stop_requested":49},"success_rate":88.47279110590989,"users":12,"readme_status":"ok","runtime_mean":5580586.29,"runtime_std":23419021.556393724,"service":"brain-life/app-roiGenerator","__v":0},"success_rate":83.53765323992994,"users":27,"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"requested":13134,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf67bde14be11ff2617cb"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf67bde14be11ff2617cc"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf67bde14be11ff2617cd"}],"examples":0,"groups":58},"create_date":"2019-10-15T03:04:24.459Z","doi":"10.25663/brainlife.app.235"},{"name":"Map pRFs in visual cortex with anatomy - copy","github":"soichih/app-benson14-retinotopy","desc":"Brainlife.io app for Noah Benson's neuropythy library, retinotopy from T1 anatomy","stats":{"stars":0,"requested":6,"users":2,"success_rate":100,"serviceinfo":{"_id":"5daf9c95fc1e051b173fb723","counts":{"_id":"5e5c3e1b87cac7c656ab1434","failed":0,"finished":2,"removed":2,"requested":5,"running":5,"running_sync":0,"stop_requested":3},"success_rate":100,"users":1,"readme_status":"too short","runtime_mean":294639,"runtime_std":5862,"service":"soichih/app-benson14-retinotopy","__v":0},"gitinfo":{"desc":"Brainlife.io app for Noah Benson's neuropythy library, retinotopy from T1 anatomy","tags":[],"stats":{"stars":1},"contributors":[{"name":"Noah C. Benson","email":"nben@nyu.edu"},{"name":"David Hunt","email":"davhunt@indiana.edu"},{"name":"Ariel Rokem","email":"arokem@gmail.com"},{"name":"Gio Piantoni","email":"github@gpiantoni.com"},{"name":"Michael Waskom","email":null}]},"runtime_mean":294639,"runtime_std":5862,"resources":[],"examples":0,"groups":2},"create_date":"2019-10-22T18:39:46.491Z","doi":"10.25663/brainlife.app.237"},{"name":"Fit Constrained Deconvolution Model for Tracking","github":"bacaron/app-mrtrix3-act","desc":"Runs mrtrix3 ACT (Anatomically Constrained Tractography) using either single- or multi-shell diffusion-weighted MRI data. ","stats":{"stars":0,"serviceinfo":{"_id":"5db23fa5e9b0ce3ab491f8d2","counts":{"_id":"5e5c3e1c87cac76e04ab1435","failed":67,"finished":51,"removed":132,"requested":195,"running":133,"running_sync":0,"stop_requested":15},"users":2,"readme_status":"ok","service":"brainlife/app-mrtrix3-csd","__v":0,"runtime_mean":15726807.88235294,"runtime_std":8447886.226064393,"success_rate":43.22033898305085},"success_rate":78.61335502992968,"users":34,"runtime_mean":15292131.23,"runtime_std":30785532.43603803,"requested":20639,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf689de14be11ff261b8d"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf689de14be11ff261b8e"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf689de14be11ff261b8f"}],"examples":5,"groups":68},"create_date":"2019-10-24T22:25:45.338Z","doi":"10.25663/brainlife.app.238"},{"name":"Tissue-type segmentation","github":"brainlife/app-mrtrix3-5tt","desc":"This app will generate a 5-tissue type mask (5tt) from a T1 anatomical image using mrtrix3's 5ttgen. This code was adapted from app-mrtrix3-act (https://brainlife.io/app/5aac2437f0b5260027e24ae1), written by Brent McPherson (bcmcpher@iu.edu).","stats":{"stars":0,"serviceinfo":{"_id":"5db23fa5e9b0ce3ab491f8d0","counts":{"_id":"5e5c3e1d87cac7e98cab1436","failed":225,"finished":2666,"removed":3085,"requested":3306,"running":2880,"running_sync":0,"stop_requested":10},"users":5,"readme_status":"ok","service":"brainlife/app-mrtrix3-5tt","__v":0,"runtime_mean":15688516.39,"runtime_std":41278139.97729138,"success_rate":92.21722587340021},"success_rate":74.46177645997165,"users":43,"runtime_mean":1095260.97,"runtime_std":390697.17401213583,"requested":21092,"resources":[],"examples":4,"groups":94},"create_date":"2019-10-24T23:30:08.038Z","doi":"10.25663/brainlife.app.239"},{"name":"Generate ROIs in DMRI Space","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1f78356a109788b2b7","counts":{"_id":"5e5c3e1e87cac7842bab1438","failed":788,"finished":6048,"removed":7078,"requested":7656,"running":6617,"running_sync":0,"stop_requested":49},"success_rate":88.47279110590989,"users":12,"readme_status":"ok","runtime_mean":5580586.29,"runtime_std":23419021.556393724,"service":"brain-life/app-roiGenerator","__v":0},"success_rate":83.53765323992994,"users":27,"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"requested":13134,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf696de14be11ff2620bd"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf696de14be11ff2620be"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf696de14be11ff2620bf"}],"examples":5,"groups":58},"create_date":"2019-10-31T20:52:12.219Z","doi":"10.25663/brainlife.app.242"},{"name":"Bin cortical volume and thickness by eccentricity","github":"brainlife/app-thickness-volume-eccentricity","desc":null,"stats":{"stars":0,"serviceinfo":null,"success_rate":88.05460750853243,"users":26,"runtime_mean":2118298.04,"runtime_std":3977244.637515472,"requested":308,"resources":[],"examples":0,"groups":24},"create_date":"2019-11-01T21:03:47.863Z","doi":"10.25663/brainlife.app.243"},{"name":"Bayesian Analysis of Retinotopic Maps","github":"davhunt/app-bayesian-retinotopy","desc":null,"stats":{"stars":0,"serviceinfo":{"_id":"5dbe1d3b62838771c9d1d0fb","counts":{"_id":"5e5c3e2187cac73b16ab143a","failed":16,"finished":18,"removed":29,"requested":47,"running":46,"running_sync":0,"stop_requested":12},"success_rate":52.94117647058824,"users":1,"readme_status":"ok","service":"davhunt/app-bayesian-retinotopy","__v":0,"runtime_mean":4759028.777777778,"runtime_std":3964010.8445363003},"success_rate":60.97560975609756,"users":1,"runtime_mean":5492316.96,"runtime_std":7835151.103487678,"requested":56,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf6a1de14be11ff2620ef"}],"examples":0,"groups":1},"create_date":"2019-11-02T22:50:08.205Z","doi":"10.25663/brainlife.app.245"},{"name":"QSIPrep - Preprocessing workflow","github":"brainlife/app-qsiprep","desc":"Preprocessing of diffusion MRI data. It includes automatically generated preprocessing pipelines that correctly group, distortion correct, motion correct, denoise, coregister and resample your scans, producing visual reports and QC metrics.","stats":{"stars":0,"serviceinfo":{"_id":"5dc211bf9c9bb24118b49b20","counts":{"_id":"5e5c3e2287cac79247ab143b","failed":4,"finished":3,"removed":6,"requested":9,"running":9,"running_sync":0,"stop_requested":2},"success_rate":42.857142857142854,"users":3,"readme_status":"ok","runtime_mean":4802304.333333333,"runtime_std":5130781.321276018,"service":"brainlife/app-qsiprep","__v":0},"success_rate":35.17783149171271,"users":26,"runtime_mean":27346656.71,"runtime_std":16315722.544463044,"requested":16154,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf6a7de14be11ff2622d3"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf6a7de14be11ff2622d4"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf6a7de14be11ff2622d5"}],"examples":5,"groups":52},"create_date":"2019-11-05T18:43:49.856Z","doi":"10.25663/brainlife.app.246"},{"name":"Denoise SOS-reconstructed DWI data","github":"brainlife/app-denoise-tensorflow","desc":null,"stats":{"stars":0,"serviceinfo":{"_id":"5dc363c45b365f708c60d52f","counts":{"_id":"5e5c3e2387cac7a867ab143c","failed":42,"finished":334,"removed":283,"requested":432,"running":372,"running_sync":0,"stop_requested":3},"success_rate":88.82978723404256,"users":3,"readme_status":"too short","runtime_mean":64581.13,"runtime_std":59343.03596255503,"service":"brainlife/app-denoise-tensorflow","__v":0},"success_rate":86.74418604651163,"users":3,"runtime_mean":50443.32,"runtime_std":7793.5852479844,"requested":973,"resources":[],"examples":0,"groups":5},"create_date":"2019-11-06T17:48:06.851Z","doi":"10.25663/brainlife.app.247"},{"name":"C-PAC","github":"soichih/C-PAC","desc":"Configurable Pipeline for the Analysis of Connectomes","stats":{"stars":110,"serviceinfo":null,"resources":[],"success_rate":15.384615384615385,"users":3,"runtime_mean":122169.5,"runtime_std":15378.5,"requested":13,"examples":0,"groups":3},"create_date":"2019-11-09T02:43:16.828Z","doi":"10.25663/brainlife.app.248"},{"name":"Segment tractogram into fiber categories","github":"brainlife/app-streamlineCategorySegmentation","desc":"Automatically segment a tractogram into categories (i.e. fronto-parietal tracts, parieto-temporal tracts, etc). THIS APPLICATION IS HIGHLY RECOMMENDED AS A MEANS OF RUNNING AN INITIAL QUALITY ASSURANCE CHECK ON YOUR GENERATED TRACTOGRAPHY OR AS A SANITY CHECK ON PROBLEMATIC SEGMENTATIONS.","stats":{"stars":0,"requested":6317,"users":27,"success_rate":76.00512163892445,"serviceinfo":{"_id":"5d729e1f78356a109788b257","counts":{"_id":"5e5c3e2a87cac72549ab143d","failed":630,"finished":2538,"removed":2930,"requested":3538,"running":3151,"running_sync":0,"stop_requested":76},"success_rate":80.11363636363636,"users":14,"readme_status":"ok","runtime_mean":4701550.01,"runtime_std":5896154.965123517,"service":"brainlife/app-streamlineCategorySegmentation","__v":0},"gitinfo":{"desc":"anatomy","tags":["anatomy","white-matter-segmentation"],"stats":{"stars":0},"contributors":[{"name":"Franco Pestilli","email":null},{"name":"Daniel Bullock","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Sophia Vinci-Booher","email":null}]},"runtime_mean":9626059.63,"runtime_std":20298759.815652583,"resources":[],"examples":2,"groups":36},"create_date":"2019-11-11T21:55:58.655Z","doi":"10.25663/brainlife.app.249"},{"name":"Anatomically-informed multi-LAP with trk","github":"giulia-berto/app-multi-lap-anat","desc":"White matter bundle segmentation as Anatomically-Informed multiple Linear Assignment Problems (multi-LAP-anat).","stats":{"stars":1,"requested":1036,"users":1,"success_rate":83.97502601456816,"serviceinfo":{"_id":"5d729e1f78356a109788b283","counts":{"_id":"5e5c3e2b87cac70de9ab143e","failed":150,"finished":806,"removed":741,"requested":1024,"running":982,"running_sync":0,"stop_requested":39},"success_rate":84.30962343096235,"users":1,"readme_status":"ok","runtime_mean":19688102.98,"runtime_std":11191394.632128878,"service":"giulia-berto/app-multi-lap-anat","__v":0},"gitinfo":{"desc":"White matter bundle segmentation as multiple Linear Assignment Problems (multi-LAP).","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":19616098.84,"runtime_std":11230532.48671157,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf6c1de14be11ff2623c4"}],"examples":0,"groups":4},"create_date":"2019-11-16T16:40:50.105Z","doi":"10.25663/brainlife.app.250"},{"name":"Extract multi-tcks from wmc + wbfg or composite tck","github":"brainlife/app-extractTCKfromWMC","desc":"This application takes an input tractography amalgam (i.e. whole brain fiber group (WBFG) or composite) and, using the categories designated in the associated White Matter Classification (WMC) structure input, extracts and outputs a Tck file for each category into the output directory. ","stats":{"stars":0,"serviceinfo":{"_id":"5dd092b5b28ec72c245d624b","counts":{"_id":"5e5c3e2b87cac72972ab143f","failed":2,"finished":25,"removed":5,"requested":30,"running":27,"running_sync":0,"stop_requested":0},"success_rate":92.5925925925926,"users":4,"readme_status":"no README.md","runtime_mean":471206.92,"runtime_std":244162.40282368127,"service":"brainlife/app-extractTCKfromWMC","__v":0},"success_rate":91.93899782135077,"users":10,"runtime_mean":1288502.69,"runtime_std":3424334.4463424096,"requested":521,"resources":[{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf6c8de14be11ff26254d"}],"examples":1,"groups":14},"create_date":"2019-11-16T20:50:25.746Z","doi":"10.25663/brainlife.app.251"},{"name":"Track The Human Optic RAdiation (THORA): Contrack - Eccentricity","github":"brainlife/app-contrack-optic-radiation","desc":null,"stats":{"stars":0,"serviceinfo":{"_id":"5ddc70174e1eed32f44698e0","counts":{"_id":"5e5c3e2c87cac75f96ab1440","failed":39,"finished":166,"removed":904,"requested":1005,"running":289,"running_sync":0,"stop_requested":108},"success_rate":80.97560975609757,"users":1,"readme_status":"too short","service":"brainlife/app-contrack-optic-radiation","__v":0,"runtime_mean":4833658.12,"runtime_std":12226682.928288473},"success_rate":73.77398720682304,"users":3,"runtime_mean":25563004.18,"runtime_std":18189546.80106385,"requested":1685,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf6cede14be11ff262591"}],"examples":1,"groups":5},"create_date":"2019-11-25T06:14:16.589Z","doi":"10.25663/brainlife.app.252"},{"name":"Track The Human Optic RAdiation (THORA): mrtrix2 - Eccentricity","github":"brainlife/app-roi2roitracking","desc":"This app will perform ensemble tracking between 2 or more cortical regions of interest (ROIs) from either a freesurfer parcellation or an atlas parcellation. The app will automatically generate ROI niftis in diffusion space for tracking based on inputted ROI numbers. Inputs include: parcellation (freesurfer; atlas optional), dt6 from dtiinit, and ROI pairings. Outputs include a track.tck for each pairing of ROIs, a classification structure, and a fg_classified structure which can then be fed into other apps on the website (example: Clean WMC Output).","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1f78356a109788b2eb","counts":{"_id":"5e5c3e2d87cac73cfaab1441","failed":3381,"finished":11383,"removed":28448,"requested":30096,"running":14546,"running_sync":0,"stop_requested":509},"success_rate":77.0997019777838,"users":4,"readme_status":"ok","runtime_mean":5104239.9,"runtime_std":9812760.010720242,"service":"brain-life/app-roi2roitracking","__v":0},"success_rate":4.411764705882353,"users":3,"runtime_mean":48983551,"runtime_std":10404132.833534982,"requested":82,"resources":[],"examples":0,"groups":4},"create_date":"2019-11-26T04:35:21.568Z","doi":"10.25663/brainlife.app.253"},{"name":"Track The Human Optic RAdiation (THORA): Contrack - Tracking Eccentricity","github":"brainlife/app-contrack-visual-white-matter","desc":null,"stats":{"stars":0,"serviceinfo":{"_id":"5ddc70174e1eed32f44698e0","counts":{"_id":"5e5c3e2e87cac7e448ab1442","failed":39,"finished":166,"removed":904,"requested":1005,"running":289,"running_sync":0,"stop_requested":108},"success_rate":80.97560975609757,"users":1,"readme_status":"too short","service":"brainlife/app-contrack-optic-radiation","__v":0,"runtime_mean":4833658.12,"runtime_std":12226682.928288473},"users":3,"requested":166,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf6dade14be11ff2626bf"}],"examples":0,"groups":4,"success_rate":57.54716981132076,"runtime_mean":21450760.508196723,"runtime_std":10681959.291094214},"create_date":"2019-11-26T08:40:34.227Z","doi":"10.25663/brainlife.app.254"},{"name":"Mrtrix2 CSD","github":"brainlife/app-mrtrix2-csd","desc":null,"stats":{"stars":0,"serviceinfo":{"_id":"5de1b6064c234e10113d521e","counts":{"_id":"5e5c3e2e87cac7e897ab1443","failed":33,"finished":813,"removed":1122,"requested":1283,"running":811,"running_sync":0,"stop_requested":2},"success_rate":96.09929078014184,"users":2,"readme_status":"too short","runtime_mean":14288839.39,"runtime_std":51827383.30578027,"service":"brainlife/app-mrtrix2-csd","__v":0},"success_rate":94.98249708284715,"users":9,"runtime_mean":14331230.41,"runtime_std":51818144.95806107,"requested":1299,"resources":[],"examples":0,"groups":12},"create_date":"2019-11-29T18:41:18.609Z","doi":"10.25663/brainlife.app.255"},{"name":"mrtrix3-preproc-impr","github":"rjpuzniak/human-brain-albinism-and-achiasmatic-dataset","desc":"Improved version of the mrtrix3-preproc script deployed on BrainLife platform","stats":{"stars":0,"serviceinfo":{"_id":"5de84d8b178f0840a93c005f","counts":{"_id":"5e5c3e2f87cac74117ab1444","failed":0,"finished":0,"removed":2,"requested":2,"running":0,"running_sync":0,"stop_requested":0},"users":1,"readme_status":"too short","service":"rjpuzniak/human-brain-albinism-and-achiasmatic-dataset","__v":0},"users":1,"requested":2,"resources":[],"examples":0,"groups":1},"create_date":"2019-12-04T13:30:00.991Z","doi":"10.25663/brainlife.app.256"},{"name":"Automated Segmentation of Hippocampal Subfields (ASHS)","github":"svincibo/app-ashs-segment","desc":"brainlife.io app for using Automated Segmentation of Hippocampal Subfields (ASHS) software to segment hippocampal subfields based on previously acquired atlases","stats":{"stars":0,"serviceinfo":{"_id":"5e23a244b0d615607b79bdd9","counts":{"_id":"5e5c3e3087cac7276dab1445","failed":86,"finished":87,"removed":10,"requested":181,"running":175,"running_sync":0,"stop_requested":3},"users":2,"readme_status":"ok","service":"svincibo/app-ashs-segment","__v":0,"success_rate":50.28901734104046,"runtime_mean":6964495.356321839,"runtime_std":2307340.749197013},"success_rate":68.73156342182891,"users":5,"runtime_mean":6275028.89,"runtime_std":692367.1580469987,"requested":818,"resources":[],"examples":1,"groups":12},"create_date":"2019-12-09T22:43:47.156Z","doi":"10.25663/brainlife.app.262"},{"name":"Extract b0 images from DWI","github":"brainlife/app-mrtrix3-split-b0s","desc":null,"stats":{"stars":0,"serviceinfo":{"_id":"5df57c3c0eb5d62908c5722b","counts":{"_id":"5e5c3e3187cac7d65aab1446","failed":0,"finished":15,"removed":10,"requested":20,"running":18,"running_sync":0,"stop_requested":3},"success_rate":100,"users":2,"readme_status":"too short","runtime_mean":386645.13333333336,"runtime_std":579727.6980455413,"service":"brainlife/app-mrtrix3-split-b0s","__v":0},"success_rate":94.21965317919076,"users":5,"runtime_mean":75464.94,"runtime_std":280158.39896675665,"requested":189,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf6efde14be11ff2626eb"}],"examples":1,"groups":15},"create_date":"2019-12-14T00:49:42.372Z","doi":"10.25663/brainlife.app.263"},{"name":"Detect ECG artifacts","github":"soichih/app-detect-ecg-artifact","desc":"A sample brainlife app that uses EEG data (fif)","stats":{"stars":0,"serviceinfo":{"_id":"5df970eaac720c6c286364c7","counts":{"_id":"5e5c3e3187cac72c0aab1447","failed":2,"finished":4,"removed":1,"requested":6,"running":6,"running_sync":0,"stop_requested":0},"success_rate":66.66666666666666,"users":2,"readme_status":"too short","runtime_mean":82898.5,"runtime_std":36094.111836281554,"service":"soichih/app-detect-ecg-artifact","__v":0},"success_rate":66.66666666666666,"users":2,"runtime_mean":82898.5,"runtime_std":36094.111836281554,"requested":6,"resources":[],"examples":0,"groups":2},"create_date":"2019-12-17T18:46:09.426Z","doi":"10.25663/brainlife.app.264"},{"name":"Classifyber - segmentation","github":"FBK-NILab/app-classifyber-segmentation","desc":"Code to run Classifyber as a pre-trained bundle segmentation method.","stats":{"stars":1,"serviceinfo":{"_id":"5e4496d545e14842a4f7a7d2","counts":{"_id":"5e5c3e3287cac7792bab1448","failed":4,"finished":7,"removed":1,"requested":12,"running":12,"running_sync":0,"stop_requested":1},"success_rate":63.63636363636363,"users":3,"readme_status":"ok","runtime_mean":1102862.7142857143,"runtime_std":525790.412974522,"service":"FBK-NILab/app-classifyber-segmentation","__v":0},"gitinfo":{"desc":"Linear classification of single streamlines.","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"success_rate":71.11913357400722,"users":17,"runtime_mean":5467853.25,"runtime_std":6048965.798287718,"requested":328,"resources":[],"examples":1,"groups":24},"create_date":"2019-12-17T20:18:07.079Z","doi":"10.25663/brainlife.app.265"},{"name":"Penumbra Analysis","github":"brainlife/app-penumbra-analysis","desc":null,"stats":{"stars":0,"serviceinfo":{"_id":"5dfc13f2150a9b4c0383c455","counts":{"_id":"5e5c3e3387cac72b67ab1449","failed":0,"finished":8,"removed":8,"requested":9,"running":8,"running_sync":0,"stop_requested":0},"success_rate":100,"users":1,"readme_status":"too short","runtime_mean":279604.875,"runtime_std":81472.5994498112,"service":"brainlife/app-penumbra-analysis","__v":0},"success_rate":100,"users":1,"runtime_mean":279604.875,"runtime_std":81472.5994498112,"requested":9,"resources":[],"examples":0,"groups":1},"create_date":"2019-12-19T00:06:02.467Z","doi":"10.25663/brainlife.app.266"},{"name":"fMRIPrep - Surface Output","github":"brainlife/app-fmriprep","desc":"fMRIPrep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting.","stats":{"stars":1,"requested":87343,"users":193,"success_rate":44.30148573311729,"serviceinfo":{"_id":"5d729e1e78356a109788b1d7","counts":{"_id":"5e5c3e3387cac72eb6ab144a","failed":345,"finished":893,"removed":868,"requested":1485,"running":1265,"running_sync":0,"stop_requested":90},"success_rate":72.13247172859451,"users":26,"readme_status":"ok","runtime_mean":8657706.8,"runtime_std":2072534.0096058971,"service":"brainlife/app-fmriprep","__v":0},"gitinfo":{"desc":"runs fmriprep for brainlife","tags":["brain","fmri","mri","preprocessing"],"stats":{"stars":1},"contributors":[{"name":"Josh Faskowitz","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":7291092.28,"runtime_std":4463267.395332778,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf705de14be11ff262862"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf705de14be11ff262863"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf705de14be11ff262864"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf705de14be11ff262865"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf705de14be11ff262866"}],"examples":5,"groups":378},"create_date":"2019-12-20T15:54:37.416Z","doi":"10.25663/brainlife.app.267"},{"name":"Freesurfer on OSG","github":"brainlife/app-freesurfer-osg","desc":"A Pegasus workflow for running FreeSurfer on the Open Science Grid","stats":{"stars":0,"serviceinfo":{"_id":"5e03fcebc25c3d6b98eaf9ef","counts":{"_id":"5e5c3e3487cac73103ab144b","failed":2,"finished":0,"removed":1,"requested":2,"running":2,"running_sync":0,"stop_requested":0},"success_rate":0,"users":1,"readme_status":"ok","service":"brainlife/app-freesurfer-osg","__v":0},"success_rate":5.240174672489083,"users":9,"runtime_mean":59877015.666666664,"runtime_std":35020234.91876788,"requested":240,"resources":[{"resource_id":"5931bee335530000253833d2","name":"osgconnect","_id":"642cf70bde14be11ff26286e"}],"examples":0,"groups":10},"create_date":"2019-12-25T20:34:11.450Z","doi":"10.25663/brainlife.app.268"},{"name":"Freesurfer Statistics","github":"brainlife/app-freesurfer-stats","desc":null,"stats":{"stars":0,"serviceinfo":{"_id":"5e3221e029fabd6848ed6d1e","counts":{"_id":"5e5c3e3787cac708caab144f","failed":17,"finished":139,"removed":6,"requested":164,"running":154,"running_sync":0,"stop_requested":2},"success_rate":89.1025641025641,"users":13,"readme_status":"too short","runtime_mean":70411.26,"runtime_std":231629.3800326557,"service":"brainlife/app-freesurfer-stats","__v":0},"success_rate":80.49093438219494,"users":113,"runtime_mean":11258153.79,"runtime_std":45191300.94772274,"requested":123866,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf710de14be11ff262d5e"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf710de14be11ff262d5f"}],"examples":5,"groups":247},"create_date":"2020-01-29T17:19:36.866Z","doi":"10.25663/brainlife.app.272"},{"name":"FSL Anat (T1)","github":"brainlife/app-fsl-anat","desc":null,"stats":{"stars":0,"serviceinfo":{"_id":"5e3cad3c50444e3beb536144","counts":{"_id":"5e5c3e3887cac75014ab1450","failed":10,"finished":2,"removed":4,"requested":14,"running":14,"running_sync":0,"stop_requested":2},"success_rate":16.666666666666664,"users":1,"readme_status":"too short","service":"brainlife/app-fsl-anat","__v":0,"runtime_mean":3168917.5,"runtime_std":1128485.5},"success_rate":57.867899513886535,"users":115,"runtime_mean":11434850.57,"runtime_std":27696166.450184193,"requested":35442,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf715de14be11ff262f10"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf715de14be11ff262f11"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf715de14be11ff262f12"}],"examples":1,"groups":218},"create_date":"2020-02-06T21:39:58.946Z","doi":"10.25663/brainlife.app.273"},{"name":"mergeDWI","github":"svincibo/app-mergeDWI","desc":"Concatenates one or more diffusion images.","stats":{"stars":0,"serviceinfo":{"_id":"5e41f34b1a2e69792a64a0b2","counts":{"_id":"5e5c3e3987cac76deeab1452","failed":5,"finished":2,"removed":0,"requested":7,"running":7,"running_sync":0,"stop_requested":0},"success_rate":28.57142857142857,"users":2,"readme_status":"ok","runtime_mean":22220,"runtime_std":301,"service":"svincibo/app-mergeDWI","__v":0},"success_rate":80.6896551724138,"users":9,"runtime_mean":1622563.34,"runtime_std":3330474.430113632,"requested":157,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf71ade14be11ff262f89"}],"examples":2,"groups":16},"create_date":"2020-02-10T18:17:52.275Z","doi":"10.25663/brainlife.app.275"},{"name":"DenseUnet-based Automatic Rapid Tool for brain Segmentation (DARTS)","github":"davhunt/app-darts","desc":null,"stats":{"stars":0,"serviceinfo":{"_id":"5e4739df0f910e3b89b16b18","counts":{"_id":"5e5c3e3987cac74e98ab1453","failed":10,"finished":5,"removed":0,"requested":15,"running":14,"running_sync":0,"stop_requested":0},"success_rate":33.33333333333333,"users":1,"readme_status":"no README.md","service":"davhunt/app-darts","__v":0,"runtime_mean":1282854.8,"runtime_std":274717.04116009985},"success_rate":6.024096385542169,"users":6,"runtime_mean":1277702,"runtime_std":369348.62696428155,"requested":315,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf71fde14be11ff262f8c"}],"examples":0,"groups":7},"create_date":"2020-02-14T20:13:02.448Z","doi":"10.25663/brainlife.app.276"},{"name":"Network Null Model","github":"filipinascimento/bl-network-nullmodel","desc":"Generates an esemble of networks according to null models that try to reproduce the data. Erdos reyni (random), Barabási-Albert and Configuration model are implemented","stats":{"stars":0,"serviceinfo":null,"success_rate":97.6470588235294,"users":6,"runtime_mean":49661.361445783135,"runtime_std":175751.30697497394,"requested":86,"resources":[{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf725de14be11ff26305a"}],"examples":1,"groups":10},"create_date":"2020-02-17T17:53:01.212Z","doi":"10.25663/brainlife.app.277"},{"name":"ROI to ROI Tracking - MRTrix 0.2.12","github":"brainlife/app-roi2roitracking","desc":"This app will perform ensemble tracking between 2 or more cortical regions of interest (ROIs) from either a freesurfer parcellation or an atlas parcellation. The app will automatically generate ROI niftis in diffusion space for tracking based on inputted ROI numbers. Inputs include: parcellation (freesurfer; atlas optional), dt6 from dtiinit, and ROI pairings. Outputs include a track.tck for each pairing of ROIs, a classification structure, and a fg_classified structure which can then be fed into other apps on the website (example: Clean WMC Output).","stats":{"stars":0,"requested":82,"users":3,"success_rate":4.411764705882353,"serviceinfo":{"_id":"5d729e1f78356a109788b2eb","counts":{"_id":"5e5c3e3c87cac71f5eab1455","failed":3381,"finished":11383,"removed":28448,"requested":30096,"running":14546,"running_sync":0,"stop_requested":509},"success_rate":77.0997019777838,"users":4,"readme_status":"ok","runtime_mean":5104239.9,"runtime_std":9812760.010720242,"service":"brain-life/app-roi2roitracking","__v":0},"gitinfo":{"desc":"This app will perform ensemble tracking between 2 or more cortical regions of interest (ROIs) from either a freesurfer parcellation or an atlas parcellation. The app will automatically generate ROI niftis in diffusion space for tracking based on inputted ROI numbers. Inputs include: parcellation (freesurfer; atlas optional), dt6 from dtiinit, and ROI pairings. Outputs include a track.tck for each pairing of ROIs, a classification structure, and a fg_classified structure which can then be fed into other apps on the website (example: Clean WMC Output).","tags":["tracking"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null},{"name":"Ilaria Sani","email":"ila.gina@virgilio.it"}]},"runtime_mean":48983551,"runtime_std":10404132.833534982,"resources":[],"examples":1,"groups":4},"create_date":"2020-02-22T17:25:52.601Z","doi":"10.25663/brainlife.app.279"},{"name":"Trekker ROI Tracking (dwi) - v1.0","github":"brainlife/app-trekker-roi-tracking","desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1e3","counts":{"_id":"5e5c3e3d87cac7ceb4ab1456","failed":112,"finished":147,"removed":309,"requested":392,"running":302,"running_sync":0,"stop_requested":65},"success_rate":56.75675675675676,"users":7,"readme_status":"ok","runtime_mean":18540062.42,"runtime_std":10967451.73775354,"service":"brainlife/app-trekker-roi-tracking","__v":0},"success_rate":45.722171113155476,"users":16,"runtime_mean":36733933.86,"runtime_std":20438070.958943717,"requested":6027,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf730de14be11ff26307d"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf730de14be11ff26307e"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf730de14be11ff26307f"}],"examples":0,"groups":27},"create_date":"2020-02-24T20:13:57.622Z","doi":"10.25663/brainlife.app.280"},{"name":"Segment Tracts with ROIs","github":"brainlife/app-intersect-tract-roi","desc":null,"stats":{"stars":0,"serviceinfo":{"_id":"5e55bbdae86ae82d65712e1e","counts":{"_id":"5e5c3e3e87cac7db63ab1458","failed":33,"finished":609,"removed":1180,"requested":1803,"running":762,"running_sync":0,"stop_requested":98},"success_rate":94.85981308411215,"users":2,"readme_status":"too short","runtime_mean":1641385.46,"runtime_std":6687249.690709428,"service":"brainlife/app-intersect-tract-roi","__v":0},"success_rate":90.88105726872246,"users":6,"runtime_mean":3140432.85,"runtime_std":7330286.616514233,"requested":3446,"resources":[],"examples":3,"groups":9},"create_date":"2020-02-24T22:42:23.805Z","doi":"10.25663/brainlife.app.282"},{"name":"Extract diffusion metrics inside ROIs (DTI)","github":"brainlife/app-extract-diffusion-metrics-rois","desc":null,"stats":{"success_rate":95.79349904397706,"users":7,"runtime_mean":273055.13,"runtime_std":911261.5527963601,"requested":568,"resources":[],"examples":1,"groups":20},"create_date":"2020-03-02T20:30:12.944Z","doi":"10.25663/brainlife.app.283"},{"name":"Extract diffusion metrics inside ROIs (NODDI) - Deprecated","github":"brainlife/app-extract-diffusion-metrics-rois","desc":null,"stats":{"success_rate":95.79349904397706,"users":7,"runtime_mean":273055.13,"runtime_std":911261.5527963601,"requested":568,"resources":[],"examples":0,"groups":20},"create_date":"2020-03-02T20:30:54.395Z","doi":"10.25663/brainlife.app.284"},{"name":"Extract diffusion metrics inside ROIs - Deprecated","github":"brainlife/app-extract-diffusion-metrics-rois","desc":null,"stats":{"success_rate":95.79349904397706,"users":7,"runtime_mean":273055.13,"runtime_std":911261.5527963601,"requested":568,"resources":[],"examples":0,"groups":20},"create_date":"2020-03-02T20:32:18.900Z","doi":"10.25663/brainlife.app.285"},{"name":"EPI T1 Registration","github":"brainlife/app-epi-t1-registration","desc":"Align a Diffusion weighted MRI image to a T1 image using FSL's epi_reg. INPUTS: DWI data and a T1 image. OUTPUTS aligned DWI filed","stats":{"requested":3825,"users":15,"success_rate":75.45691906005221,"gitinfo":{"desc":"Preprocess a Diffusion weighted MRI image and aligne it to a T1 image. This App will also: (A) Fit a diffusion tensor model to the DWI data, (B) ... and (C) Create a dt6.mat compatibe with AFQ and VISTA SOFT. INPUTS: DWI data and a T1 image. OUTPUTS dt6.mat, and dt6.json, in addition to processed DWI files.","tags":["diffusion-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":3836362.95,"runtime_std":6966161.380045135,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf750de14be11ff263756"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf750de14be11ff263757"}],"examples":5,"groups":36},"create_date":"2020-03-12T19:34:21.503Z","doi":"10.25663/brainlife.app.286"},{"name":"FSL Top-up & Eddy - CUDA","github":"brainlife/app-FSLTopupEddy","desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","stats":{"requested":3399,"users":24,"success_rate":58.620689655172406,"gitinfo":{"desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","tags":["preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"runtime_mean":5133032.47,"runtime_std":8164410.893760923,"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"642cf756de14be11ff2637f2"}],"examples":2,"groups":45},"create_date":"2020-03-15T18:22:59.530Z","doi":"10.25663/brainlife.app.287"},{"name":"Generate Prostriata and LGN ROIs","github":"brainlife/app-prostriata-lgn-roi-generation","desc":null,"stats":{"success_rate":97.87234042553192,"users":1,"runtime_mean":809545.4130434783,"runtime_std":269084.6723375842,"requested":76,"resources":[],"examples":0,"groups":1},"create_date":"2020-03-22T00:32:26.812Z","doi":"10.25663/brainlife.app.288"},{"name":"Network Preprocess","github":"filipinascimento/bl-network-preprocess","desc":"App to preprocess connectivity/similarity matrices (conmat) and generate a filtered version of the network, which can be directed or undirected, weighted or unweighted.","stats":{"success_rate":95.28282195783761,"users":9,"runtime_mean":3576108.64,"runtime_std":7959475.674941436,"requested":5050,"resources":[{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf762de14be11ff263a02"}],"examples":1,"groups":18},"create_date":"2020-03-22T04:33:20.362Z","doi":"10.25663/brainlife.app.289"},{"name":"Network Communities","github":"filipinascimento/bl-network-communities","desc":"App to obtain the community structure of networks by using the Louvain or Infomap methods. All the Louvain quality functions work for networks with negative weights.","stats":{"success_rate":94.88817891373802,"users":10,"runtime_mean":25242.03,"runtime_std":23096.590406575167,"requested":318,"resources":[{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf767de14be11ff263acf"}],"examples":1,"groups":14},"create_date":"2020-03-24T09:07:14.462Z","doi":"10.25663/brainlife.app.290"},{"name":"mrtrix3 preprocess test","github":"brainlife/app-mrtrix3-preproc","desc":"Run the recommended preprocessing procedure provided by mrtrix3. The options available mostly reflect the optimal DESIGNER pipeline that was recently proposed. This App runs for >15 on topup if both PA and AP dwi files are provided. It detects bvecs flipping (dwigradcheck) and update the gradient table accordingly.","stats":{"requested":53522,"users":85,"success_rate":68.44728292971057,"gitinfo":{"desc":"Run the recommended preprocessing procedure provided by mrtrix3. The options available mostly reflect the optimal DESIGNER pipeline that was recently proposed. This App runs for >15 on topup if both PA and AP dwi files are provided.","tags":["diffusion-mri","mri","tractography"],"stats":{"stars":0},"contributors":[{"name":"Brent McPherson","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":5724997.08,"runtime_std":9406299.788806936,"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"642cf76cde14be11ff263ad2"},{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf76cde14be11ff263ad3"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf76cde14be11ff263ad4"}],"examples":0,"groups":221},"create_date":"2020-03-27T21:35:34.131Z","doi":"10.25663/brainlife.app.291"},{"name":"FSL DTIFIT","github":"brainlife/app-fslDTIFIT","desc":" This app will fit the diffusion tensor model (DTI) to a diffusion MRI image using FSL's dtifit commmand.","stats":{"requested":7990,"users":53,"success_rate":90.53836234687299,"gitinfo":{"desc":" This app will fit the diffusion tensor model (DTI) to a diffusion MRI image using FSL's dtifit commmand.","tags":["diffusion-mri"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"runtime_mean":70382.66,"runtime_std":182924.66367880633,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf775de14be11ff263e6b"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf775de14be11ff263e6c"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf775de14be11ff263e6d"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf775de14be11ff263e6e"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf775de14be11ff263e6f"}],"examples":5,"groups":86},"create_date":"2020-03-28T18:01:13.861Z","doi":"10.25663/brainlife.app.292"},{"name":"Cortex Tissue Mapping - Fukutomi et al  2018 Replication - DEPRECATED","github":"brainlife/app-hcp-cortex-mapping-replication","desc":null,"stats":{"requested":802,"users":1,"success_rate":75.45787545787546,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":509812.48,"runtime_std":419863.4260586525,"resources":[],"examples":0,"groups":2},"create_date":"2020-03-29T20:49:09.935Z","doi":"10.25663/brainlife.app.293"},{"name":"Segment white matter tracts using pyAFQ","github":"brainlife/app-pyafq-segment","desc":null,"stats":{"success_rate":0.22843321687718354,"users":16,"runtime_mean":6657990.647058823,"runtime_std":8398729.027456077,"requested":7944,"resources":[],"examples":0,"groups":25},"create_date":"2020-03-31T03:32:58.860Z","doi":"10.25663/brainlife.app.295"},{"name":"Tractography quality check - with LiFE (BROKEN?)","github":"brainlife/app-tractographyQualityCheck","desc":"Compute many statistics from your input tractogram and any (optionally input) associated classification structure.  These statistics can be used to facilitate quality assurance on your tractography and segmentation, or as part of subject/group level quantative analysis for a research project. See the output section of README.MD for more details.","stats":{"gitinfo":{"desc":"A quality check application for tractography, segmentatations, and LiFE structures","tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"success_rate":80.88005301524188,"users":34,"runtime_mean":32749303.59,"runtime_std":47565668.53729795,"requested":39939,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf785de14be11ff263e79"}],"examples":0,"groups":75},"create_date":"2020-03-31T16:48:33.098Z","doi":"10.25663/brainlife.app.296"},{"name":"Anatomically Constrained Tractography using precomputed 5tt & CSD","github":"bacaron/app-mrtrix3-act","desc":"Runs mrtrix3 ACT (Anatomically Constrained Tractography) using either single- or multi-shell diffusion-weighted MRI data. ","stats":{"success_rate":78.61335502992968,"users":34,"runtime_mean":15292131.23,"runtime_std":30785532.43603803,"requested":20639,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf78ede14be11ff264424"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf78ede14be11ff264425"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf78ede14be11ff264426"}],"examples":5,"groups":68},"create_date":"2020-04-04T16:41:35.886Z","doi":"10.25663/brainlife.app.297"},{"name":"Generate images of DWI","github":"brainlife/app-slicer-fsl","desc":null,"stats":{"success_rate":82.31619858418544,"users":118,"runtime_mean":274514.93,"runtime_std":622047.7772298245,"requested":23119,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf794de14be11ff2645db"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf794de14be11ff2645dc"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf794de14be11ff2645dd"}],"examples":5,"groups":185},"create_date":"2020-04-04T17:42:08.836Z","doi":"10.25663/brainlife.app.298"},{"name":"Generate images of fMRI","github":"brainlife/app-slicer-fsl","desc":null,"stats":{"success_rate":82.31619858418544,"users":118,"runtime_mean":274514.93,"runtime_std":622047.7772298245,"requested":23119,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf799de14be11ff264672"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf799de14be11ff264673"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf799de14be11ff264674"}],"examples":2,"groups":185},"create_date":"2020-04-04T17:42:47.311Z","doi":"10.25663/brainlife.app.299"},{"name":"Generate images of T1","github":"brainlife/app-slicer-fsl","desc":null,"stats":{"success_rate":82.31619858418544,"users":118,"runtime_mean":274514.93,"runtime_std":622047.7772298245,"requested":23119,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf79fde14be11ff26491e"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf79fde14be11ff26491f"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf79fde14be11ff264920"}],"examples":5,"groups":185},"create_date":"2020-04-04T17:43:09.187Z","doi":"10.25663/brainlife.app.300"},{"name":"Generate images of T2","github":"brainlife/app-slicer-fsl","desc":null,"stats":{"success_rate":82.31619858418544,"users":118,"runtime_mean":274514.93,"runtime_std":622047.7772298245,"requested":23119,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf7a4de14be11ff264a1a"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf7a4de14be11ff264a1b"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf7a4de14be11ff264a1c"}],"examples":3,"groups":185},"create_date":"2020-04-04T17:43:31.028Z","doi":"10.25663/brainlife.app.301"},{"name":"Generate images of tensor","github":"brainlife/app-slicer-fsl","desc":null,"stats":{"success_rate":82.31619858418544,"users":118,"runtime_mean":274514.93,"runtime_std":622047.7772298245,"requested":23119,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf7abde14be11ff264be1"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf7abde14be11ff264be2"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf7abde14be11ff264be3"}],"examples":3,"groups":185},"create_date":"2020-04-04T17:44:03.199Z","doi":"10.25663/brainlife.app.302"},{"name":"Generate images of NODDI - Deprecated","github":"brainlife/app-slicer-fsl","desc":null,"stats":{"success_rate":82.31619858418544,"users":118,"runtime_mean":274514.93,"runtime_std":622047.7772298245,"requested":23119,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf7b0de14be11ff264be6"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf7b0de14be11ff264be7"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf7b0de14be11ff264be8"}],"examples":0,"groups":185},"create_date":"2020-04-04T17:44:28.855Z","doi":"10.25663/brainlife.app.303"},{"name":"merge2TCKs","github":"svincibo/app-mergeTCK","desc":"Merge multiple TCK files into one TCK file.","stats":{"success_rate":78.48101265822784,"users":4,"runtime_mean":783905.6935483871,"runtime_std":2803960.445063879,"requested":86,"resources":[],"examples":1,"groups":11},"create_date":"2020-04-06T16:37:58.862Z","doi":"10.25663/brainlife.app.304"},{"name":"Merge Tractography (tcks) together with MRTrix3 (Two Tcks)","github":"bacaron/app-mergeTCK","desc":"Merge multiple TCK files into one TCK file.","stats":{"success_rate":92.20055710306406,"users":6,"runtime_mean":403908.66,"runtime_std":729450.6702689391,"requested":848,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf7c4de14be11ff2655ce"}],"examples":5,"groups":12},"create_date":"2020-04-06T21:02:35.591Z","doi":"10.25663/brainlife.app.305"},{"name":"Network Visualization","github":"filipinascimento/bl-network-visualization","desc":"This app generates simple 2D static visualizations for networks by using a force-directed algorithm. The current implementation uses the Large Graph Layout (LGL) algorithm.","stats":{"success_rate":94.68196037539103,"users":43,"runtime_mean":262886.71,"runtime_std":1926923.8118783336,"requested":1991,"resources":[{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf7cbde14be11ff265950"}],"examples":5,"groups":60},"create_date":"2020-04-07T18:52:31.796Z","doi":"10.25663/brainlife.app.306"},{"name":"Generate images of masks","github":"brainlife/app-slicer-fsl","desc":null,"stats":{"success_rate":82.31619858418544,"users":118,"runtime_mean":274514.93,"runtime_std":622047.7772298245,"requested":23119,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf7d0de14be11ff26597e"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf7d0de14be11ff26597f"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf7d0de14be11ff265980"}],"examples":1,"groups":185},"create_date":"2020-04-07T19:00:03.379Z","doi":"10.25663/brainlife.app.307"},{"name":"Generate images of mask overlaid on DWI","github":"brainlife/app-slicer-fsl","desc":null,"stats":{"success_rate":82.31619858418544,"users":118,"runtime_mean":274514.93,"runtime_std":622047.7772298245,"requested":23119,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf7d6de14be11ff265983"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf7d6de14be11ff265984"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf7d6de14be11ff265985"}],"examples":0,"groups":185},"create_date":"2020-04-07T19:07:30.909Z","doi":"10.25663/brainlife.app.308"},{"name":"Generate images of DWI overlaid on T1","github":"brainlife/app-slicer-fsl","desc":null,"stats":{"success_rate":82.31619858418544,"users":118,"runtime_mean":274514.93,"runtime_std":622047.7772298245,"requested":23119,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf7dede14be11ff265d73"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf7dede14be11ff265d74"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf7dede14be11ff265d75"}],"examples":5,"groups":185},"create_date":"2020-04-08T18:21:35.188Z","doi":"10.25663/brainlife.app.309"},{"name":"Generate figures of whole-brain tractogram (tck)","github":"kitchell/app-AFQ_figures","desc":"This service creates 4 figures of each AFQ tract: axial, left sagittal, right sagittal, coronal. Please choose the t1 image slices you would like displayed. The default slices work well for the HCP t1 images if they have not been re-ACPC aligned. If you have ACPC aligned your t1 images using the ACPC alignment app on Brain Life the following values are a good starting point: coronal = 105, sagittal = 89, axial = 65. The img_min and img_max values refer to the value range displayed for the t1 image. The value range is calulated as follow (mean + img_min * std, mean + img_max * std). The default values are a good starting place, adjust them if your t1 is too dark or too light.","stats":{"requested":2093,"users":41,"success_rate":80.65934065934066,"gitinfo":{"desc":"This service creates 4 figures of each AFQ tract: axial, left sagittal, right sagittal, coronal. Please choose the t1 image slices you would like displayed. The default slices work well for the HCP t1 images if they have not been re-ACPC aligned. If you have ACPC aligned your t1 images using the ACPC alignment app on Brain Life the following values are a good starting point: coronal = 105, sagittal = 89, axial = 65. The img_min and img_max values refer to the value range displayed for the t1 image. The value range is calulated as follow (mean + img_min * std, mean + img_max * std). The default values are a good starting place, adjust them if your t1 is too dark or too light.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":824849.84,"runtime_std":3312293.4410328493,"resources":[],"examples":4,"groups":36},"create_date":"2020-04-10T20:01:53.595Z","doi":"10.25663/brainlife.app.310"},{"name":"Plot response function","github":"brainlife/app-plot-response","desc":null,"stats":{"success_rate":89.17748917748918,"users":17,"runtime_mean":250676,"runtime_std":717281.7281318688,"requested":1228,"resources":[],"examples":3,"groups":28},"create_date":"2020-04-11T20:09:37.012Z","doi":"10.25663/brainlife.app.311"},{"name":"Generate images of tissue type masks","github":"brainlife/app-slicer-fsl","desc":null,"stats":{"success_rate":82.31619858418544,"users":118,"runtime_mean":274514.93,"runtime_std":622047.7772298245,"requested":23119,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf7f1de14be11ff266126"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf7f1de14be11ff266127"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf7f1de14be11ff266128"}],"examples":2,"groups":185},"create_date":"2020-04-12T01:46:21.788Z","doi":"10.25663/brainlife.app.312"},{"name":"combineROI","github":"svincibo/app-combineROI","desc":"This app will merge two ROI datatype sets into one ROI datatype dataset.","stats":{"success_rate":94.53219927095991,"users":4,"runtime_mean":5423682.28,"runtime_std":14304979.000090763,"requested":848,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf7f9de14be11ff2664c1"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf7f9de14be11ff2664c2"}],"examples":3,"groups":7},"create_date":"2020-04-13T22:21:32.418Z","doi":"10.25663/brainlife.app.313"},{"name":"mergeROI","github":"svincibo/app-mergeROI","desc":null,"stats":{"success_rate":97.32620320855615,"users":3,"runtime_mean":1369309.26,"runtime_std":4204635.105033748,"requested":881,"resources":[],"examples":0,"groups":4},"create_date":"2020-04-13T23:39:58.835Z","doi":"10.25663/brainlife.app.314"},{"name":"pRFLife with mrTools","github":"davhunt/app-prfv2","desc":null,"stats":{"success_rate":31.57894736842105,"users":1,"runtime_mean":85804083.08333333,"runtime_std":112690653.6729291,"requested":47,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf803de14be11ff2664c8"}],"examples":0,"groups":1},"create_date":"2020-04-14T19:49:34.816Z","doi":"10.25663/brainlife.app.315"},{"name":"Merge ROIs (Sophia)","github":"brainlife/app-merge-rois","desc":null,"stats":{"success_rate":55.55555555555556,"users":1,"runtime_mean":77038.2,"runtime_std":21479.396038064013,"requested":9,"resources":[],"examples":0,"groups":1},"create_date":"2020-04-20T02:47:53.220Z","doi":"10.25663/brainlife.app.316"},{"name":"Generate image of ODF","github":"brainlife/app-plot-odf","desc":null,"stats":{"success_rate":5.772594752186589,"users":8,"runtime_mean":82833.23232323233,"runtime_std":137067.1233231271,"requested":1762,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf80ede14be11ff266560"}],"examples":1,"groups":11},"create_date":"2020-04-20T05:19:02.677Z","doi":"10.25663/brainlife.app.317"},{"name":"Whole Brain Tractography","github":"brainlife/app-mrtrix3-act","desc":"Runs mrtrix3 ACT (Anatomically Constrained Tractography) using either single- or multi-shell diffusion-weighted MRI data. ","stats":{"success_rate":49.32970902576142,"users":58,"runtime_mean":11606863.4,"runtime_std":9971625.491358008,"requested":17691,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf814de14be11ff266611"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf814de14be11ff266612"}],"examples":1,"groups":124},"create_date":"2020-04-20T14:42:13.592Z","doi":"10.25663/brainlife.app.318"},{"name":"mrtrix3 - WMC Anatomically Constrained Tractography (ACT)","github":"brainlife/app-mrtrix3-act","desc":"Runs mrtrix3 ACT (Anatomically Constrained Tractography) using either single- or multi-shell diffusion-weighted MRI data. ","stats":{"requested":17691,"users":58,"success_rate":49.32970902576142,"gitinfo":{"desc":"Runs mrtrix3 ACT (Anatomically Constrained Tractography) using either single- or multi-shell diffusion-weighted MRI data. ","tags":["tracking","tractography"],"stats":{"stars":0},"contributors":[{"name":"Brent McPherson","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":11606863.4,"runtime_std":9971625.491358008,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf81cde14be11ff266aaf"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf81cde14be11ff266ab0"}],"examples":5,"groups":124},"create_date":"2020-04-20T16:33:29.381Z","doi":"10.25663/brainlife.app.319"},{"name":"Network Measurements","github":"filipinascimento/bl-network-measurements","desc":"App to calculate several basic statistics for networks and their respective null model distributions.","stats":{"success_rate":95.78357299536924,"users":10,"runtime_mean":55331.38,"runtime_std":68072.16945312967,"requested":5937,"resources":[{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf825de14be11ff266e70"}],"examples":4,"groups":20},"create_date":"2020-04-27T16:29:07.384Z","doi":"10.25663/brainlife.app.321"},{"name":"Fit IVIM","github":"dipy/bl_apps_dipy_fit_ivim","desc":"Brainlife wrapper app for dipy_fit_ivim workflows.","stats":{"success_rate":0,"users":3,"requested":10,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf82ade14be11ff266e73"}],"examples":0,"groups":3},"create_date":"2020-04-28T04:45:06.165Z","doi":"10.25663/brainlife.app.322"},{"name":"Denoising using LPCA","github":"dipy/bl_apps_dipy_denoise_lpca","desc":"Brainlife wrapper app for dipy_denoise_lpca workflows.","stats":{"success_rate":38.23529411764706,"users":8,"runtime_mean":4875807.538461538,"runtime_std":4114299.891485691,"requested":254,"resources":[],"examples":1,"groups":8},"create_date":"2020-04-28T05:29:45.634Z","doi":"10.25663/brainlife.app.454"},{"name":"Denoising using Marcenko-Pastur PCA (MP-PCA)","github":"dipy/bl_apps_dipy_denoise_mppca","desc":"Brainlife wrapper app for dipy_denoise_mppca workflows.","stats":{"success_rate":88.73239436619718,"users":7,"runtime_mean":4141947.1746031744,"runtime_std":7171631.511355943,"requested":74,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf835de14be11ff266ea9"}],"examples":1,"groups":7},"create_date":"2020-04-28T05:46:35.790Z","doi":"10.25663/brainlife.app.326"},{"name":"Remove Gibbs Ringing from your DWI data","github":"dipy/bl_apps_dipy_gibbs_ringing","desc":"Brainlife wrapper app for dipy_gibbs_ringing workflows.","stats":{"success_rate":98.24561403508771,"users":5,"runtime_mean":12049637.88,"runtime_std":2890282.9146500216,"requested":120,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf83ade14be11ff266ef6"}],"examples":1,"groups":4},"create_date":"2020-04-28T06:04:24.331Z","doi":"10.25663/brainlife.app.327"},{"name":"Tracking using Particle Filtering (PFT)","github":"dipy/bl_apps_dipy_track_pft","desc":"Brainlife wrapper app for dipy_track_pft workflows.","stats":{"resources":[],"examples":0},"create_date":"2020-04-28T07:03:23.608Z","doi":"10.25663/brainlife.app.328"},{"name":"Tracking using Probabilistic algorithm","github":"dipy/bl_apps_dipy_track","desc":"Brainlife wrapper app for dipy_track workflows.","stats":{"requested":849,"users":12,"success_rate":96.84343434343434,"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":3502445.35,"runtime_std":4220463.651326779,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf845de14be11ff266fb6"}],"examples":2,"groups":14},"create_date":"2020-04-28T07:31:55.782Z","doi":"10.25663/brainlife.app.448"},{"name":"Tracking using EuDX algorithm","github":"dipy/bl_apps_dipy_track","desc":"Brainlife wrapper app for dipy_track workflows.","stats":{"requested":849,"users":12,"success_rate":96.84343434343434,"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":3502445.35,"runtime_std":4220463.651326779,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf84bde14be11ff267036"}],"examples":1,"groups":14},"create_date":"2020-04-28T07:33:34.696Z","doi":"10.25663/brainlife.app.330"},{"name":"Tracking using Closest Peaks algorithm","github":"dipy/bl_apps_dipy_track","desc":"Brainlife wrapper app for dipy_track workflows.","stats":{"requested":849,"users":12,"success_rate":96.84343434343434,"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":3502445.35,"runtime_std":4220463.651326779,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf850de14be11ff26703a"}],"examples":0,"groups":14},"create_date":"2020-04-28T07:35:23.482Z","doi":"10.25663/brainlife.app.331"},{"name":"Streamlines Linear Registration (slr)","github":"dipy/bl_apps_dipy_slr","desc":"Brainlife wrapper app for dipy_slr workflows.","stats":{"success_rate":98.45559845559846,"users":4,"runtime_mean":113442.55,"runtime_std":146419.17360041165,"requested":260,"resources":[],"examples":3,"groups":3},"create_date":"2020-04-29T17:19:12.298Z","doi":"10.25663/brainlife.app.332"},{"name":"ROI to ROI Tracking - with dtiInit","github":"brainlife/app-roi2roitracking","desc":"This app will perform ensemble tracking between 2 or more cortical regions of interest (ROIs) from either a freesurfer parcellation or an atlas parcellation. The app will automatically generate ROI niftis in diffusion space for tracking based on inputted ROI numbers. Inputs include: parcellation (freesurfer; atlas optional), dt6 from dtiinit, and ROI pairings. Outputs include a track.tck for each pairing of ROIs, a classification structure, and a fg_classified structure which can then be fed into other apps on the website (example: Clean WMC Output).","stats":{"requested":82,"users":3,"success_rate":4.411764705882353,"gitinfo":{"desc":"This app will perform ensemble tracking between 2 or more cortical regions of interest (ROIs) from either a freesurfer parcellation or an atlas parcellation. The app will automatically generate ROI niftis in diffusion space for tracking based on inputted ROI numbers. Inputs include: parcellation (freesurfer; atlas optional), dt6 from dtiinit, and ROI pairings. Outputs include a track.tck for each pairing of ROIs, a classification structure, and a fg_classified structure which can then be fed into other apps on the website (example: Clean WMC Output).","tags":["tracking"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null},{"name":"Ilaria Sani","email":"ila.gina@virgilio.it"}]},"runtime_mean":48983551,"runtime_std":10404132.833534982,"resources":[],"examples":0,"groups":4},"create_date":"2020-04-29T19:46:21.136Z","doi":"10.25663/brainlife.app.333"},{"name":"ROI Generation (merge) - dtiInit","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"success_rate":83.53765323992994,"users":27,"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"requested":13134,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf861de14be11ff2670a3"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf861de14be11ff2670a4"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf861de14be11ff2670a5"}],"examples":0,"groups":58},"create_date":"2020-04-29T20:52:13.937Z","doi":"10.25663/brainlife.app.334"},{"name":"Convert network neuro matrix to conmat","github":"brainlife/app-network-matrices-2-mat","desc":null,"stats":{"success_rate":97.6054454843807,"users":24,"runtime_mean":287614.32,"runtime_std":1070949.9821393797,"requested":9448,"resources":[],"examples":5,"groups":35},"create_date":"2020-05-04T23:08:21.463Z","doi":"10.25663/brainlife.app.335"},{"name":"Mrtrix3 iFOD2 ROI Tracking (dwi)","github":"brainlife/app-mrtrix3-roi2roi-tracking","desc":null,"stats":{"success_rate":52.53423012250781,"users":10,"runtime_mean":6591077.91,"runtime_std":7833006.808106441,"requested":12229,"resources":[],"examples":2,"groups":19},"create_date":"2020-05-08T22:12:56.892Z","doi":"10.25663/brainlife.app.337"},{"name":"Trekker ROI Tracking (dtiinit) - v1.0","github":"brainlife/app-trekker-roi-tracking","desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","stats":{"success_rate":45.722171113155476,"users":16,"runtime_mean":36733933.86,"runtime_std":20438070.958943717,"requested":6027,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf876de14be11ff267705"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf876de14be11ff267706"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf876de14be11ff267707"}],"examples":0,"groups":27},"create_date":"2020-05-10T21:42:55.002Z","doi":"10.25663/brainlife.app.338"},{"name":"Mrtrix3 iFOD2 ROI Tracking (dtiinit)","github":"brainlife/app-mrtrix3-roi2roi-tracking","desc":null,"stats":{"success_rate":52.53423012250781,"users":10,"runtime_mean":6591077.91,"runtime_std":7833006.808106441,"requested":12229,"resources":[],"examples":0,"groups":19},"create_date":"2020-05-10T21:44:38.179Z","doi":"10.25663/brainlife.app.339"},{"name":"Make white matter mask in dwi space from Freesurfer","github":"brainlife/app-make-white-matter-mask-freesurfer","desc":null,"stats":{"success_rate":99.9341672152732,"users":4,"runtime_mean":540314.07,"runtime_std":987513.5825359696,"requested":1520,"resources":[],"examples":0,"groups":4},"create_date":"2020-05-11T18:50:06.753Z","doi":"10.25663/brainlife.app.340"},{"name":"Make white matter mask in dwi space from Freesurfer (dtiinit)","github":"brainlife/app-make-white-matter-mask-freesurfer","desc":null,"stats":{"success_rate":99.9341672152732,"users":4,"runtime_mean":540314.07,"runtime_std":987513.5825359696,"requested":1520,"resources":[],"examples":0,"groups":4},"create_date":"2020-05-11T18:50:54.366Z","doi":"10.25663/brainlife.app.341"},{"name":"Generate ROIs in DMRI Space (dtiinit)","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"success_rate":83.53765323992994,"users":27,"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"requested":13134,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf88bde14be11ff267711"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf88bde14be11ff267712"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf88bde14be11ff267713"}],"examples":0,"groups":58},"create_date":"2020-05-18T14:35:02.421Z","doi":"10.25663/brainlife.app.342"},{"name":"Fit NODDI model using AMICO (dtiinit)","github":"brainlife/app-noddi-amico","desc":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs) and an optional brainmask of the DWI. Will output the four NODDI output files: neurite density index (ndi), orientation dispersion index (odi), isotropic volume fraction (isovf), and the directions (dirs).","stats":{"requested":17952,"users":31,"success_rate":80.29782359679267,"gitinfo":{"desc":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs), and the single shell dwi file that has been aligned to the subject's T1 (i.e. dtiinit output) as input. The app will align the multi-shell data to the single-shell data (if dtiinit was used for tracking; otherwise single shell data is not necessary) in order to assure that NODDI outputs are in the same space as the tensor outputs for later analyses. Will output the five NODDI output files: FIT_ICVF_NEW, FIT_OD_NEW, FIT_ISOVF_NEW, FIT_dir, and config.pickle.","tags":["postprocessing"],"stats":{"stars":1},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":5453700.08,"runtime_std":14494456.081946442,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf890de14be11ff267718"}],"examples":0,"groups":61},"create_date":"2020-05-18T17:17:31.299Z","doi":"10.25663/brainlife.app.343"},{"name":"Mrtrix2 CSD (dtiinit)","github":"brainlife/app-mrtrix2-csd","desc":null,"stats":{"success_rate":94.98249708284715,"users":9,"runtime_mean":14331230.41,"runtime_std":51818144.95806107,"requested":1299,"resources":[],"examples":0,"groups":12},"create_date":"2020-05-18T17:42:13.655Z","doi":"10.25663/brainlife.app.344"},{"name":"Tract Analysis Profiles (NODDI) - Deprecated","github":"brainlife/app-tractanalysisprofiles","desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","stats":{"requested":19317,"users":42,"success_rate":77.25239616613419,"gitinfo":{"desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":2138024.52,"runtime_std":9002049.390707558,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf89bde14be11ff267720"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf89bde14be11ff267721"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf89bde14be11ff267722"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf89bde14be11ff267723"}],"examples":0,"groups":90},"create_date":"2020-05-18T20:46:00.692Z","doi":"10.25663/brainlife.app.345"},{"name":"Voxeleron OCT data Processing","github":"DanNBullock/app-voxeleronOCT","desc":"This app computes the mean and standard deviation of Voxeleron OTC data for each degree of visual angle.  This can be computed within a single layer, or across layers.  The output of this app is a table for both mean and standard deviation, and the output data (visual angle OCT data) for each combination of eye and layer combination.","stats":{"success_rate":90.47619047619048,"users":4,"runtime_mean":72689.71052631579,"runtime_std":43643.373815149025,"requested":88,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf8a0de14be11ff267737"}],"examples":1,"groups":4},"create_date":"2020-05-19T22:57:51.572Z","doi":"10.25663/brainlife.app.346"},{"name":"Track the Human Optic RAdiation (THORA) - mrtrix3 iFOD2 (dwi)","github":"brainlife/app-mrtrix3-roi2roi-tracking","desc":null,"stats":{"success_rate":52.53423012250781,"users":10,"runtime_mean":6591077.91,"runtime_std":7833006.808106441,"requested":12229,"resources":[],"examples":1,"groups":19},"create_date":"2020-05-20T19:27:18.258Z","doi":"10.25663/brainlife.app.347"},{"name":"Track the Human Optic RAdiation - mrtrix3 iFOD2 (dtiinit)","github":"brainlife/app-mrtrix3-roi2roi-tracking","desc":null,"stats":{"success_rate":52.53423012250781,"users":10,"runtime_mean":6591077.91,"runtime_std":7833006.808106441,"requested":12229,"resources":[],"examples":0,"groups":19},"create_date":"2020-05-20T19:27:49.280Z","doi":"10.25663/brainlife.app.348"},{"name":"Generate ROIs for Visual White Matter Tracking in dMRI Space (Benson pRF)","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"success_rate":83.53765323992994,"users":27,"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"requested":13134,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf8b6de14be11ff267dfb"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf8b6de14be11ff267dfc"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf8b6de14be11ff267dfd"}],"examples":0,"groups":58},"create_date":"2020-05-21T15:23:09.019Z","doi":"10.25663/brainlife.app.349"},{"name":"FSL Anat (T2)","github":"brainlife/app-fsl-anat","desc":null,"stats":{"success_rate":57.867899513886535,"users":115,"runtime_mean":11434850.57,"runtime_std":27696166.450184193,"requested":35442,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf8bbde14be11ff267ed8"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf8bbde14be11ff267ed9"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf8bbde14be11ff267eda"}],"examples":3,"groups":218},"create_date":"2020-05-21T21:07:44.423Z","doi":"10.25663/brainlife.app.350"},{"name":"Track the Human Optic RAdiation (THORA) - Trekker (dtiinit) -v1.0","github":"brainlife/app-trekker-roi-tracking","desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":45.722171113155476,"users":16,"runtime_mean":36733933.86,"runtime_std":20438070.958943717,"requested":6027,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf8c1de14be11ff267edd"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf8c1de14be11ff267ede"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf8c1de14be11ff267edf"}],"examples":0,"groups":27},"create_date":"2020-05-22T21:23:51.283Z","doi":"10.25663/brainlife.app.351"},{"name":"Track the Human Optic TRAct (THOTRA) - mrtrix3 iFOD2 (dwi)","github":"brainlife/app-mrtrix3-roi2roi-tracking","desc":null,"stats":{"success_rate":52.53423012250781,"users":10,"runtime_mean":6591077.91,"runtime_std":7833006.808106441,"requested":12229,"resources":[],"examples":0,"groups":19},"create_date":"2020-05-25T18:46:09.612Z","doi":"10.25663/brainlife.app.352"},{"name":"Track the Human Optic TRAct (THOTRA) - Trekker - v1.0","github":"brainlife/app-trekker-roi-tracking","desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":45.722171113155476,"users":16,"runtime_mean":36733933.86,"runtime_std":20438070.958943717,"requested":6027,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf8cbde14be11ff267ee5"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf8cbde14be11ff267ee6"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf8cbde14be11ff267ee7"}],"examples":0,"groups":27},"create_date":"2020-05-26T00:31:05.984Z","doi":"10.25663/brainlife.app.353"},{"name":"Track the Human Optic RAdiation (THORA) - Trekker - V1.0","github":"brainlife/app-trekker-roi-tracking","desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":45.722171113155476,"users":16,"runtime_mean":36733933.86,"runtime_std":20438070.958943717,"requested":6027,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf8d0de14be11ff267eeb"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf8d0de14be11ff267eec"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf8d0de14be11ff267eed"}],"examples":0,"groups":27},"create_date":"2020-05-26T03:11:54.042Z","doi":"10.25663/brainlife.app.354"},{"name":"Trekker ROI Tracking (DWI)","github":"brainlife/app-trekker-roi-tracking","desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":45.722171113155476,"users":16,"runtime_mean":36733933.86,"runtime_std":20438070.958943717,"requested":6027,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf8dbde14be11ff2684e5"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf8dbde14be11ff2684e6"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf8dbde14be11ff2684e7"}],"examples":5,"groups":27},"create_date":"2020-05-26T04:04:01.055Z","doi":"10.25663/brainlife.app.355"},{"name":"Trekker","github":"brainlife/app-trekker","desc":"Brainlife App (wrapper) for dMRI based fiber tracking using parallel transport tractography https://dmritrekker.github.io","stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking using parallel transport tractography https://dmritrekker.github.io","tags":[],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"success_rate":62.55144032921811,"users":11,"runtime_mean":37888004.83,"runtime_std":23561585.448650327,"requested":342,"resources":[],"examples":1,"groups":12},"create_date":"2020-05-26T04:33:02.139Z","doi":"10.25663/brainlife.app.356"},{"name":"Track the Human Optic TRAct (THOTRA) - Trekker","github":"brainlife/app-trekker-roi-tracking","desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":45.722171113155476,"users":16,"runtime_mean":36733933.86,"runtime_std":20438070.958943717,"requested":6027,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf8e6de14be11ff268524"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf8e6de14be11ff268525"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf8e6de14be11ff268526"}],"examples":0,"groups":27},"create_date":"2020-05-26T05:02:41.605Z","doi":"10.25663/brainlife.app.357"},{"name":"Trekker ROI Tracking (dtiinit)","github":"brainlife/app-trekker-roi-tracking","desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":45.722171113155476,"users":16,"runtime_mean":36733933.86,"runtime_std":20438070.958943717,"requested":6027,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf8ebde14be11ff26852a"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf8ebde14be11ff26852b"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf8ebde14be11ff26852c"}],"examples":0,"groups":27},"create_date":"2020-05-26T05:05:33.306Z","doi":"10.25663/brainlife.app.358"},{"name":"Track the Human Optic TRAct (THOTRA) - Trekker (dtiinit)","github":"brainlife/app-trekker-roi-tracking","desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":45.722171113155476,"users":16,"runtime_mean":36733933.86,"runtime_std":20438070.958943717,"requested":6027,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf8f0de14be11ff268530"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf8f0de14be11ff268531"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf8f0de14be11ff268532"}],"examples":0,"groups":27},"create_date":"2020-05-26T05:09:52.986Z","doi":"10.25663/brainlife.app.360"},{"name":"Tract Analysis Profiles","github":"brainlife/app-tractanalysisprofiles","desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","stats":{"requested":19317,"users":42,"success_rate":77.25239616613419,"gitinfo":{"desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":2138024.52,"runtime_std":9002049.390707558,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf901de14be11ff26941d"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf901de14be11ff26941e"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf901de14be11ff26941f"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf901de14be11ff269420"}],"examples":5,"groups":90},"create_date":"2020-05-28T21:22:00.532Z","doi":"10.25663/brainlife.app.361"},{"name":"Tract Analysis Profiles (NODDI)","github":"brainlife/app-tractanalysisprofiles","desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","stats":{"requested":19317,"users":42,"success_rate":77.25239616613419,"gitinfo":{"desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":2138024.52,"runtime_std":9002049.390707558,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf907de14be11ff269427"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf907de14be11ff269428"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf907de14be11ff269429"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf907de14be11ff26942a"}],"examples":0,"groups":90},"create_date":"2020-05-28T21:22:58.634Z","doi":"10.25663/brainlife.app.362"},{"name":"Extract diffusion metrics inside ROIs (NODDI)","github":"brainlife/app-extract-diffusion-metrics-rois","desc":null,"stats":{"success_rate":95.79349904397706,"users":7,"runtime_mean":273055.13,"runtime_std":911261.5527963601,"requested":568,"resources":[],"examples":0,"groups":20},"create_date":"2020-05-28T21:23:51.617Z","doi":"10.25663/brainlife.app.363"},{"name":"Extract diffusion metrics inside ROIs - Deprecated","github":"brainlife/app-extract-diffusion-metrics-rois","desc":null,"stats":{"success_rate":95.79349904397706,"users":7,"runtime_mean":273055.13,"runtime_std":911261.5527963601,"requested":568,"resources":[],"examples":0,"groups":20},"create_date":"2020-05-28T21:24:38.792Z","doi":"10.25663/brainlife.app.364"},{"name":"Noddi Amico","github":"brainlife/app-noddi-amico","desc":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs) and an optional brainmask of the DWI. Will output the four NODDI output files: neurite density index (ndi), orientation dispersion index (odi), isotropic volume fraction (isovf), and the directions (dirs).","stats":{"requested":17952,"users":31,"success_rate":80.29782359679267,"gitinfo":{"desc":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs), and the single shell dwi file that has been aligned to the subject's T1 (i.e. dtiinit output) as input. The app will align the multi-shell data to the single-shell data (if dtiinit was used for tracking; otherwise single shell data is not necessary) in order to assure that NODDI outputs are in the same space as the tensor outputs for later analyses. Will output the five NODDI output files: FIT_ICVF_NEW, FIT_OD_NEW, FIT_ISOVF_NEW, FIT_dir, and config.pickle.","tags":["postprocessing"],"stats":{"stars":1},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":5453700.08,"runtime_std":14494456.081946442,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf919de14be11ff269864"}],"examples":5,"groups":61},"create_date":"2020-05-28T21:25:38.479Z","doi":"10.25663/brainlife.app.365"},{"name":"NODDI Amico (single shell)","github":"brainlife/app-noddi-amico","desc":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs) and an optional brainmask of the DWI. Will output the four NODDI output files: neurite density index (ndi), orientation dispersion index (odi), isotropic volume fraction (isovf), and the directions (dirs).","stats":{"success_rate":80.29782359679267,"users":31,"runtime_mean":5453700.08,"runtime_std":14494456.081946442,"requested":17952,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf91fde14be11ff2698bb"}],"examples":2,"groups":61},"create_date":"2020-05-28T21:27:03.483Z","doi":"10.25663/brainlife.app.366"},{"name":"Generate images of NODDI","github":"brainlife/app-slicer-fsl","desc":null,"stats":{"success_rate":82.31619858418544,"users":118,"runtime_mean":274514.93,"runtime_std":622047.7772298245,"requested":23119,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf925de14be11ff269955"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf925de14be11ff269956"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf925de14be11ff269957"}],"examples":1,"groups":185},"create_date":"2020-05-28T21:29:32.757Z","doi":"10.25663/brainlife.app.367"},{"name":"Temporary converter app from NODDI-deprecated to NODDI datatype","github":"brainlife/app-convert-noddi-datatypes","desc":null,"stats":{"success_rate":100,"users":1,"runtime_mean":10820097.2,"runtime_std":25115798.30425453,"requested":133,"resources":[],"examples":0,"groups":3},"create_date":"2020-05-28T21:51:08.955Z","doi":"10.25663/brainlife.app.368"},{"name":"fMRI Timeseries Extraction","github":"faskowit/app-fmri-2-mat","desc":"fmriprep outputs to connectivity matrices ","stats":{"success_rate":54.54330055680606,"users":67,"runtime_mean":591949.28,"runtime_std":2744109.496301108,"requested":9537,"resources":[{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf932de14be11ff269dbf"}],"examples":5,"groups":97},"create_date":"2020-05-29T01:05:44.133Z","doi":"10.25663/brainlife.app.369"},{"name":"mrtrix3 act test","github":"brainlife/app-mrtrix3-act","desc":"Runs mrtrix3 ACT (Anatomically Constrained Tractography) using either single- or multi-shell diffusion-weighted MRI data. ","stats":{"requested":17691,"users":58,"success_rate":49.32970902576142,"gitinfo":{"desc":"Runs mrtrix3 ACT (Anatomically Constrained Tractography) using either single- or multi-shell diffusion-weighted MRI data. ","tags":["tracking","tractography"],"stats":{"stars":0},"contributors":[{"name":"Brent McPherson","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":11606863.4,"runtime_std":9971625.491358008,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf937de14be11ff269dc3"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf937de14be11ff269dc4"}],"examples":0,"groups":124},"create_date":"2020-06-04T16:50:02.308Z","doi":"10.25663/brainlife.app.370"},{"name":"Extract DWI volumes of choice - Deprecated","github":"brainlife/app-split-dwi-volumes","desc":null,"stats":{"success_rate":98.44559585492227,"users":2,"runtime_mean":452247.07,"runtime_std":793552.1110190719,"requested":596,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf93dde14be11ff269df7"}],"examples":1,"groups":4},"create_date":"2020-06-07T03:47:50.820Z","doi":"10.25663/brainlife.app.371"},{"name":"Time Series to Network","github":"brainlife/app-time-series-2-network","desc":"convert an NxT time series to an NxN functional connectivity matrix","stats":{"success_rate":76.47058823529412,"users":2,"runtime_mean":205788.96153846153,"runtime_std":104120.76255722737,"requested":35,"resources":[{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf942de14be11ff269dfa"}],"examples":0,"groups":4},"create_date":"2020-06-09T00:00:00.052Z","doi":"10.25663/brainlife.app.372"},{"name":"Parcellation Statistics - Deprecated","github":"brainlife/app-freesurfer-stats","desc":null,"stats":{"success_rate":80.49093438219494,"users":113,"runtime_mean":11258153.79,"runtime_std":45191300.94772274,"requested":123866,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf948de14be11ff269e13"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf948de14be11ff269e14"}],"examples":0,"groups":247},"create_date":"2020-06-09T20:55:57.388Z","doi":"10.25663/brainlife.app.374"},{"name":"Track The Human Optic RAdiation (THORA): Trekker - Eccentricity - DEPRECATED","github":"brainlife/app-trekker-roi-tracking","desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","stats":{"success_rate":45.722171113155476,"users":16,"runtime_mean":36733933.86,"runtime_std":20438070.958943717,"requested":6027,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf94dde14be11ff269e17"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf94dde14be11ff269e18"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf94dde14be11ff269e19"}],"examples":0,"groups":27},"create_date":"2020-06-11T06:30:51.820Z","doi":"10.25663/brainlife.app.375"},{"name":"Extract diffusion metrics inside tissue types","github":"brainlife/app-extract-diffusion-metrics-tissue-types","desc":null,"stats":{"success_rate":33.33333333333333,"users":3,"runtime_mean":36380.2,"runtime_std":18245.891224053707,"requested":17,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf952de14be11ff269e1d"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf952de14be11ff269e1e"}],"examples":0,"groups":4},"create_date":"2020-06-11T18:42:23.648Z","doi":"10.25663/brainlife.app.377"},{"name":"Compute  tSNR of DMRI Images","github":"brainlife/app-compute-temporal-snr","desc":null,"stats":{"resources":[],"success_rate":87.87878787878788,"users":1,"runtime_mean":6516969.5344827585,"runtime_std":10713287.969975939,"requested":78,"examples":0,"groups":3},"create_date":"2020-06-17T20:20:34.790Z","doi":"10.25663/brainlife.app.378"},{"name":"Cortex Tissue Mapping (Native & Template Space)","github":"brainlife/app-cortex-tissue-mapping","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","stats":{"requested":19134,"users":16,"success_rate":76.52514036969276,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":250899.08,"runtime_std":392917.6303011785,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf95fde14be11ff26a123"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf95fde14be11ff26a124"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf95fde14be11ff26a125"}],"examples":4,"groups":44},"create_date":"2020-06-17T21:04:08.534Z","doi":"10.25663/brainlife.app.379"},{"name":"Cortex Tissue Mapping (Native & Template Space) (Noddi)","github":"brainlife/app-cortex-tissue-mapping","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","stats":{"requested":19134,"users":16,"success_rate":76.52514036969276,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":250899.08,"runtime_std":392917.6303011785,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf964de14be11ff26a167"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf964de14be11ff26a168"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf964de14be11ff26a169"}],"examples":0,"groups":44},"create_date":"2020-06-17T21:05:17.586Z","doi":"10.25663/brainlife.app.380"},{"name":"Cortex Tissue Mapping (Native Space)","github":"brainlife/app-cortex-tissue-mapping","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","stats":{"requested":19134,"users":16,"success_rate":76.52514036969276,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":250899.08,"runtime_std":392917.6303011785,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf96ede14be11ff26a683"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf96ede14be11ff26a684"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf96ede14be11ff26a685"}],"examples":5,"groups":44},"create_date":"2020-06-17T21:18:29.740Z","doi":"10.25663/brainlife.app.381"},{"name":"Cortex Tissue Mapping (Native Space) (Noddi)","github":"brainlife/app-cortex-tissue-mapping","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","stats":{"requested":19134,"users":16,"success_rate":76.52514036969276,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":250899.08,"runtime_std":392917.6303011785,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf973de14be11ff26a72c"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf973de14be11ff26a72d"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf973de14be11ff26a72e"}],"examples":0,"groups":44},"create_date":"2020-06-17T21:18:54.071Z","doi":"10.25663/brainlife.app.382"},{"name":"Compute summary statistics of diffusion measures mapped to cortical surface - Deprecated Surface","github":"brainlife/app-cortex-tissue-mapping-stats","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf97cde14be11ff26abbd"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf97cde14be11ff26abbe"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf97cde14be11ff26abbf"}],"success_rate":44.93765121905825,"users":12,"runtime_mean":817560.56,"runtime_std":2302860.854492113,"requested":38152,"examples":2,"groups":27},"create_date":"2020-06-20T00:55:57.544Z","doi":"10.25663/brainlife.app.383"},{"name":"Compile tract profiles to summary structure","github":"brainlife/app-compile-tract-profiles","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf982de14be11ff26abc3"}],"success_rate":84.47488584474885,"users":4,"runtime_mean":91287.58,"runtime_std":153553.7515613461,"requested":287,"examples":0,"groups":6},"create_date":"2020-06-20T01:42:30.566Z","doi":"10.25663/brainlife.app.384"},{"name":"midway align and average T1w","github":"brainlife/app-align-n-average-images","desc":"align one image to another, and then average","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf987de14be11ff26abd7"}],"success_rate":92.85714285714286,"users":8,"runtime_mean":2291220.4725274723,"runtime_std":2904397.8716536458,"requested":122,"examples":1,"groups":13},"create_date":"2020-06-20T17:32:36.870Z","doi":"10.25663/brainlife.app.385"},{"name":"Qoala-T Model A","github":"davhunt/app-qoala-t-model-a","desc":"Predicting scan Qoala-T score by using Braintime model","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf98cde14be11ff26abff"}],"success_rate":56.00000000000001,"users":1,"runtime_mean":124544.42857142857,"runtime_std":131843.9366663233,"requested":25,"examples":1,"groups":2},"create_date":"2020-06-21T22:11:23.410Z","doi":"10.25663/brainlife.app.386"},{"name":"Create brainmask of DWI using MrTrix3","github":"brainlife/app-mrtrix3-dwi-brainmask","desc":null,"stats":{"resources":[],"success_rate":0,"users":8,"requested":23,"examples":0,"groups":8},"create_date":"2020-06-22T21:22:38.918Z","doi":"10.25663/brainlife.app.387"},{"name":"pydeface","github":"brainlife/app-pydeface","desc":"Brainlife wrapper for poldracklab/pydeface - MRI defacing App based on flirt and face template mask. https://github.com/poldracklab/pydeface ","stats":{"requested":598,"users":13,"success_rate":66.6083916083916,"gitinfo":{"desc":"Runs freesurfer/mri_deface with talairach_mixed_with_skull.gca and face.gca","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":611262.42,"runtime_std":228571.277946385,"resources":[],"examples":2,"groups":14},"create_date":"2020-06-24T03:08:07.337Z","doi":"10.25663/brainlife.app.388"},{"name":"Compute summary statistics of diffusion measures from subcortical segmentation","github":"brainlife/app-freesurfer-stats","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf99dde14be11ff26aee2"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf99dde14be11ff26aee3"}],"success_rate":80.49093438219494,"users":113,"runtime_mean":11258153.79,"runtime_std":45191300.94772274,"requested":123866,"examples":3,"groups":247},"create_date":"2020-06-26T21:41:57.775Z","doi":"10.25663/brainlife.app.389"},{"name":"Tractogram Filtering","github":"FBK-NILab/tractogram_filtering","desc":"Filtering out of artifactual streamlines from a tractogram with a geometric deep learning model","stats":{"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"642cf9a2de14be11ff26aee6"}],"success_rate":20,"users":5,"runtime_mean":1056881.25,"runtime_std":2503036.458852465,"requested":45,"examples":0,"groups":6},"create_date":"2020-07-06T17:15:33.931Z","doi":"10.25663/brainlife.app.390"},{"name":"Conmat to network","github":"filipinascimento/bl-conmat2network","desc":"Simple brainlife app to create a network from a conmat matrix.","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf9abde14be11ff26b492"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf9abde14be11ff26b493"}],"success_rate":93.95693866473674,"users":36,"runtime_mean":71975.24,"runtime_std":116851.17905174254,"requested":11265,"examples":5,"groups":56},"create_date":"2020-07-28T03:54:42.203Z","doi":"10.25663/brainlife.app.393"},{"name":"Structural Connectome MRTrix3 (SCMRT) (SIFT2) - Deprecated","github":"brainlife/app-sift2-connectome-generation","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf9b1de14be11ff26b62e"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf9b1de14be11ff26b62f"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf9b1de14be11ff26b630"}],"success_rate":69.42613125561881,"users":21,"runtime_mean":773265.98,"runtime_std":1117285.7638660036,"requested":18185,"examples":1,"groups":53},"create_date":"2020-08-05T02:37:24.381Z","doi":"10.25663/brainlife.app.394"},{"name":"Structural Connectome MRTrix3 (SCMRT) - No labels or weights","github":"brainlife/app-sift2-connectome-generation","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf9bbde14be11ff26bb86"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf9bbde14be11ff26bb87"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf9bbde14be11ff26bb88"}],"success_rate":69.42613125561881,"users":21,"runtime_mean":773265.98,"runtime_std":1117285.7638660036,"requested":18185,"examples":5,"groups":53},"create_date":"2020-08-05T14:22:16.905Z","doi":"10.25663/brainlife.app.395"},{"name":"Compile tract macro-structural and profile data","github":"brainlife/app-compile-macro-micro-tract-stats","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cf9c5de14be11ff26c165"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf9c5de14be11ff26c166"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf9c5de14be11ff26c167"}],"success_rate":89.68830560112491,"users":11,"runtime_mean":10657.82,"runtime_std":6801.613372399229,"requested":9506,"examples":5,"groups":25},"create_date":"2020-08-10T21:06:25.229Z","doi":"10.25663/brainlife.app.397"},{"name":"C-PAC","github":"FCP-INDI/app-C-PAC-brainlife.io","desc":"This is the official C-PAC (Configurable Pipeline for the Analysis of Connectomes) brainlife.io app. Currently this app runs either the default pipeline or one of our preconfigured pipelines.","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf9cbde14be11ff26c235"}],"success_rate":69.92611907866146,"users":27,"runtime_mean":806596.72,"runtime_std":2721959.5319404854,"requested":3772,"examples":1,"groups":31},"create_date":"2020-08-13T19:26:32.683Z","doi":"10.25663/brainlife.app.399"},{"name":"Generate Tract Overlays on Anatomical Image","github":"brainlife/app-plot-classified-streamlines","desc":null,"stats":{"resources":[],"success_rate":0,"users":2,"requested":6,"examples":0,"groups":2},"create_date":"2020-08-13T21:24:54.575Z","doi":"10.25663/brainlife.app.401"},{"name":"Temp extract warp freesurferpost HCP","github":"brainlife/app-extract-warp-temp","desc":null,"stats":{"resources":[],"success_rate":98.36808703535812,"users":1,"runtime_mean":64895.36,"runtime_std":170803.39759293554,"requested":1550,"examples":0,"groups":1},"create_date":"2020-08-30T14:54:44.236Z","doi":"10.25663/brainlife.app.402"},{"name":"pyAFQ_dry_run","github":"yeatmanlab/pyAFQ","desc":"Automated Fiber Quantification ... in Python","stats":{"resources":[],"users":1,"requested":3,"examples":0,"groups":1},"create_date":"2020-09-02T00:59:50.061Z","doi":"10.25663/brainlife.app.403"},{"name":"Track the Human Optic RAdiation (THORA) - Trekker (V2)","github":"brainlife/app-trekker-roi-tracking","desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":45.722171113155476,"users":16,"runtime_mean":36733933.86,"runtime_std":20438070.958943717,"requested":6027,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf9e4de14be11ff26c264"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf9e4de14be11ff26c265"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf9e4de14be11ff26c266"}],"examples":0,"groups":27},"create_date":"2020-09-02T03:23:43.849Z","doi":"10.25663/brainlife.app.404"},{"name":"Track The Human Optic RAdiation (THORA): Trekker - Eccentricity (V2)","github":"brainlife/app-trekker-roi-tracking","desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","stats":{"success_rate":45.722171113155476,"users":16,"runtime_mean":36733933.86,"runtime_std":20438070.958943717,"requested":6027,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cf9e9de14be11ff26c26a"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf9e9de14be11ff26c26b"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf9e9de14be11ff26c26c"}],"examples":0,"groups":27},"create_date":"2020-09-02T03:34:38.429Z","doi":"10.25663/brainlife.app.405"},{"name":"Track the Human Optic TRAct (THOTRA) - mrtrix3 IFOD2 (dwi)","github":"brainlife/app-mrtrix3-roi2roi-tracking","desc":null,"stats":{"success_rate":52.53423012250781,"users":10,"runtime_mean":6591077.91,"runtime_std":7833006.808106441,"requested":12229,"resources":[],"examples":0,"groups":19},"create_date":"2020-09-03T17:24:31.303Z","doi":"10.25663/brainlife.app.406"},{"name":"Track the Human Optic TRAct (THOTRA) - mrtrix3 (dwi)","github":"brainlife/app-mrtrix3-roi2roi-tracking","desc":null,"stats":{"success_rate":52.53423012250781,"users":10,"runtime_mean":6591077.91,"runtime_std":7833006.808106441,"requested":12229,"resources":[],"examples":0,"groups":19},"create_date":"2020-09-03T17:27:48.302Z","doi":"10.25663/brainlife.app.407"},{"name":"Generate ROIs for Visual White Matter Tracking in dMRI Space (Glasser Parcellation)","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"success_rate":83.53765323992994,"users":27,"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"requested":13134,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cf9fbde14be11ff26c4a1"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cf9fbde14be11ff26c4a2"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cf9fbde14be11ff26c4a3"}],"examples":4,"groups":58},"create_date":"2020-09-04T17:22:07.793Z","doi":"10.25663/brainlife.app.411"},{"name":"Generate ROIs for Visual White Matter Tracking in dMRI Space (Glasser Parcellation) Binned by prf Eccentricity Estimates - Deprecated Surface","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"success_rate":83.53765323992994,"users":27,"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"requested":13134,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfa01de14be11ff26c4a8"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfa01de14be11ff26c4a9"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfa01de14be11ff26c4aa"}],"examples":0,"groups":58},"create_date":"2020-09-04T23:21:54.054Z","doi":"10.25663/brainlife.app.413"},{"name":"Generate Visual Regions of Interest Binned by Eccentricity Estimates (Benson Atlas) - Diffusion Space","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"success_rate":83.53765323992994,"users":27,"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"requested":13134,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfa07de14be11ff26c59a"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfa07de14be11ff26c59b"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfa07de14be11ff26c59c"}],"examples":1,"groups":58},"create_date":"2020-09-04T23:22:51.536Z","doi":"10.25663/brainlife.app.414"},{"name":"Trekker ROI Tracking (DWI) based on Eccentricity","github":"brainlife/app-trekker-roi-tracking","desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":45.722171113155476,"users":16,"runtime_mean":36733933.86,"runtime_std":20438070.958943717,"requested":6027,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cfa0dde14be11ff26c5a1"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfa0dde14be11ff26c5a2"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfa0dde14be11ff26c5a3"}],"examples":0,"groups":27},"create_date":"2020-09-05T00:54:30.002Z","doi":"10.25663/brainlife.app.415"},{"name":"HD-BET","github":"anibalsolon/HD-BET_app","desc":"HD-BET is an automated brain extraction method for MRI using neural networks.","stats":{"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"642cfa12de14be11ff26c5fc"}],"success_rate":98.60956618464961,"users":17,"runtime_mean":478109.16,"runtime_std":1741259.844584177,"requested":22563,"examples":2,"groups":24},"create_date":"2020-09-09T19:28:45.061Z","doi":"10.25663/brainlife.app.416"},{"name":"Generate Eccentricity Parcellations from Visual ROIs","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfa18de14be11ff26c771"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfa18de14be11ff26c772"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfa18de14be11ff26c773"}],"success_rate":83.53765323992994,"users":27,"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"requested":13134,"examples":2,"groups":58},"create_date":"2020-09-10T19:14:40.887Z","doi":"10.25663/brainlife.app.417"},{"name":"Tracking the Visual White Matter (TVWM) (Trekker) - Eccentricity","github":"brainlife/app-trekker-roi-tracking","desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":45.722171113155476,"users":16,"runtime_mean":36733933.86,"runtime_std":20438070.958943717,"requested":6027,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cfa1dde14be11ff26c778"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfa1dde14be11ff26c779"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfa1dde14be11ff26c77a"}],"examples":0,"groups":27},"create_date":"2020-09-10T20:28:01.893Z","doi":"10.25663/brainlife.app.418"},{"name":"MatLab App Example","github":"brainlife/app-template-matlab","desc":"brainlife.io template for a basic matlab app.","stats":{"resources":[],"success_rate":0,"users":4,"requested":7,"examples":0,"groups":4},"create_date":"2020-09-20T01:10:55.086Z","doi":"10.25663/brainlife.app.419"},{"name":"dsi-studio-dwi2src","github":"frankyeh/dsi-studio-dwi2src","desc":"DSI Studio scripts converting DWI file to SRC format.","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfa28de14be11ff26c7b0"}],"success_rate":77.52375296912113,"users":10,"runtime_mean":1838643.86,"runtime_std":5245766.754112764,"requested":17817,"examples":2,"groups":33},"create_date":"2020-09-22T02:26:02.929Z","doi":"10.25663/brainlife.app.422"},{"name":"dsi-studio-atk","github":"frankyeh/dsi-studio-atk","desc":"DSI Studio augmented fiber tracking and automatic segmentation for mapping major white matter pathways (Yeh, Neuroimage, 2020). The pathway includes projection, association, and commissural pathways.","stats":{"resources":[],"success_rate":43.99843505477308,"users":11,"runtime_mean":23610057.12,"runtime_std":10514580.892609518,"requested":20384,"examples":3,"groups":31},"create_date":"2020-09-22T13:53:35.428Z","doi":"10.25663/brainlife.app.423"},{"name":"dsi-studio-tt2trk","github":"frankyeh/dsi-studio-tt2trk","desc":"Convert TRK format to TinyTrack format","stats":{"resources":[],"success_rate":0,"users":4,"requested":135,"examples":0,"groups":7},"create_date":"2020-09-22T22:33:52.656Z","doi":"10.25663/brainlife.app.425"},{"name":"dsi-studio-trk2tt","github":"frankyeh/dsi-studio-trk2tt","desc":"Convert TinyTrack format to TRK format","stats":{"resources":[],"success_rate":37.5,"users":2,"runtime_mean":46696,"runtime_std":17389.256855886626,"requested":8,"examples":1,"groups":2},"create_date":"2020-09-22T22:35:23.024Z","doi":"10.25663/brainlife.app.426"},{"name":"dsi-studio-src2fib","github":"frankyeh/dsi-studio-src2fib","desc":"Reconstruction of DWI signals to extract fiber orientations.","stats":{"resources":[],"success_rate":80.78616352201257,"users":8,"runtime_mean":1461809.77,"runtime_std":4574037.165527036,"requested":6845,"examples":1,"groups":21},"create_date":"2020-09-23T17:41:39.926Z","doi":"10.25663/brainlife.app.427"},{"name":"dsi-studio-qc","github":"frankyeh/dsi-studio-qc","desc":"Quality control for DWI data","stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cfa42de14be11ff26c870"}],"success_rate":69.48420199837969,"users":8,"runtime_mean":438821.88,"runtime_std":1142589.3757124147,"requested":7896,"examples":0,"groups":18},"create_date":"2020-09-23T18:03:15.551Z","doi":"10.25663/brainlife.app.428"},{"name":"dsi-studio-trk","github":"frankyeh/dsi-studio-trk","desc":"DSI Studio fiber tracking","stats":{"resources":[],"success_rate":100,"users":5,"runtime_mean":54260.28,"runtime_std":36992.79131860152,"requested":650,"examples":0,"groups":9},"create_date":"2020-09-24T03:08:38.842Z","doi":"10.25663/brainlife.app.429"},{"name":"Cortex Tissue Mapping - Fukutomi et al  2018 Replication","github":"brainlife/app-hcp-cortex-mapping-replication","desc":null,"stats":{"requested":802,"users":1,"success_rate":75.45787545787546,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":509812.48,"runtime_std":419863.4260586525,"resources":[],"examples":0,"groups":2},"create_date":"2020-09-24T15:55:47.239Z","doi":"10.25663/brainlife.app.430"},{"name":"Cortex Tissue Mapping (Native Space) - Gray Matter Density","github":"brainlife/app-cortex-tissue-mapping","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","stats":{"requested":19134,"users":16,"success_rate":76.52514036969276,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":250899.08,"runtime_std":392917.6303011785,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfa52de14be11ff26c8b2"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfa52de14be11ff26c8b3"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfa52de14be11ff26c8b4"}],"examples":1,"groups":44},"create_date":"2020-09-24T17:43:10.869Z","doi":"10.25663/brainlife.app.431"},{"name":"Compile qc data from tractmeasures (tsv) data","github":"brainlife/app-compile-tractmeasures","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfa58de14be11ff26c8b8"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfa58de14be11ff26c8b9"}],"success_rate":13.346613545816732,"users":9,"runtime_mean":58869.54,"runtime_std":82864.24038117046,"requested":1021,"examples":0,"groups":11},"create_date":"2020-09-24T18:47:37.341Z","doi":"10.25663/brainlife.app.432"},{"name":"GLMdenoise","github":"davhunt/app-GLMdenoise","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfa5dde14be11ff26c8bc"}],"success_rate":41.66666666666667,"users":5,"runtime_mean":10363832.8,"runtime_std":5921550.37251561,"requested":16,"examples":0,"groups":7},"create_date":"2020-09-24T22:05:31.550Z","doi":"10.25663/brainlife.app.451"},{"name":"Network Report","github":"filipinascimento/bl-network-report","desc":"App to generate reports from networks. This includes network properties, node attributes and their respective distributions.","stats":{"resources":[{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfa62de14be11ff26c972"}],"success_rate":45.562130177514796,"users":7,"runtime_mean":4716136.948051948,"runtime_std":7866371.736909718,"requested":188,"examples":1,"groups":10},"create_date":"2020-09-28T07:24:14.470Z","doi":"10.25663/brainlife.app.435"},{"name":"Compile measures from dsistudio tractmeasures datatype","github":"brainlife/app-compile-tractmeasures","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfa67de14be11ff26c975"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfa67de14be11ff26c976"}],"success_rate":13.346613545816732,"users":9,"runtime_mean":58869.54,"runtime_std":82864.24038117046,"requested":1021,"examples":0,"groups":11},"create_date":"2020-09-29T21:34:34.069Z","doi":"10.25663/brainlife.app.436"},{"name":"Extract summary statistics of diffusion measures mapped to cortical surface inside tract endpoints","github":"brainlife/app-cortex-tissue-mapping-stats","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfa70de14be11ff26cde6"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfa70de14be11ff26cde7"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfa70de14be11ff26cde8"}],"success_rate":44.93765121905825,"users":12,"runtime_mean":817560.56,"runtime_std":2302860.854492113,"requested":38152,"examples":5,"groups":27},"create_date":"2020-10-01T19:38:36.536Z","doi":"10.25663/brainlife.app.437"},{"name":"Segment tracts into multiple bundles using QuickBundles","github":"brainlife/app-extract-bundles-quickbundles","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfa76de14be11ff26ce66"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfa76de14be11ff26ce67"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfa76de14be11ff26ce68"}],"success_rate":57.920792079207914,"users":3,"runtime_mean":781004.2,"runtime_std":1541387.9204718058,"requested":227,"examples":1,"groups":3},"create_date":"2020-10-03T02:58:21.040Z","doi":"10.25663/brainlife.app.438"},{"name":"Compute macro-structural statistics of tracts using Dipy","github":"brainlife/app-compute-tract-stats","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfa7cde14be11ff26cf13"}],"success_rate":61.165048543689316,"users":5,"runtime_mean":372456.6349206349,"runtime_std":316625.53128383606,"requested":106,"examples":0,"groups":7},"create_date":"2020-10-04T04:13:18.743Z","doi":"10.25663/brainlife.app.439"},{"name":"Generate ROIs for Visual White Matter Analysis in Freesurfer Space (Benson pRF)","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"success_rate":83.53765323992994,"users":27,"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"requested":13134,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfa81de14be11ff26cf22"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfa81de14be11ff26cf23"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfa81de14be11ff26cf24"}],"examples":1,"groups":58},"create_date":"2020-10-14T05:14:51.293Z","doi":"10.25663/brainlife.app.440"},{"name":"Generate Visual Regions of Interest Binned by Eccentricity Estimates (Benson Atlas) - Freesurfer Space","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"success_rate":83.53765323992994,"users":27,"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"requested":13134,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfa87de14be11ff26d007"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfa87de14be11ff26d008"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfa87de14be11ff26d009"}],"examples":5,"groups":58},"create_date":"2020-10-14T17:16:50.559Z","doi":"10.25663/brainlife.app.441"},{"name":"Fractal Dimension (FD) of bundle masks","github":"FBK-NILab/fractal_dimension","desc":"Investigation on the fractal dimension of segmented white matter bundles.","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfa8dde14be11ff26d00e"}],"success_rate":66.66666666666666,"users":4,"runtime_mean":76441.33333333333,"runtime_std":44698.00595726341,"requested":10,"examples":0,"groups":4},"create_date":"2020-10-15T10:31:11.861Z","doi":"10.25663/brainlife.app.442"},{"name":"Parcellation Statistics","github":"brainlife/app-freesurfer-stats","desc":null,"stats":{"success_rate":80.49093438219494,"users":113,"runtime_mean":11258153.79,"runtime_std":45191300.94772274,"requested":123866,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfa92de14be11ff26d02a"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfa92de14be11ff26d02b"}],"examples":0,"groups":247},"create_date":"2020-10-24T00:15:11.187Z","doi":"10.25663/brainlife.app.443"},{"name":"Franco Python Template","github":"brainlife/app-template-python","desc":"This is a template for a python-based brainlife.io/app","stats":{"resources":[],"success_rate":60,"users":4,"runtime_mean":69566,"runtime_std":41820.37049891675,"requested":5,"examples":0,"groups":4},"create_date":"2020-11-05T19:44:38.791Z","doi":"10.25663/brainlife.app.444"},{"name":"Test Python Template for Class","github":"brainlife/app-template-python","desc":"This is a template for a python-based brainlife.io/app","stats":{"resources":[],"success_rate":60,"users":4,"runtime_mean":69566,"runtime_std":41820.37049891675,"requested":5,"examples":1,"groups":4},"create_date":"2020-11-05T21:24:00.384Z","doi":"10.25663/brainlife.app.445"},{"name":"Little Test","github":"sunaguo/brainlife-app-test","desc":"This is a template for a python-based brainlife.io/app","stats":{"resources":[],"examples":0},"create_date":"2020-11-05T22:41:11.742Z","doi":"10.25663/brainlife.app.446"},{"name":"Justin Reslice T1w App","github":"jkilmarx/app-template-python","desc":"This is a template for a python-based brainlife.io/app","stats":{"resources":[],"examples":0},"create_date":"2020-11-05T22:48:53.296Z","doi":"10.25663/brainlife.app.447"},{"name":"Warp T1 and tensor","github":"brainlife/app-warp-t1","desc":"Warp T1 and tensor volumes with a given non-linear warp.nii.gz using ANTs.","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfaadde14be11ff26d045"}],"success_rate":60.29411764705882,"users":4,"runtime_mean":133528.46341463414,"runtime_std":94405.20553782459,"requested":73,"examples":0,"groups":5},"create_date":"2020-11-09T14:24:54.317Z","doi":"10.25663/brainlife.app.448"},{"name":"CIT168 parcellation of human subcortical brain nuclei","github":"brainlife/app-CIT168Parc","desc":"A dockerized parcellation of human subcortical brain nuclei from the work of Pauli et al. 2018","stats":{"resources":[],"success_rate":79.520697167756,"users":17,"runtime_mean":4027176.53,"runtime_std":4813391.959229656,"requested":4877,"examples":1,"groups":27},"create_date":"2020-11-16T21:43:38.723Z","doi":"10.25663/brainlife.app.449"},{"name":"Create Edge Time Series","github":"JacobColbyTanner/bnbl_brainlife","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfab7de14be11ff26d06b"}],"success_rate":0,"users":1,"requested":8,"examples":0,"groups":1},"create_date":"2020-11-23T21:45:06.913Z","doi":"10.25663/brainlife.app.450"},{"name":"ABCD HCP Pipeline","github":"brainlife/app-abcd-hcp-pipeline","desc":"ABCD-BIDS pipeline used to process the BIDS input data (DCAN Labs' modified HCP pipeline)","stats":{"resources":[],"success_rate":44.642857142857146,"users":6,"runtime_mean":53381357.24,"runtime_std":16689720.004323015,"requested":139,"examples":1,"groups":5},"create_date":"2020-12-01T15:58:27.417Z","doi":"10.25663/brainlife.app.452"},{"name":"Generate Parcellation (Volume) from ROIs","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfac2de14be11ff26d11c"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfac2de14be11ff26d11d"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfac2de14be11ff26d11e"}],"success_rate":83.53765323992994,"users":27,"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"requested":13134,"examples":1,"groups":58},"create_date":"2020-12-03T21:08:06.682Z","doi":"10.25663/brainlife.app.453"},{"name":"BUAN Compute Bundles Shapes ","github":"brainlife/bl_apps_dipy_buan_shapes","desc":"BUAN shape analysis App in BrainLife","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfac7de14be11ff26d123"}],"examples":0},"create_date":"2020-12-07T17:52:44.144Z","doi":"10.25663/brainlife.app.455"},{"name":"BUAN Compute Bundles Profiles ","github":"brainlife/bl_apps_dipy_buan_profiles","desc":"BUAN bundle profiles ","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfacdde14be11ff26d126"}],"examples":0},"create_date":"2020-12-07T17:56:29.028Z","doi":"10.25663/brainlife.app.456"},{"name":"Warp DWI","github":"brainlife/app-warp-dwi","desc":"Warp DWI volumes with a given non-linear warp.nii.gz using ANTs.","stats":{"resources":[],"success_rate":94.31818181818183,"users":1,"runtime_mean":788520.9638554216,"runtime_std":590540.0829296357,"requested":153,"examples":0,"groups":2},"create_date":"2020-12-09T11:56:07.503Z","doi":"10.25663/brainlife.app.457"},{"name":"Linearly align DWI to another DWI with FSL Flirt","github":"brainlife/app-fsl-flirt","desc":null,"stats":{"resources":[],"success_rate":44.44444444444444,"users":2,"runtime_mean":10504277.5,"runtime_std":5887499.354512173,"requested":10,"examples":0,"groups":1},"create_date":"2020-12-09T16:19:45.475Z","doi":"10.25663/brainlife.app.458"},{"name":"earlyCNN","github":"roijo/NiftyNet","desc":"[unmaintained] An open-source convolutional neural networks platform for research in medical image analysis and image-guided therapy","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfadcde14be11ff26d12d"}],"success_rate":0,"users":2,"requested":3,"examples":0,"groups":2},"create_date":"2020-12-14T17:33:34.867Z","doi":"10.25663/brainlife.app.459"},{"name":"FC Identifiability/Fingerprinting Analyses","github":"joy-neuro/bnbl_brainlife","desc":"App on processing, analyzing eFC","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfae5de14be11ff26d14d"}],"examples":0},"create_date":"2020-12-16T21:31:55.331Z","doi":"10.25663/brainlife.app.460"},{"name":"Generate images of data mapped to cortical surface","github":"brainlife/app-cortex-mapping-images","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfaebde14be11ff26d200"}],"success_rate":77.08933717579251,"users":6,"runtime_mean":241933.87,"runtime_std":170279.6284897671,"requested":825,"examples":1,"groups":6},"create_date":"2020-12-21T02:55:32.999Z","doi":"10.25663/brainlife.app.461"},{"name":"Freesurfer 7.1.1","github":"brainlife/app-freesurfer","desc":"Freesurfer segments the t1w anatomical data into functionally different parts of the brain. Segmentation/parcellation can then be fed to many other subsequent analysis. ","stats":{"gitinfo":{"desc":"Freesurfer segments the t1w anatomical data into functionally different parts of the brain. Segmentation/parcellation can then be fed to many other subsequent analysis. Please consider using OSG version of Freesurfer (https://brainlife.io/app/5931c0b8ff090a00210eff09) to process a large number of subjects. ","tags":["analysis","anatomy-preprocessing"],"stats":{"stars":1},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Lindsey Kitchell","email":null}]},"success_rate":48.68517116737809,"users":431,"runtime_mean":32186778.47,"runtime_std":21686686.3444785,"requested":368573,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cfaeede14be11ff26d444"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfaeede14be11ff26d445"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfaeede14be11ff26d446"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfaeede14be11ff26d447"}],"examples":5,"groups":1071},"create_date":"2020-12-21T20:28:16.298Z","doi":"10.25663/brainlife.app.462"},{"name":"Parcellation Statistics - Volume","github":"brainlife/app-freesurfer-stats","desc":null,"stats":{"success_rate":80.49093438219494,"users":113,"runtime_mean":11258153.79,"runtime_std":45191300.94772274,"requested":123866,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfaf4de14be11ff26d563"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfaf4de14be11ff26d564"}],"examples":4,"groups":247},"create_date":"2020-12-29T01:32:32.962Z","doi":"10.25663/brainlife.app.463"},{"name":"Parcellation Statistics - Surface - Deprecated Datatype","github":"brainlife/app-freesurfer-stats","desc":null,"stats":{"success_rate":80.49093438219494,"users":113,"runtime_mean":11258153.79,"runtime_std":45191300.94772274,"requested":123866,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfaf9de14be11ff26d670"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfaf9de14be11ff26d671"}],"examples":4,"groups":247},"create_date":"2020-12-29T01:35:41.144Z","doi":"10.25663/brainlife.app.464"},{"name":"HCP Pipelines - Structural preprocessing","github":"brainlife/app-hcp-pipeline","desc":"brainlife wrapper for HCP Pipelines","stats":{"resources":[],"success_rate":26.168224299065418,"users":10,"runtime_mean":29772992.39285714,"runtime_std":15462883.03244422,"requested":134,"examples":1,"groups":9},"create_date":"2021-01-13T12:13:19.942Z","doi":"10.25663/brainlife.app.465"},{"name":"Trekker - scalar testing","github":"brainlife/app-trekker","desc":"Brainlife App (wrapper) for dMRI based fiber tracking using parallel transport tractography https://dmritrekker.github.io","stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking using parallel transport tractography https://dmritrekker.github.io","tags":[],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"success_rate":62.55144032921811,"users":11,"runtime_mean":37888004.83,"runtime_std":23561585.448650327,"requested":342,"resources":[],"examples":0,"groups":12},"create_date":"2021-01-19T19:22:56.134Z","doi":"10.25663/brainlife.app.466"},{"name":"app-brainstorm_1_import_anatomy","github":"guiomar/app-brainstorm-1_import_anatomy","desc":null,"stats":{"resources":[],"success_rate":97.72727272727273,"users":1,"runtime_mean":33776.93023255814,"runtime_std":51774.353508544074,"requested":45,"examples":0,"groups":3},"create_date":"2021-01-26T19:40:04.893Z","doi":"10.25663/brainlife.app.467"},{"name":"Network Degree Distribution","github":"brainlife/bl-network-template","desc":"Template app to build new network neuroscience apps for brainlife","stats":{"resources":[],"success_rate":0,"users":1,"requested":1,"examples":0,"groups":1},"create_date":"2021-01-29T16:05:07.516Z","doi":"10.25663/brainlife.app.468"},{"name":"MNE-BIDS-Pipeline: [1] MEEG preprocessing","github":"guiomar/app-mne-1","desc":null,"stats":{"resources":[],"success_rate":66.66666666666666,"users":2,"runtime_mean":1965100.034883721,"runtime_std":12293734.014614021,"requested":157,"examples":1,"groups":9},"create_date":"2021-01-29T18:41:58.051Z","doi":"10.25663/brainlife.app.469"},{"name":"Multi-Atlas Transfer Tool","github":"faskowit/app-multiAtlasTT","desc":"brainlife.io version of maTT","stats":{"requested":143270,"users":131,"success_rate":74.58521346754598,"gitinfo":{"desc":"brainlife.io version of maTT","tags":[],"stats":{"stars":0},"contributors":[{"name":"Josh Faskowitz","email":null},{"name":"Brent McPherson","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":1128900.81,"runtime_std":847363.4525348811,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfb19de14be11ff26d9ac"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfb19de14be11ff26d9ad"}],"examples":5,"groups":259},"create_date":"2021-01-31T16:37:48.533Z","doi":"10.25663/brainlife.app.470"},{"name":"Matlab example","github":"filipinascimento/bl-network-template-matlab","desc":"Example template for network analyses using matlab inside brainlife.","stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cfb1ede14be11ff26d9b2"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfb1ede14be11ff26d9b3"}],"success_rate":20,"users":1,"runtime_mean":237778,"runtime_std":0,"requested":5,"examples":0,"groups":2},"create_date":"2021-02-05T15:23:45.640Z","doi":"10.25663/brainlife.app.471"},{"name":"Network Plot Degree Distribution","github":"filipinascimento/bl-network-template-matlab","desc":"Example template for network analyses using matlab inside brainlife.","stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cfb23de14be11ff26d9b6"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfb23de14be11ff26d9b7"}],"success_rate":20,"users":1,"runtime_mean":237778,"runtime_std":0,"requested":5,"examples":0,"groups":2},"create_date":"2021-02-05T16:25:19.709Z","doi":"10.25663/brainlife.app.472"},{"name":"app-test","github":"AuroreBussalb/app-test","desc":"This a little App to test registration steps on Brainlife and to test how to run it.","stats":{"resources":[],"success_rate":57.714285714285715,"users":2,"runtime_mean":61031.74,"runtime_std":168248.07326864815,"requested":194,"examples":1,"groups":2},"create_date":"2021-02-08T10:00:35.027Z","doi":"10.25663/brainlife.app.473"},{"name":"Tract Analysis Profiles - Dipy","github":"brainlife/app-tractanalysisprofiles","desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","stats":{"requested":19317,"users":42,"success_rate":77.25239616613419,"gitinfo":{"desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":2138024.52,"runtime_std":9002049.390707558,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cfb2ede14be11ff26daf1"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfb2ede14be11ff26daf2"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfb2ede14be11ff26daf3"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfb2ede14be11ff26daf4"}],"examples":0,"groups":90},"create_date":"2021-02-10T02:29:35.419Z","doi":"10.25663/brainlife.app.474"},{"name":"Extract shell from DWI image","github":"brainlife/app-mrtrix3-split-b0s","desc":null,"stats":{"success_rate":94.21965317919076,"users":5,"runtime_mean":75464.94,"runtime_std":280158.39896675665,"requested":189,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfb33de14be11ff26dafb"}],"examples":0,"groups":15},"create_date":"2021-02-13T20:01:01.159Z","doi":"10.25663/brainlife.app.475"},{"name":"Apply Maxwell filter on MEG signals using MNE-python","github":"brainlife/app-maxwell-filter","desc":"Apply Maxwell filtering on MEG signals recorded with Elketa (or MEGIN or Neuromag) machine using MNE Python. ","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfb38de14be11ff26db93"}],"success_rate":46.60159074475777,"users":3,"runtime_mean":68082.01,"runtime_std":71585.12533026606,"requested":2778,"examples":3,"groups":12},"create_date":"2021-02-16T13:20:35.558Z","doi":"10.25663/brainlife.app.476"},{"name":"EFC identifiability","github":"joy-neuro/bnbl_brainlife","desc":"App on processing, analyzing eFC","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfb3ede14be11ff26db98"}],"examples":0},"create_date":"2021-02-19T04:26:52.403Z","doi":"10.25663/brainlife.app.477"},{"name":"Compute myelin map using T1w / T2w ratio","github":"brainlife/app-myelin-mapping","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cfb43de14be11ff26dc95"}],"success_rate":79.62466487935657,"users":9,"runtime_mean":7336108.39,"runtime_std":8985566.546634642,"requested":809,"examples":3,"groups":17},"create_date":"2021-02-23T19:46:18.762Z","doi":"10.25663/brainlife.app.478"},{"name":"Cortex Tissue Mapping (Native Space) - Myelin Mapping (T1w/T2w ratio)","github":"brainlife/app-cortex-tissue-mapping","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","stats":{"requested":19134,"users":16,"success_rate":76.52514036969276,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":250899.08,"runtime_std":392917.6303011785,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfb49de14be11ff26dd17"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfb49de14be11ff26dd18"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfb49de14be11ff26dd19"}],"examples":1,"groups":44},"create_date":"2021-02-23T20:57:37.747Z","doi":"10.25663/brainlife.app.479"},{"name":"Cortex Tissue Mapping (Native & Template Space) - Myelin Mapping (T1w/T2w ratio)","github":"brainlife/app-cortex-tissue-mapping","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","stats":{"requested":19134,"users":16,"success_rate":76.52514036969276,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":250899.08,"runtime_std":392917.6303011785,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfb4ede14be11ff26dd1d"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfb4ede14be11ff26dd1e"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfb4ede14be11ff26dd1f"}],"examples":0,"groups":44},"create_date":"2021-02-23T21:00:13.754Z","doi":"10.25663/brainlife.app.480"},{"name":"Fit qT1 models using mrQ","github":"brainlife/app-qt1-mrq","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfb54de14be11ff26dd23"}],"examples":0},"create_date":"2021-02-24T21:52:12.157Z","doi":"10.25663/brainlife.app.481"},{"name":"Network Aggregate","github":"filipinascimento/bl-network-template-matlab","desc":"Example template for network analyses using matlab inside brainlife.","stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cfb59de14be11ff26dd26"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfb59de14be11ff26dd27"}],"success_rate":20,"users":1,"runtime_mean":237778,"runtime_std":0,"requested":5,"examples":0,"groups":2},"create_date":"2021-02-26T15:39:56.318Z","doi":"10.25663/brainlife.app.482"},{"name":"Compute summary statistics of diffusion measures mapped to cortical surface","github":"brainlife/app-cortex-tissue-mapping-stats","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfb61de14be11ff26e100"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfb61de14be11ff26e101"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfb61de14be11ff26e102"}],"success_rate":44.93765121905825,"users":12,"runtime_mean":817560.56,"runtime_std":2302860.854492113,"requested":38152,"examples":2,"groups":27},"create_date":"2021-02-28T02:42:16.720Z","doi":"10.25663/brainlife.app.483"},{"name":"Parcellation Statistics - Surface","github":"brainlife/app-freesurfer-stats","desc":null,"stats":{"success_rate":80.49093438219494,"users":113,"runtime_mean":11258153.79,"runtime_std":45191300.94772274,"requested":123866,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfb67de14be11ff26e122"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfb67de14be11ff26e123"}],"examples":0,"groups":247},"create_date":"2021-02-28T02:48:27.162Z","doi":"10.25663/brainlife.app.484"},{"name":"PyNets","github":"brainlife/app-pynets","desc":"A Reproducible post-processing workflow for Structural and Functional Connectome Ensemble Learning. PyNets  leverages Nilearn and Dipy fMRI and dMRI libraries to specify any of a variety of methodological choices and sampling individual structural and functional connectome estimates. See https://pynets.readthedocs.io/","stats":{"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cfb6cde14be11ff26e2ab"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfb6cde14be11ff26e2ac"}],"success_rate":9.289146236294197,"users":10,"runtime_mean":22212223.2,"runtime_std":15784124.287120411,"requested":12970,"examples":5,"groups":22},"create_date":"2021-03-05T09:18:09.192Z","doi":"10.25663/brainlife.app.486"},{"name":"Test bl2bids conversion","github":"giulia-berto/abcd-spec","desc":"Application for Big Computational Data Specification (v1.1). This specification provide information on how to write an Application that can run on the open platform","stats":{"resources":[],"success_rate":79.62962962962963,"users":3,"runtime_mean":28891.837209302324,"runtime_std":49086.97218105566,"requested":60,"examples":1,"groups":10},"create_date":"2021-03-08T11:23:18.958Z","doi":"10.25663/brainlife.app.487"},{"name":"Brainstorm: MEG preprocessing","github":"guiomar/app-brainstorm-2_meg_preprocessing","desc":null,"stats":{"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cfb77de14be11ff26e2e9"}],"success_rate":90.69767441860465,"users":1,"runtime_mean":1427644.8717948718,"runtime_std":5580119.07053104,"requested":117,"examples":1,"groups":4},"create_date":"2021-03-08T21:23:33.375Z","doi":"10.25663/brainlife.app.488"},{"name":"Edge time series","github":"FarnazZE/bnbl-brainlife-create-edge-time-series","desc":null,"stats":{"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cfb7cde14be11ff26e33c"}],"success_rate":40.32258064516129,"users":1,"runtime_mean":389877.32,"runtime_std":294985.875661018,"requested":69,"examples":2,"groups":1},"create_date":"2021-03-10T17:12:05.446Z","doi":"10.25663/brainlife.app.489"},{"name":"Generate images of fMRI overlaid on T1","github":"brainlife/app-slicer-fsl","desc":null,"stats":{"success_rate":82.31619858418544,"users":118,"runtime_mean":274514.93,"runtime_std":622047.7772298245,"requested":23119,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cfb82de14be11ff26e363"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfb82de14be11ff26e364"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfb82de14be11ff26e365"}],"examples":1,"groups":185},"create_date":"2021-03-12T16:50:07.506Z","doi":"10.25663/brainlife.app.490"},{"name":"LiFE - Multishell","github":"bcmcpher/app-life-dev","desc":"dev version of life app for testing my fork","stats":{"resources":[],"success_rate":88.94952251023193,"users":1,"runtime_mean":33781361.54,"runtime_std":8658796.84671172,"requested":1341,"examples":3,"groups":3},"create_date":"2021-03-12T19:22:21.564Z","doi":"10.25663/brainlife.app.491"},{"name":"Convert wmc to labels","github":"brainlife/app-convert-wmc2labels","desc":"Convert wmc to labels","stats":{"resources":[],"success_rate":83.33333333333334,"users":2,"runtime_mean":544266.8,"runtime_std":207687.733902029,"requested":13,"examples":0,"groups":2},"create_date":"2021-03-18T17:14:08.761Z","doi":"10.25663/brainlife.app.492"},{"name":" MAIA microperimetry analysis","github":"brainlife/app-maiaRings","desc":"A brainlife.io app for computing the degree-based ring averages for microperimetry measurements ","stats":{"resources":[],"success_rate":61.00840336134454,"users":4,"runtime_mean":87298.85,"runtime_std":268959.28725431196,"requested":672,"examples":1,"groups":3},"create_date":"2021-03-24T19:21:39.729Z","doi":"10.25663/brainlife.app.493"},{"name":"Detect bad channels in MEG signals using Maxwell Filtering","github":"guiomar/app-bad-channels","desc":"Detect bad channels in MEG signals.","stats":{"resources":[],"success_rate":94.38775510204081,"users":2,"runtime_mean":209953.17,"runtime_std":104105.50366278001,"requested":2901,"examples":2,"groups":7},"create_date":"2021-03-26T16:23:50.381Z","doi":"10.25663/brainlife.app.494"},{"name":"Remove first volumes of fMRI","github":"amnsbr/app-remove-first-volumes","desc":"Simple Brainlife app which removes the first volumes of fMRI images","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfb9cde14be11ff26e525"}],"success_rate":95.6386292834891,"users":3,"runtime_mean":205693.68,"runtime_std":1284647.7711051689,"requested":321,"examples":0,"groups":3},"create_date":"2021-04-01T11:11:34.900Z","doi":"10.25663/brainlife.app.495"},{"name":"Compute mean transformation across MEG runs","github":"brainlife/app-mean-transformation-matrix","desc":"Compute mean transformation matrix across MEG runs.","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfba1de14be11ff26e569"}],"success_rate":63.41463414634146,"users":1,"runtime_mean":31031.73076923077,"runtime_std":19647.396354337587,"requested":51,"examples":1},"create_date":"2021-04-01T13:47:21.173Z","doi":"10.25663/brainlife.app.496"},{"name":"Apply a temporal filter (lowpass, highpass, or bandpass) on MEG signals (epoched or continuous)","github":"guiomar/app-temporal-filtering","desc":"Filter MEG signals using MNE Python","stats":{"resources":[],"users":1,"requested":1,"examples":1,"groups":1},"create_date":"2021-04-02T09:58:10.669Z","doi":"10.25663/brainlife.app.497"},{"name":"Track Density Masks","github":"brainlife/app-tractDensityMasks","desc":"This app creates a streamline density mask (NIfTI format) for each structure labeled in a classification structure.  This provides information about the volumetric density of streamline models of tracts.","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfbacde14be11ff26e679"}],"success_rate":94.99036608863199,"users":4,"runtime_mean":701751.14,"runtime_std":177882.95110262927,"requested":1361,"examples":0,"groups":6},"create_date":"2021-04-03T19:16:32.075Z","doi":"10.25663/brainlife.app.498"},{"name":"Compute headshape.pos file from cHPI recorded during MEG acquisition","github":"brainlife/app-head-pos","desc":"Compute time varying head positions from MEG signals when cHPI were recorded.","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfbb1de14be11ff26e687"}],"success_rate":100,"users":1,"runtime_mean":35908,"runtime_std":5050.392525999011,"requested":3,"examples":1,"groups":2},"create_date":"2021-04-09T08:17:04.657Z","doi":"10.25663/brainlife.app.499"},{"name":"Structural Networks (count)","github":"bcmcpher/app-StructuralCountNetwork","desc":null,"stats":{"resources":[],"success_rate":24.818986323411103,"users":4,"runtime_mean":17158826.72,"runtime_std":34649099.26803448,"requested":4284,"examples":3,"groups":7},"create_date":"2021-04-09T15:19:36.638Z","doi":"10.25663/brainlife.app.503"},{"name":"FSL Reorient and Crop T1","github":"brainlife/app-crop_reorient","desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","stats":{"requested":11099,"users":106,"success_rate":94.52861952861953,"gitinfo":{"desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","tags":[],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":464343.13,"runtime_std":3265360.1856333264,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfbbbde14be11ff26e843"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfbbbde14be11ff26e844"}],"examples":3,"groups":163},"create_date":"2021-04-09T16:23:39.597Z","doi":"10.25663/brainlife.app.500"},{"name":"FSL Reorient and Crop T2","github":"brainlife/app-crop_reorient","desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","stats":{"requested":11099,"users":106,"success_rate":94.52861952861953,"gitinfo":{"desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","tags":[],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":464343.13,"runtime_std":3265360.1856333264,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfbc0de14be11ff26e878"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfbc0de14be11ff26e879"}],"examples":1,"groups":163},"create_date":"2021-04-09T16:43:10.409Z","doi":"10.25663/brainlife.app.501"},{"name":"FSL Reorient - Task","github":"brainlife/app-crop_reorient","desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","stats":{"requested":11099,"users":106,"success_rate":94.52861952861953,"gitinfo":{"desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","tags":[],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":464343.13,"runtime_std":3265360.1856333264,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfbc6de14be11ff26e895"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfbc6de14be11ff26e896"}],"examples":1,"groups":163},"create_date":"2021-04-09T16:45:48.597Z","doi":"10.25663/brainlife.app.502"},{"name":"Apply a notch filter on continuous MEG data","github":"brainlife/app-notch-filter","desc":"Notch filter MEG data stored in a .fif file using MNE Python.","stats":{"resources":[],"success_rate":0,"users":2,"requested":5,"examples":2,"groups":2},"create_date":"2021-04-14T14:45:52.429Z","doi":"10.25663/brainlife.app.504"},{"name":"Resample MEG signals (epoched or continuous)","github":"AuroreBussalb/app-resampling","desc":"Resample MEG signals using MNE Python.","stats":{"resources":[],"success_rate":60.60606060606061,"users":1,"runtime_mean":61020.8,"runtime_std":14997.436469610397,"requested":33,"examples":1,"groups":1},"create_date":"2021-04-15T08:05:05.803Z","doi":"10.25663/brainlife.app.505"},{"name":"Create fixed length events or extract them from MEG signals","github":"brainlife/app-get-events","desc":"Extract existing events from a fif file or create new events and store them in a .tsv file.","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfbd4de14be11ff26e936"}],"success_rate":80.48780487804879,"users":1,"runtime_mean":28526.21212121212,"runtime_std":12694.015000534404,"requested":41,"examples":1},"create_date":"2021-04-16T09:33:21.385Z","doi":"10.25663/brainlife.app.507"},{"name":"Epoch continuous MEG signals","github":"brainlife/app-make-epochs","desc":"Create epochs in MEG data","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfbd9de14be11ff26e974"}],"success_rate":42.62295081967213,"users":1,"runtime_mean":33877.03846153846,"runtime_std":12824.343553392657,"requested":61,"examples":1},"create_date":"2021-04-16T14:13:51.508Z","doi":"10.25663/brainlife.app.508"},{"name":"Denoise MP2RAGE UNI ","github":"svincibo/app-mp2rage-denoiseUNI","desc":"Removes noise in an MP2RAGE_UNI.nii.gz image given a user-provided regularization parameter (see app-mp2rage-selectregparam).","stats":{"resources":[],"success_rate":40.08567931456548,"users":5,"runtime_mean":175744.11,"runtime_std":444924.67103798356,"requested":2315,"examples":2,"groups":4},"create_date":"2021-04-20T17:59:30.897Z","doi":"10.25663/brainlife.app.506"},{"name":"Align mp2rage volumes to T1 using FSL Flirt","github":"brainlife/app-align-mp2rage-to-t1","desc":null,"stats":{"resources":[],"success_rate":50,"users":1,"runtime_mean":431592.5,"runtime_std":347707.5,"requested":6,"examples":1,"groups":1},"create_date":"2021-04-22T18:34:59.755Z","doi":"10.25663/brainlife.app.509"},{"name":"Align T2  to T1 using FSL Flirt","github":"brainlife/app-align-t2-to-t1","desc":null,"stats":{"resources":[],"success_rate":40,"users":3,"runtime_mean":619667,"runtime_std":481310,"requested":23,"examples":0,"groups":3},"create_date":"2021-04-22T19:06:19.669Z","doi":"10.25663/brainlife.app.510"},{"name":"Align mp2rage to ACPC Plane (HCP-based)","github":"brainlife/app-hcp-acpc-alignment","desc":"This app will align a T1w image to the ACPC plane (specifically, the MNI152_T1_1mm template from FSL using a 6 DOF alignment via FSL commands. This protocol was adapted from the HCP Preprocessing Pipeline (https://github.com/Washington-University/HCPpipelines.git). Requires a T1w image input and outputs an acpc_aligned T1w image.","stats":{"requested":99085,"users":148,"success_rate":87.43401733114742,"gitinfo":{"desc":"This app will align a T1w image to the ACPC plane (specifically, the MNI152_T1_1mm template from FSL using a 6 DOF alignment via FSL commands. This protocol was adapted from the HCP Preprocessing Pipeline (https://github.com/Washington-University/HCPpipelines.git). Requires a T1w image input and outputs an acpc_aligned T1w image.","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Josh Faskowitz","email":null}]},"runtime_mean":34232313.61,"runtime_std":84465148.88505387,"resources":[],"examples":1,"groups":296},"create_date":"2021-04-23T20:12:39.566Z","doi":"10.25663/brainlife.app.511"},{"name":"FSL Anat (mp2rage)","github":"brainlife/app-fsl-anat","desc":null,"stats":{"success_rate":57.867899513886535,"users":115,"runtime_mean":11434850.57,"runtime_std":27696166.450184193,"requested":35442,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cfbf3de14be11ff26ea73"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfbf3de14be11ff26ea74"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfbf3de14be11ff26ea75"}],"examples":0,"groups":218},"create_date":"2021-04-23T20:48:22.773Z","doi":"10.25663/brainlife.app.512"},{"name":"Hippunfold (T1w)","github":"akhanf/app-hippunfold-t1","desc":"Brainlife app for hippunfold","stats":{"resources":[],"success_rate":33.33333333333333,"users":1,"runtime_mean":5152146.5,"runtime_std":1592094.5,"requested":11,"examples":1,"groups":2},"create_date":"2021-04-26T22:39:02.041Z","doi":"10.25663/brainlife.app.513"},{"name":"Compute T1 and R1 maps from MP2RAGE","github":"svincibo/app-mp2rage-computeT1andR1","desc":"Computes T1map and R1map images when provided a denoised mp2rage t1 image (see app-mp2rage-denoiseUNI).","stats":{"resources":[],"success_rate":71.80555555555556,"users":3,"runtime_mean":247269.01,"runtime_std":713593.3964819531,"requested":726,"examples":2,"groups":3},"create_date":"2021-04-29T20:35:23.263Z","doi":"10.25663/brainlife.app.514"},{"name":"Cortex Tissue Mapping (Native Space) - Myelin Mapping (T1w/T2w ratio) (No SNR masking)","github":"brainlife/app-cortex-tissue-mapping","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","stats":{"requested":19134,"users":16,"success_rate":76.52514036969276,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":250899.08,"runtime_std":392917.6303011785,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfc03de14be11ff26eb70"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfc03de14be11ff26eb71"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfc03de14be11ff26eb72"}],"examples":0,"groups":44},"create_date":"2021-05-01T19:08:45.840Z","doi":"10.25663/brainlife.app.515"},{"name":"Cortex Tissue Mapping (Native & Template Space) - Myelin Mapping (T1w/T2w ratio) (No SNR masking)","github":"brainlife/app-cortex-tissue-mapping","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","stats":{"requested":19134,"users":16,"success_rate":76.52514036969276,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":250899.08,"runtime_std":392917.6303011785,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfc08de14be11ff26eb76"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfc08de14be11ff26eb77"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfc08de14be11ff26eb78"}],"examples":0,"groups":44},"create_date":"2021-05-01T19:14:04.388Z","doi":"10.25663/brainlife.app.516"},{"name":"BROCCOLI (experimental)","github":"brainlife/app-broccoli","desc":"Fast fMRI analysis on many-core CPUs and GPUs.","stats":{"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"642cfc0dde14be11ff26eb89"}],"success_rate":32.467532467532465,"users":2,"runtime_mean":387174.52,"runtime_std":95035.50390422308,"requested":79,"examples":1,"groups":3},"create_date":"2021-05-04T11:21:02.091Z","doi":"10.25663/brainlife.app.517"},{"name":"Clean parcellations","github":"brainlife/app-clean-parcellation","desc":null,"stats":{"resources":[],"success_rate":16.666666666666664,"users":1,"runtime_mean":1576384,"runtime_std":1565256,"requested":18,"examples":1,"groups":1},"create_date":"2021-05-05T01:56:04.722Z","doi":"10.25663/brainlife.app.518"},{"name":"Convert ctf file to fif","github":"brainlife/app-ctf2fif","desc":"Convert ctf files into fif format","stats":{"resources":[],"success_rate":100,"users":1,"runtime_mean":50429.333333333336,"runtime_std":14681.773674260963,"requested":3,"examples":1,"groups":2},"create_date":"2021-05-11T16:01:14.908Z","doi":"10.25663/brainlife.app.519"},{"name":"MNE-BIDS-Pipeline: [2] MEEG sensor analysis","github":"guiomar/app-mne-2","desc":null,"stats":{"resources":[],"success_rate":63.1578947368421,"users":1,"runtime_mean":24321,"runtime_std":13803.239988012476,"requested":19,"examples":1,"groups":1},"create_date":"2021-05-17T18:47:41.565Z","doi":"10.25663/brainlife.app.520"},{"name":"MNE-BIDS-Pipeline: [3] MEEG source analysis","github":"guiomar/app-mne-3","desc":null,"stats":{"resources":[],"success_rate":100,"users":1,"runtime_mean":10735,"runtime_std":1000.6597823436296,"requested":5,"examples":1,"groups":1},"create_date":"2021-05-18T16:22:12.270Z","doi":"10.25663/brainlife.app.521"},{"name":"Reslice ROIs to match input anatomy","github":"bacaron/app-reslice-roi-t1","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfc29de14be11ff26ed42"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfc29de14be11ff26ed43"}],"success_rate":36.64942300039793,"users":4,"runtime_mean":578251.76,"runtime_std":1161990.5048332633,"requested":12030,"examples":3,"groups":9},"create_date":"2021-05-19T22:28:04.670Z","doi":"10.25663/brainlife.app.522"},{"name":"Tract Analysis Profiles - Myelin mapping","github":"brainlife/app-tractanalysisprofiles","desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","stats":{"requested":19317,"users":42,"success_rate":77.25239616613419,"gitinfo":{"desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":2138024.52,"runtime_std":9002049.390707558,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cfc2ede14be11ff26ed46"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfc2ede14be11ff26ed47"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfc2ede14be11ff26ed48"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfc2ede14be11ff26ed49"}],"examples":0,"groups":90},"create_date":"2021-05-20T18:22:49.062Z","doi":"10.25663/brainlife.app.523"},{"name":"Convert tractmeasures datatype to tractprofile datatype","github":"brainlife/app-convert-tractmeasures-2-tractprofile","desc":null,"stats":{"resources":[],"examples":0,"success_rate":0,"users":1,"requested":1,"groups":1},"create_date":"2021-05-20T21:01:49.111Z","doi":"10.25663/brainlife.app.524"},{"name":"Extract diffusion metrics inside ROIs","github":"brainlife/app-extract-diffusion-metrics-rois","desc":null,"stats":{"success_rate":95.79349904397706,"users":7,"runtime_mean":273055.13,"runtime_std":911261.5527963601,"requested":568,"resources":[],"examples":1,"groups":20},"create_date":"2021-05-21T20:04:33.542Z","doi":"10.25663/brainlife.app.525"},{"name":"[WIP] Create animation from trk","github":"soichih/app-trk2mp4","desc":"Generate animation of trk streamlines","stats":{"resources":[],"success_rate":25,"users":1,"runtime_mean":21860,"runtime_std":0,"requested":6,"examples":0,"groups":1},"create_date":"2021-05-21T21:33:54.300Z","doi":"10.25663/brainlife.app.526"},{"name":"Make GIFs from ROIs","github":"brainlife/app-gifsFromNIfTI","desc":null,"stats":{"resources":[],"examples":0},"create_date":"2021-05-24T16:31:47.550Z","doi":"10.25663/brainlife.app.527"},{"name":"Fit Tensor Model using MRTrix3","github":"brainlife/app-mrtrix3-tensor-fit","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cfc4cde14be11ff26f1a4"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfc4cde14be11ff26f1a5"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfc4cde14be11ff26f1a6"}],"success_rate":70.18348623853211,"users":8,"runtime_mean":661984.5,"runtime_std":4456634.0458812285,"requested":338,"examples":1,"groups":12},"create_date":"2021-05-25T17:52:09.513Z","doi":"10.25663/brainlife.app.528"},{"name":"Split MEG file","github":"guiomar/app-meg-split-fif","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfc52de14be11ff26f279"}],"success_rate":86.63551401869158,"users":1,"runtime_mean":23190.87,"runtime_std":20948.441733291285,"requested":5368,"examples":2,"groups":9},"create_date":"2021-05-28T18:44:00.559Z","doi":"10.25663/brainlife.app.529"},{"name":"PSD: Power Spectral Density (Welch method)","github":"guiomar/app-psd","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfc57de14be11ff26f30a"}],"success_rate":80.14981273408239,"users":4,"runtime_mean":15771.24,"runtime_std":10629.207536895683,"requested":316,"examples":3,"groups":14},"create_date":"2021-06-02T10:08:31.318Z","doi":"10.25663/brainlife.app.530"},{"name":"Find frequency peak of PSD data","github":"guiomar/app-peak-frequency","desc":"Detect individual alpha peak in MEG signals","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfc5dde14be11ff26f457"}],"success_rate":89.67903293038766,"users":1,"runtime_mean":13171.74,"runtime_std":3860.977911410527,"requested":14438,"examples":5,"groups":5},"create_date":"2021-06-03T08:40:24.032Z","doi":"10.25663/brainlife.app.531"},{"name":"Time series to network","github":"filipinascimento/bl-timeseries2network","desc":"Calculates a similarity matrix (such as correlation, covariance, etc) from time series and convert it to a network datatype (JGFZ) so it can be used in the network pipeline.","stats":{"resources":[{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfc64de14be11ff26f74b"}],"success_rate":76.78471051152333,"users":11,"runtime_mean":332109.78,"runtime_std":1601688.4664944776,"requested":3779,"examples":5,"groups":20},"create_date":"2021-06-03T23:11:45.467Z","doi":"10.25663/brainlife.app.532"},{"name":"app-helloworld1","github":"M-ballabio1/app-helloworld1","desc":"prova","stats":{"resources":[],"success_rate":null,"users":1,"runtime_mean":null,"runtime_std":null,"requested":3},"create_date":"2021-06-09T09:13:43.396Z","doi":"10.25663/brainlife.app.533"},{"name":"Structural Networks (Microstructure Properties - Tensor)","github":"bcmcpher/app-StructuralPropertyNetwork","desc":null,"stats":{"resources":[],"success_rate":33.33333333333333,"users":1,"runtime_mean":504298,"runtime_std":0,"requested":3,"examples":1,"groups":1},"create_date":"2021-06-09T14:24:38.353Z","doi":"10.25663/brainlife.app.534"},{"name":"DBB_preprocessing_t1w","github":"FBK-NILab/bl_app_dbb_preproc_t1w","desc":"Brainlife App for the preprocessing of T1w MRI data of Distorted Brain Benchmark ","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfc73de14be11ff26f7a1"}],"success_rate":100,"users":2,"runtime_mean":65167,"runtime_std":187,"requested":2,"examples":1,"groups":2},"create_date":"2021-06-17T15:27:28.243Z","doi":"10.25663/brainlife.app.535"},{"name":"Split MEG file [ctf]","github":"guiomar/app-meg-split-ctf","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfc78de14be11ff26f7b4"}],"success_rate":27.083333333333332,"users":2,"runtime_mean":49553.692307692305,"runtime_std":121278.80699153476,"requested":51,"examples":1,"groups":5},"create_date":"2021-06-21T12:57:25.179Z","doi":"10.25663/brainlife.app.536"},{"name":"MEG filter [ctf]","github":"guiomar/app-meg-filter","desc":null,"stats":{"resources":[],"success_rate":0,"users":1,"requested":1,"examples":0,"groups":1},"create_date":"2021-06-28T18:21:36.123Z","doi":"10.25663/brainlife.app.537"},{"name":"EEG Data Quality","github":"dungscout96/app-test-brainlife","desc":null,"stats":{"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cfc83de14be11ff26f7bd"}],"success_rate":4.761904761904762,"users":5,"runtime_mean":10021615,"runtime_std":0,"requested":27,"examples":1,"groups":6},"create_date":"2021-06-30T16:11:50.423Z","doi":"10.25663/brainlife.app.538"},{"name":"Reslice ROIs to match input anatomy (with affine)","github":"bacaron/app-reslice-roi-t1","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfc89de14be11ff26f87b"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfc89de14be11ff26f87c"}],"success_rate":36.64942300039793,"users":4,"runtime_mean":578251.76,"runtime_std":1161990.5048332633,"requested":12030,"examples":2,"groups":9},"create_date":"2021-07-06T20:59:26.811Z","doi":"10.25663/brainlife.app.539"},{"name":"BUAN Bundle Profiles","github":"BramshQamar/brainlife_buan_bundle_profile","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfc8ede14be11ff26f87f"}],"success_rate":0,"users":1,"requested":1,"examples":0,"groups":1},"create_date":"2021-07-07T19:49:56.970Z","doi":"10.25663/brainlife.app.540"},{"name":"DBB_ANTsCortThickSeg","github":"FBK-NILab/bl_app_dbb_ANTsCTSeg","desc":"A tool that performs the antsCorticalThickness.sh script on a T1-w image using PTBP priors in order to obtain the brain tissue segmentation.","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfc93de14be11ff26f89b"}],"success_rate":42.857142857142854,"users":5,"runtime_mean":2179465.6666666665,"runtime_std":1434055.4931397256,"requested":8,"examples":1,"groups":6},"create_date":"2021-07-14T15:50:04.885Z","doi":"10.25663/brainlife.app.541"},{"name":"FSL Eddy-correct","github":"brainlife/app-FSLTopupEddy","desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","stats":{"requested":3399,"users":24,"success_rate":58.620689655172406,"gitinfo":{"desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","tags":["preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"runtime_mean":5133032.47,"runtime_std":8164410.893760923,"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"642cfc99de14be11ff26f903"}],"examples":2,"groups":45},"create_date":"2021-07-14T17:17:49.411Z","doi":"10.25663/brainlife.app.542"},{"name":"FSL Eddy (OpenMP)","github":"brainlife/app-FSLTopupEddy","desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","stats":{"requested":3399,"users":24,"success_rate":58.620689655172406,"gitinfo":{"desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","tags":["preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"runtime_mean":5133032.47,"runtime_std":8164410.893760923,"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"642cfc9ede14be11ff26f90d"}],"examples":1,"groups":45},"create_date":"2021-07-14T23:44:40.707Z","doi":"10.25663/brainlife.app.543"},{"name":"FSL Eddy (CUDA)","github":"brainlife/app-FSLTopupEddy","desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","stats":{"requested":3399,"users":24,"success_rate":58.620689655172406,"gitinfo":{"desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","tags":["preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"runtime_mean":5133032.47,"runtime_std":8164410.893760923,"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"642cfca3de14be11ff26f917"}],"examples":1,"groups":45},"create_date":"2021-07-14T23:56:07.010Z","doi":"10.25663/brainlife.app.544"},{"name":"Intersect Tracts with ROI - deprecated","github":"brainlife/app-intersect-tract-roi","desc":null,"stats":{"success_rate":90.88105726872246,"users":6,"runtime_mean":3140432.85,"runtime_std":7330286.616514233,"requested":3446,"resources":[],"examples":0,"groups":9},"create_date":"2021-07-16T22:23:11.490Z","doi":"10.25663/brainlife.app.545"},{"name":"Generate ROIs in FMRI Space","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"success_rate":83.53765323992994,"users":27,"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"requested":13134,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfcaede14be11ff26f933"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfcaede14be11ff26f934"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfcaede14be11ff26f935"}],"examples":0,"groups":58},"create_date":"2021-07-19T15:56:42.355Z","doi":"10.25663/brainlife.app.546"},{"name":"DBB_DisSeg","github":"FBK-NILab/bl_app_dbb_DisSeg","desc":"3D U-Net for brain tissue segmentation","stats":{"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"642cfcb3de14be11ff26f97f"}],"success_rate":75.38461538461539,"users":2,"runtime_mean":213074.3469387755,"runtime_std":391114.53703077574,"requested":74,"examples":1,"groups":1},"create_date":"2021-07-21T14:47:48.675Z","doi":"10.25663/brainlife.app.548"},{"name":"Generate ROIs in Anatomical Space","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"success_rate":83.53765323992994,"users":27,"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"requested":13134,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfcb9de14be11ff26f9ea"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfcb9de14be11ff26f9eb"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfcb9de14be11ff26f9ec"}],"examples":1,"groups":58},"create_date":"2021-07-21T15:37:17.317Z","doi":"10.25663/brainlife.app.549"},{"name":"Generate surface visualizations of ROIs for WMC Datatype Viewer","github":"brainlife/app-trekker-roi-tracking","desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","stats":{"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cfcc0de14be11ff26fa9f"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfcc0de14be11ff26faa0"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfcc0de14be11ff26faa1"}],"success_rate":45.722171113155476,"users":16,"runtime_mean":36733933.86,"runtime_std":20438070.958943717,"requested":6027,"examples":0,"groups":27},"create_date":"2021-07-26T15:05:34.772Z","doi":"10.25663/brainlife.app.550"},{"name":"Resample cortexmap data to a standard mesh using Connectome Workbench","github":"brainlife/app-cortex-tissue-mapping","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfcc7de14be11ff26fc8d"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfcc7de14be11ff26fc8e"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfcc7de14be11ff26fc8f"}],"success_rate":76.52514036969276,"users":16,"runtime_mean":250899.08,"runtime_std":392917.6303011785,"requested":19134,"examples":4,"groups":44},"create_date":"2021-07-28T18:55:32.736Z","doi":"10.25663/brainlife.app.551"},{"name":"Compute average cortexmap data for group analysis","github":"brainlife/app-cortex-tissue-mapping","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfcd4de14be11ff270380"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfcd4de14be11ff270381"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfcd4de14be11ff270382"}],"success_rate":76.52514036969276,"users":16,"runtime_mean":250899.08,"runtime_std":392917.6303011785,"requested":19134,"examples":1,"groups":44},"create_date":"2021-07-29T18:32:25.225Z","doi":"10.25663/brainlife.app.552"},{"name":"Compute summary statistics of diffusion measures from Parcellation (volume)","github":"brainlife/app-freesurfer-stats","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfcdbde14be11ff270587"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfcdbde14be11ff270588"}],"success_rate":80.49093438219494,"users":113,"runtime_mean":11258153.79,"runtime_std":45191300.94772274,"requested":123866,"examples":1,"groups":247},"create_date":"2021-08-03T19:06:21.038Z","doi":"10.25663/brainlife.app.553"},{"name":"Compute summary statistics of diffusion measures from Freesurfer Parcellation (volume)","github":"brainlife/app-freesurfer-stats","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfce2de14be11ff2706f0"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfce2de14be11ff2706f1"}],"success_rate":80.49093438219494,"users":113,"runtime_mean":11258153.79,"runtime_std":45191300.94772274,"requested":123866,"examples":0,"groups":247},"create_date":"2021-08-03T19:33:33.272Z","doi":"10.25663/brainlife.app.554"},{"name":"Generate images of tract endpoints on cortical surface","github":"brainlife/app-cortex-mapping-images","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfce7de14be11ff270719"}],"success_rate":77.08933717579251,"users":6,"runtime_mean":241933.87,"runtime_std":170279.6284897671,"requested":825,"examples":1,"groups":6},"create_date":"2021-08-04T01:26:43.064Z","doi":"10.25663/brainlife.app.555"},{"name":"Segment Wholebrain Tractogram with ROIs","github":"brainlife/app-intersect-tract-roi","desc":null,"stats":{"success_rate":90.88105726872246,"users":6,"runtime_mean":3140432.85,"runtime_std":7330286.616514233,"requested":3446,"resources":[],"examples":1,"groups":9},"create_date":"2021-08-06T03:31:43.528Z","doi":"10.25663/brainlife.app.556"},{"name":"DWI Debias","github":"brainlife/app-dwi-debias","desc":"Performs mrtrix's dwibiascorrect on dwi data","stats":{"success_rate":77.8048780487805,"users":6,"runtime_mean":85627.02,"runtime_std":83766.37883434858,"requested":418,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfcf4de14be11ff2709f5"}],"examples":2,"groups":9},"create_date":"2021-08-10T22:45:55.245Z","doi":"10.25663/brainlife.app.557"},{"name":"Warp density-probability from subject space to MNI space - copy","github":"brainlife/app-subj2reference","desc":"This app warps your input set of ROIS to a reference space. As it is currently set up, the master branch of this app warps to MNI space.","stats":{"requested":8222,"users":3,"success_rate":92.16520650813517,"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null}]},"runtime_mean":11480175.27,"runtime_std":12104814.882031843,"resources":[],"examples":0,"groups":6},"create_date":"2021-08-12T20:57:41.426Z","doi":"10.25663/brainlife.app.558"},{"name":"pRFs / Benson14-Retinotopy","github":"brainlife/app-benson14-retinotopy","desc":"Brainlife.io app for Noah Benson's neuropythy library, retinotopy from T1 anatomy","stats":{"requested":423,"users":10,"success_rate":63.23529411764706,"gitinfo":{"desc":"Brainlife.io app for Noah Benson's neuropythy library, retinotopy from T1 anatomy","tags":[],"stats":{"stars":1},"contributors":[{"name":"Noah C. Benson","email":"nben@nyu.edu"},{"name":"David Hunt","email":"davhunt@indiana.edu"},{"name":"Ariel Rokem","email":"arokem@gmail.com"},{"name":"Gio Piantoni","email":"github@gpiantoni.com"},{"name":"Michael Waskom","email":null}]},"runtime_mean":899919.11,"runtime_std":686105.8950094933,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfcffde14be11ff270aae"}],"examples":4,"groups":10},"create_date":"2021-08-13T01:17:29.539Z","doi":"10.25663/brainlife.app.559"},{"name":"Cortex Tissue Mapping (Native & Template Space) - qMRI","github":"brainlife/app-cortex-tissue-mapping","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","stats":{"requested":19134,"users":16,"success_rate":76.52514036969276,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":250899.08,"runtime_std":392917.6303011785,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd06de14be11ff270ab7"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfd06de14be11ff270ab8"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfd06de14be11ff270ab9"}],"examples":0,"groups":44},"create_date":"2021-08-13T02:47:02.139Z","doi":"10.25663/brainlife.app.560"},{"name":"Cortex Tissue Mapping (Native Space) - qMRI","github":"brainlife/app-cortex-tissue-mapping","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","stats":{"requested":19134,"users":16,"success_rate":76.52514036969276,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":250899.08,"runtime_std":392917.6303011785,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd0cde14be11ff270bb9"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfd0cde14be11ff270bba"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfd0cde14be11ff270bbb"}],"examples":2,"groups":44},"create_date":"2021-08-13T02:48:26.747Z","doi":"10.25663/brainlife.app.561"},{"name":"Cortex Tissue Mapping (Native Space) - qMRI (No SNR masking)","github":"brainlife/app-cortex-tissue-mapping","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","stats":{"requested":19134,"users":16,"success_rate":76.52514036969276,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":250899.08,"runtime_std":392917.6303011785,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd11de14be11ff270bbf"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfd11de14be11ff270bc0"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfd11de14be11ff270bc1"}],"examples":0,"groups":44},"create_date":"2021-08-13T03:00:37.816Z","doi":"10.25663/brainlife.app.562"},{"name":"HOI_toolbox","github":"PranavMahajan25/HOI_toolbox","desc":"Higher-order interactions toolbox","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd16de14be11ff270bc5"}],"success_rate":0,"users":1,"requested":1,"examples":0,"groups":1},"create_date":"2021-08-14T10:17:48.449Z","doi":"10.25663/brainlife.app.563"},{"name":"Tractogram cleaning with DIPY's quickBundles","github":"DanNBullock/app-filterViaQuickbundles","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd1cde14be11ff270c1a"}],"success_rate":75.86206896551724,"users":3,"requested":33,"examples":0,"groups":5,"runtime_mean":697611.1363636364,"runtime_std":1500536.0485296971},"create_date":"2021-08-16T17:46:10.804Z","doi":"10.25663/brainlife.app.564"},{"name":"app-skullStrip ","github":"vnbcs/app-skullStrip","desc":"brainlife app - runs AFNI's skullstrip function on NIfTI files","stats":{"resources":[],"success_rate":84.25515947467167,"users":13,"runtime_mean":289186.47,"runtime_std":418896.15332488925,"requested":14265,"examples":1,"groups":28},"create_date":"2021-08-23T17:33:09.726Z","doi":"10.25663/brainlife.app.565"},{"name":"Apply warp to BOLD data","github":"brainlife/app-warp-bold","desc":null,"stats":{"requested":3692,"users":1,"success_rate":66.75824175824175,"gitinfo":{"desc":"This app will align a T1w image to the ACPC plane (specifically, the MNI152_T1_1mm template from FSL using a 6 DOF alignment via FSL commands. This protocol was adapted from the HCP Preprocessing Pipeline (https://github.com/Washington-University/HCPpipelines.git). Requires a T1w image input and outputs an acpc_aligned T1w image.","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Josh Faskowitz","email":null}]},"runtime_mean":15979.66,"runtime_std":13425.741584895784,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd26de14be11ff270c46"}],"examples":1,"groups":3},"create_date":"2021-09-01T19:36:48.840Z","doi":"10.25663/brainlife.app.566"},{"name":"Regional Homogeneity (ReHo)","github":"anibalsolon/app-reho","desc":"BrainLife.io Regional Homogeneity app","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd2cde14be11ff270c7d"}],"success_rate":97.51243781094527,"users":4,"runtime_mean":28288.18,"runtime_std":9468.048383251957,"requested":407,"examples":1,"groups":5},"create_date":"2021-09-01T23:00:29.478Z","doi":"10.25663/brainlife.app.567"},{"name":"Create networkneuro datatype for visualization (Raw Datatypes)","github":"brainlife/app-create-networkneuro","desc":null,"stats":{"resources":[],"success_rate":36.507936507936506,"users":2,"runtime_mean":4389710.0869565215,"runtime_std":10140172.72877778,"requested":74,"examples":0,"groups":4},"create_date":"2021-09-02T17:22:17.606Z","doi":"10.25663/brainlife.app.568"},{"name":"Apply warp to Parcellation","github":"brainlife/app-warp-bold","desc":null,"stats":{"requested":3692,"users":1,"success_rate":66.75824175824175,"gitinfo":{"desc":"This app will align a T1w image to the ACPC plane (specifically, the MNI152_T1_1mm template from FSL using a 6 DOF alignment via FSL commands. This protocol was adapted from the HCP Preprocessing Pipeline (https://github.com/Washington-University/HCPpipelines.git). Requires a T1w image input and outputs an acpc_aligned T1w image.","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Josh Faskowitz","email":null}]},"runtime_mean":15979.66,"runtime_std":13425.741584895784,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd37de14be11ff270d2d"}],"examples":0,"groups":3},"create_date":"2021-09-08T14:37:40.841Z","doi":"10.25663/brainlife.app.569"},{"name":"Seed-based Correlation","github":"anibalsolon/app-seed-correlation","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd3cde14be11ff270d30"}],"examples":0,"users":2,"requested":3,"groups":2},"create_date":"2021-09-09T01:01:46.200Z","doi":"10.25663/brainlife.app.571"},{"name":"Map tract endpoint ROIs to cortical surface for quantitative analyses","github":"brainlife/app-cortex-tissue-mapping","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","stats":{"requested":19134,"users":16,"success_rate":76.52514036969276,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":250899.08,"runtime_std":392917.6303011785,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd42de14be11ff270dfe"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfd42de14be11ff270dff"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfd42de14be11ff270e00"}],"examples":0,"groups":44},"create_date":"2021-09-09T16:07:42.618Z","doi":"10.25663/brainlife.app.572"},{"name":"Create structural derivatives for cortexmap datatype","github":"brainlife/app-cortex-tissue-mapping","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","stats":{"requested":19134,"users":16,"success_rate":76.52514036969276,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":250899.08,"runtime_std":392917.6303011785,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd47de14be11ff270e2e"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfd47de14be11ff270e2f"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfd47de14be11ff270e30"}],"examples":0,"groups":44},"create_date":"2021-09-09T21:09:44.254Z","doi":"10.25663/brainlife.app.573"},{"name":"Connectivity Gradients","github":"anibalsolon/app-connectivity-gradient","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd4cde14be11ff270ea9"}],"success_rate":71.43932267168391,"users":1,"runtime_mean":22400,"runtime_std":10712.487023095991,"requested":6881,"examples":2,"groups":6},"create_date":"2021-09-16T20:18:45.540Z","doi":"10.25663/brainlife.app.574"},{"name":"Extract DWI volumes of choice","github":"brainlife/app-split-dwi-volumes","desc":null,"stats":{"success_rate":98.44559585492227,"users":2,"runtime_mean":452247.07,"runtime_std":793552.1110190719,"requested":596,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd51de14be11ff270eac"}],"examples":0,"groups":4},"create_date":"2021-09-17T14:47:51.973Z","doi":"10.25663/brainlife.app.575"},{"name":"Convert surface datatypes to cortexmap datatype","github":"brainlife/app-cortex-tissue-mapping","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd57de14be11ff270eba"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfd57de14be11ff270ebb"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfd57de14be11ff270ebc"}],"success_rate":76.52514036969276,"users":16,"runtime_mean":250899.08,"runtime_std":392917.6303011785,"requested":19134,"examples":1,"groups":44},"create_date":"2021-09-17T15:47:36.141Z","doi":"10.25663/brainlife.app.576"},{"name":"Virtual Lesion Networks","github":"bcmcpher/app-StructuralLiFENetwork","desc":null,"stats":{"resources":[],"success_rate":5.636530425033126,"users":1,"runtime_mean":393597497.46,"runtime_std":64384359.065338776,"requested":10750,"examples":1,"groups":1},"create_date":"2021-09-28T07:04:49.818Z","doi":"10.25663/brainlife.app.577"},{"name":"bedpostx","github":"sandrahanekamp/app-bedpostx","desc":"FSL's bedpostx app for brainlife","stats":{"resources":[],"success_rate":52.63157894736842,"users":1,"runtime_mean":4500600.975,"runtime_std":3447888.05459122,"requested":109,"examples":1,"groups":2},"create_date":"2021-10-04T21:48:15.707Z","doi":"10.25663/brainlife.app.578"},{"name":"DBB_DiceScore","github":"FBK-NILab/bl_app_dbb_DiceScore","desc":"Tool that performs the dice score between two 3D segmentations","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd67de14be11ff270fc6"}],"success_rate":25,"users":1,"runtime_mean":10845,"runtime_std":213,"requested":8,"examples":1,"groups":1},"create_date":"2021-10-11T15:37:09.901Z","doi":"10.25663/brainlife.app.579"},{"name":"Structural Connectome MRTrix3 (SCMRT) (SIFT2)","github":"brainlife/app-sift2-connectome-generation","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cfd6ede14be11ff27129c"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd6ede14be11ff27129d"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfd6ede14be11ff27129e"}],"success_rate":69.42613125561881,"users":21,"runtime_mean":773265.98,"runtime_std":1117285.7638660036,"requested":18185,"examples":2,"groups":53},"create_date":"2021-10-12T16:05:39.510Z","doi":"10.25663/brainlife.app.580"},{"name":"ANTsRegistration","github":"vnbcs/app-ANTsRegistration","desc":"registering t1w images with ANTs","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd73de14be11ff2712c5"}],"success_rate":93.03482587064677,"users":6,"runtime_mean":2913361.48,"runtime_std":454151.67095459386,"requested":2898,"examples":1,"groups":11},"create_date":"2021-10-13T13:55:38.121Z","doi":"10.25663/brainlife.app.581"},{"name":"Temporary converter of parcellation/surface-deprecated datatypes to surface datatypes","github":"brainlife/app-temp-parc-surface-deprecated-converter","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd78de14be11ff271353"}],"success_rate":99.49250845819236,"users":2,"runtime_mean":24619.7,"runtime_std":14839.001036794898,"requested":6236,"examples":1,"groups":6},"create_date":"2021-10-15T18:31:29.707Z","doi":"10.25663/brainlife.app.582"},{"name":"Mean amplitude of PSD data","github":"guiomar/app-peak-amplitude","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd7ede14be11ff271444"}],"success_rate":99.44405837387075,"users":1,"runtime_mean":13363.22,"runtime_std":3411.0580926744706,"requested":8689,"examples":3,"groups":4},"create_date":"2021-10-18T12:48:45.503Z","doi":"10.25663/brainlife.app.583"},{"name":"Epoch - equal length (MNE)","github":"guiomar/app-epoch-equal","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd83de14be11ff2714d3"}],"success_rate":99.49945593035908,"users":2,"runtime_mean":24796.16,"runtime_std":10354.143488207994,"requested":4709,"examples":2,"groups":8},"create_date":"2021-10-19T08:20:40.386Z","doi":"10.25663/brainlife.app.584"},{"name":"MNE - Autoreject","github":"guiomar/app-artifact-rejection","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd88de14be11ff271510"}],"success_rate":100,"users":2,"runtime_mean":69827.83333333333,"runtime_std":130934.32642263833,"requested":36,"examples":1,"groups":4},"create_date":"2021-10-19T08:53:27.821Z","doi":"10.25663/brainlife.app.585"},{"name":"Plot bands topomap","github":"guiomar/app-bands-topomap","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd8ede14be11ff271565"}],"success_rate":100,"users":2,"runtime_mean":47701.375,"runtime_std":45019.778139550785,"requested":9,"examples":1,"groups":2},"create_date":"2021-10-19T09:39:50.115Z","doi":"10.25663/brainlife.app.586"},{"name":"PSD: Power Spectral Density (Welch method) - epochs","github":"guiomar/app-epoch-psd","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd93de14be11ff27161b"}],"success_rate":99.27673497503014,"users":1,"runtime_mean":20967.52,"runtime_std":11731.65666858692,"requested":6122,"examples":2,"groups":5},"create_date":"2021-10-20T09:57:43.022Z","doi":"10.25663/brainlife.app.587"},{"name":"Generate images of all DWI volumes and create gif","github":"brainlife/app-slicer-fsl","desc":null,"stats":{"success_rate":82.31619858418544,"users":118,"runtime_mean":274514.93,"runtime_std":622047.7772298245,"requested":23119,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cfd98de14be11ff27168a"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd98de14be11ff27168b"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfd98de14be11ff27168c"}],"examples":1,"groups":185},"create_date":"2021-10-20T18:36:47.939Z","doi":"10.25663/brainlife.app.588"},{"name":"PRFmodel","github":"anibalsolon/PRFmodel-app","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfd9dde14be11ff271695"}],"success_rate":31.57894736842105,"users":1,"runtime_mean":434971.6666666667,"runtime_std":702188.6661870552,"requested":19,"examples":1,"groups":1},"create_date":"2021-10-22T16:23:34.606Z","doi":"10.25663/brainlife.app.589"},{"name":"Generate ROIs in DMRI Space with FA Skeleton mask","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"success_rate":83.53765323992994,"users":27,"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"requested":13134,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfda3de14be11ff2716b5"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfda3de14be11ff2716b6"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfda3de14be11ff2716b7"}],"examples":1,"groups":58},"create_date":"2021-11-15T21:11:41.382Z","doi":"10.25663/brainlife.app.591"},{"name":"Generate ROIs in DMRI Space with WM Skeleton mask","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"success_rate":83.53765323992994,"users":27,"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"requested":13134,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfda9de14be11ff271839"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfda9de14be11ff27183a"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfda9de14be11ff27183b"}],"examples":1,"groups":58},"create_date":"2021-11-15T21:27:00.058Z","doi":"10.25663/brainlife.app.592"},{"name":"HCP Pipeline test app","github":"brainlife/app-hcp-pipeline","desc":"brainlife wrapper for HCP Pipelines","stats":{"resources":[],"success_rate":26.168224299065418,"users":10,"runtime_mean":29772992.39285714,"runtime_std":15462883.03244422,"requested":134,"examples":1,"groups":9},"create_date":"2021-11-18T02:17:04.870Z","doi":"10.25663/brainlife.app.593"},{"name":"ERGMs for Brain Networks","github":"dichio/bl-ERGM","desc":"Source code for ERGM app in BrainLife.io","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfdb4de14be11ff271887"}],"examples":1,"success_rate":39.62264150943396,"users":3,"runtime_mean":33238.42857142857,"runtime_std":45237.4743901257,"requested":63,"groups":4},"create_date":"2021-11-19T16:07:48.059Z","doi":"10.25663/brainlife.app.594"},{"name":"Structural Networks (Microstructure Properties - NODDI)","github":"bcmcpher/app-StructuralPropertyNetwork","desc":null,"stats":{"success_rate":33.33333333333333,"users":1,"runtime_mean":504298,"runtime_std":0,"requested":3,"resources":[],"examples":0,"groups":1},"create_date":"2021-11-22T21:15:01.077Z","doi":"10.25663/brainlife.app.595"},{"name":"Network Tensor Tract Profiles","github":"bcmcpher/app-StructuralEdgeProfiles","desc":null,"stats":{"resources":[],"examples":0},"create_date":"2021-11-22T21:42:55.132Z","doi":"10.25663/brainlife.app.596"},{"name":"Structural Link Networks","github":"bcmcpher/app-StructuralLinkNetwork","desc":null,"stats":{"resources":[],"examples":0},"create_date":"2021-11-22T22:01:29.656Z","doi":"10.25663/brainlife.app.597"},{"name":"AFNI pRF","github":"anibalsolon/bl-app-prfmodel","desc":null,"stats":{"resources":[],"examples":0,"success_rate":0,"users":1,"requested":9,"groups":2},"create_date":"2021-11-24T03:00:10.790Z","doi":"10.25663/brainlife.app.598"},{"name":"Average channels","github":"guiomar/app-average-channels","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cfdcfde14be11ff271963"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfdcfde14be11ff271964"}],"examples":3,"success_rate":90.81925822740727,"users":2,"runtime_mean":12626.65,"runtime_std":7440.757424315086,"requested":23549,"groups":4},"create_date":"2021-12-10T13:55:05.861Z","doi":"10.25663/brainlife.app.599"},{"name":"extract_b0_masks","github":"dPys/app-extract_b0_masks","desc":null,"stats":{"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cfdd4de14be11ff271967"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfdd4de14be11ff271968"}],"examples":0,"success_rate":0,"users":1,"requested":21,"groups":1},"create_date":"2022-01-05T18:46:21.317Z","doi":"10.25663/brainlife.app.600"},{"name":"Participant Report","github":"brainlife/app-participant-report","desc":"App to generate report HTML for study participants","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfddade14be11ff271a53"}],"examples":2,"success_rate":48.1203007518797,"users":5,"runtime_mean":41420.9375,"runtime_std":20453.184843590832,"requested":147,"groups":6},"create_date":"2022-01-06T18:29:48.379Z","doi":"10.25663/brainlife.app.601"},{"name":"Freesurfer 7.1.1 Longitudinal (Step1/2)","github":"brainlife/app-freesurfer-longitudinal","desc":"This App allows brainlife.io to perform freesurfer longitudinal processing","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfde0de14be11ff271c04"}],"examples":2,"success_rate":54.803583735354934,"users":4,"runtime_mean":7234278.02,"runtime_std":749569.9601947503,"requested":11215,"groups":8},"create_date":"2022-01-14T15:24:34.972Z","doi":"10.25663/brainlife.app.602"},{"name":"Freesurfer 7.1.1 Longitudinal (Step 2/2)","github":"brainlife/app-freesurfer-longitudinal","desc":"This App allows brainlife.io to perform freesurfer longitudinal processing","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfde7de14be11ff271d89"}],"examples":2,"success_rate":54.803583735354934,"users":4,"runtime_mean":7234278.02,"runtime_std":749569.9601947503,"requested":11215,"groups":8},"create_date":"2022-01-14T16:09:24.274Z","doi":"10.25663/brainlife.app.603"},{"name":"Resample surface data from fsaverage space","github":"brainlife/app-resample-surface-data","desc":null,"stats":{"resources":[],"success_rate":93.09859154929578,"users":1,"runtime_mean":33885.04,"runtime_std":8520.661798146903,"requested":714,"examples":1,"groups":2},"create_date":"2022-02-18T21:14:47.817Z","doi":"10.25663/brainlife.app.604"},{"name":"Freesurfer 7.1.1 - Multiple T1w Inputs","github":"bacaron/app-freesurfer","desc":"Freesurfer segments the t1w anatomical data into functionally different parts of the brain. Segmentation/parcellation can then be fed to many other subsequent analysis. ","stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cfdf2de14be11ff271e57"}],"success_rate":52.66903914590747,"users":5,"runtime_mean":22326952.65,"runtime_std":6123996.497257869,"requested":706,"examples":1,"groups":6},"create_date":"2022-02-26T23:50:02.652Z","doi":"10.25663/brainlife.app.605"},{"name":"Structural connectivity predictors","github":"FarnazZE/bnbl-brainlife-sc-based-predictors","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfdf8de14be11ff271efa"}],"examples":1,"success_rate":10.434782608695652,"users":1,"runtime_mean":64407.666666666664,"runtime_std":42254.56280358634,"requested":126,"groups":2},"create_date":"2022-03-01T17:30:23.316Z","doi":"10.25663/brainlife.app.606"},{"name":"Generate figures of white matter tracts overlaid on anatomical image","github":"brainlife/app-wmc_figures","desc":"This service creates 6 figures of each specified white matter tract (any wmc structure): axial, axial_flipped, sagittal_left, sagittal_right, coronal, and coronal_flipped. Please choose the t1 image slices you would like displayed. The default slices work well for the HCP t1 images if they have not been re-ACPC aligned. If you have ACPC aligned your t1 images using the ACPC alignment app on brainlife, the following values are a good starting point: coronal = 105, sagittal = 89, axial = 65. The img_min and img_max values refer to the value range displayed for the t1 image. The value range is calculated as follow (mean + img_min * std, mean + img_max * std). The default values are a good starting place, adjust them if your t1 is too dark or too light.","stats":{"success_rate":90.1685393258427,"users":4,"runtime_mean":63697.35,"runtime_std":238826.74800752004,"requested":436,"gitinfo":{"desc":"This service creates 4 figures of each AFQ tract: axial, left sagittal, right sagittal, coronal. Please choose the t1 image slices you would like displayed. The default slices work well for the HCP t1 images if they have not been re-ACPC aligned. If you have ACPC aligned your t1 images using the ACPC alignment app on Brain Life the following values are a good starting point: coronal = 105, sagittal = 89, axial = 65. The img_min and img_max values refer to the value range displayed for the t1 image. The value range is calulated as follow (mean + img_min * std, mean + img_max * std). The default values are a good starting place, adjust them if your t1 is too dark or too light.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfe01de14be11ff2722e8"}],"examples":4,"groups":6},"create_date":"2022-03-03T16:01:02.906Z","doi":"10.25663/brainlife.app.607"},{"name":"Merge Tractography (tcks) together with MRTrix3","github":"bacaron/app-mergeTCK","desc":"Merge multiple TCK files into one TCK file.","stats":{"success_rate":92.20055710306406,"users":6,"runtime_mean":403908.66,"runtime_std":729450.6702689391,"requested":848,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfe07de14be11ff27233b"}],"examples":0,"groups":12},"create_date":"2022-03-03T22:23:58.401Z","doi":"10.25663/brainlife.app.608"},{"name":"Freesurfer Longitudinal Statistics","github":"brainlife/app-freesurfer-longitudinal-statistics","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfe0dde14be11ff2723c4"}],"examples":1,"success_rate":52.63157894736842,"users":1,"runtime_mean":1020193.6666666666,"runtime_std":92726.57671898721,"requested":62,"groups":1},"create_date":"2022-03-11T23:18:22.535Z","doi":"10.25663/brainlife.app.609"},{"name":"Convert quality control (qc) data from eddy to regressors datatype","github":"brainlife/app-convert-eddyqc-to-regressor","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfe12de14be11ff2723d1"}],"examples":1,"success_rate":25,"users":2,"runtime_mean":11709,"runtime_std":0,"requested":5,"groups":1},"create_date":"2022-03-15T16:15:55.131Z","doi":"10.25663/brainlife.app.610"},{"name":"Mediation Tool","github":"canlab/MediationToolbox","desc":"Single-level and multi-level mediation analyses for any kind of data, with bootstrap-based significance testing. Neuroimaging-oriented functions allow for mediation effect parametric mapping (mapping of mediation effects across the brain) and multivariate mediation. ","stats":{"resources":[],"examples":0},"create_date":"2022-03-21T21:03:34.217Z","doi":"10.25663/brainlife.app.611"},{"name":"Compute dice similarity coefficient between parcels in parcellations","github":"brainlife/app-compute-similarity-parcellations","desc":null,"stats":{"resources":[],"examples":0,"success_rate":100,"users":2,"runtime_mean":683446.5333333333,"runtime_std":601002.971139452,"requested":30,"groups":2},"create_date":"2022-03-24T00:30:34.545Z","doi":"10.25663/brainlife.app.612"},{"name":"Epoch MEG/EEG sensor data","github":"dnacombo/app-epoch","desc":null,"stats":{"resources":[],"examples":1,"success_rate":58.27338129496403,"users":2,"groups":3,"runtime_mean":229651.41975308643,"runtime_std":882804.1471076641,"requested":145},"create_date":"2022-04-18T09:36:48.282Z","doi":"10.25663/brainlife.app.613"},{"name":"Compute streamline weights using SIFT2","github":"brainlife/app-sift-sift2","desc":null,"stats":{"resources":[{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfe2ade14be11ff2725b0"}],"examples":1,"success_rate":77.66990291262135,"users":3,"groups":7,"runtime_mean":1542416.4375,"runtime_std":1574397.1840387732,"requested":103},"create_date":"2022-04-26T16:24:50.295Z","doi":"10.25663/brainlife.app.615"},{"name":"Filter Streamlines using SIFT","github":"brainlife/app-sift-sift2","desc":null,"stats":{"resources":[{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfe30de14be11ff2726a2"}],"examples":1,"success_rate":77.66990291262135,"users":3,"groups":7,"runtime_mean":1542416.4375,"runtime_std":1574397.1840387732,"requested":103},"create_date":"2022-04-26T17:37:12.434Z","doi":"10.25663/brainlife.app.616"},{"name":"Structural Connectome MRTrix3 (SCMRT)","github":"brainlife/app-sift2-connectome-generation","desc":null,"stats":{"success_rate":69.42613125561881,"groups":53,"users":21,"runtime_mean":773265.98,"runtime_std":1117285.7638660036,"requested":18185,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cfe38de14be11ff272947"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfe38de14be11ff272948"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfe38de14be11ff272949"}],"examples":3},"create_date":"2022-04-26T18:58:03.997Z","doi":"10.25663/brainlife.app.617"},{"name":"app-evoked-averaged ","github":"zahransa/app-evoked-averaged","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cfe3dde14be11ff272983"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfe3dde14be11ff272984"}],"examples":2,"success_rate":96.875,"users":2,"groups":1,"runtime_mean":341174.5483870968,"runtime_std":1633542.4049248907,"requested":32},"create_date":"2022-04-27T16:53:41.518Z","doi":"10.25663/brainlife.app.618"},{"name":"Sample streamlines based on labels assignments","github":"brainlife/app-filter-tractograms","desc":null,"stats":{"resources":[],"examples":1,"success_rate":40,"users":1,"groups":1,"runtime_mean":358873.5,"runtime_std":16639.5,"requested":5},"create_date":"2022-04-28T15:41:39.753Z","doi":"10.25663/brainlife.app.619"},{"name":"Create networkneuro datatype for visualization","github":"brainlife/app-create-networkneuro","desc":null,"stats":{"success_rate":36.507936507936506,"groups":4,"users":2,"runtime_mean":4389710.0869565215,"runtime_std":10140172.72877778,"requested":74,"resources":[],"examples":1},"create_date":"2022-04-29T14:12:35.665Z","doi":"10.25663/brainlife.app.620"},{"name":"Filter WMC Datatype","github":"bacaron/app-filter-wmc","desc":null,"stats":{"resources":[],"success_rate":33.33333333333333,"users":1,"groups":1,"runtime_mean":17379,"runtime_std":5236,"requested":7,"examples":1},"create_date":"2022-04-29T21:36:21.428Z","doi":"10.25663/brainlife.app.621"},{"name":"Compute streamline weights using COMMIT","github":"brainlife/app-commit","desc":null,"stats":{"resources":[],"examples":1,"success_rate":31.03448275862069,"users":1,"groups":1,"runtime_mean":1133728.5555555555,"runtime_std":1321638.393454134,"requested":37},"create_date":"2022-04-30T00:17:58.555Z","doi":"10.25663/brainlife.app.622"},{"name":"Compute Peaks from Spherical Harmonic (SH) data","github":"brainlife/app-sh2peaks","desc":null,"stats":{"resources":[],"examples":1,"success_rate":56.930693069306926,"users":2,"groups":2,"runtime_mean":11444.81,"runtime_std":2517.4815816406694,"requested":216},"create_date":"2022-05-01T15:52:11.583Z","doi":"10.25663/brainlife.app.623"},{"name":"Generate Visual Regions of Interest Binned by Eccentricity Estimates (Benson Atlas) - fMRI Space","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"success_rate":83.53765323992994,"groups":58,"users":27,"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"requested":13134,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfe5fde14be11ff272c04"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfe5fde14be11ff272c05"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfe5fde14be11ff272c06"}],"examples":0},"create_date":"2022-05-06T19:37:38.699Z","doi":"10.25663/brainlife.app.624"},{"name":"app- covariance","github":"zahransa/app-covariance","desc":null,"stats":{"resources":[],"examples":1,"success_rate":35,"users":1,"groups":1,"runtime_mean":11091.42857142857,"runtime_std":524.8702852386774,"requested":20},"create_date":"2022-05-10T12:51:13.197Z","doi":"10.25663/brainlife.app.625"},{"name":"app-forward","github":"zahransa/app-forward","desc":null,"stats":{"resources":[],"examples":1,"success_rate":18.181818181818183,"users":1,"groups":2,"requested":11,"runtime_mean":11789,"runtime_std":326},"create_date":"2022-05-10T12:56:09.347Z","doi":"10.25663/brainlife.app.627"},{"name":"app-inverse","github":"zahransa/app-inverse","desc":null,"stats":{"resources":[],"examples":0},"create_date":"2022-05-10T13:13:44.971Z","doi":"10.25663/brainlife.app.628"},{"name":"Create MNI coordinate-based ROIS and warp to subject space","github":"DanNBullock/app-createMNI_ROIS_and_warp2subj","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfe74de14be11ff272c31"}],"examples":1,"success_rate":30,"users":1,"groups":1,"runtime_mean":1429286.3333333333,"runtime_std":397663.8813171523,"requested":10},"create_date":"2022-05-19T20:34:22.883Z","doi":"10.25663/brainlife.app.629"},{"name":"Track the aLIC","github":"DanNBullock/app-track_aLIC","desc":"Containerized app for tracking the anterior limb of the internal capsule (in humans)","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfe79de14be11ff272c46"}],"examples":0,"success_rate":19.047619047619047,"users":2,"groups":2,"runtime_mean":13356436,"runtime_std":9664902.80202618,"requested":28},"create_date":"2022-05-22T14:16:32.742Z","doi":"10.25663/brainlife.app.630"},{"name":"Segment with ROIs","github":"DanNBullock/app-segment_with_ROIs","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfe7fde14be11ff272c5b"}],"examples":1,"success_rate":36.61971830985916,"users":2,"groups":3,"runtime_mean":7530760.807692308,"runtime_std":2379587.8664086577,"requested":94},"create_date":"2022-05-22T14:52:36.759Z","doi":"10.25663/brainlife.app.631"},{"name":"MEG FIF to mne/raw","github":"guiomar/app_fif2mne","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfe84de14be11ff272c6e"}],"examples":1,"success_rate":75,"users":2,"groups":4,"runtime_mean":35566.5,"runtime_std":21685.789538697147,"requested":10},"create_date":"2022-05-23T10:06:01.751Z","doi":"10.25663/brainlife.app.632"},{"name":"MEG CTF to mne/raw ","github":"guiomar/app_ctf2mne","desc":null,"stats":{"resources":[],"examples":1,"success_rate":20,"users":1,"groups":1,"runtime_mean":11312,"runtime_std":0,"requested":5},"create_date":"2022-05-23T10:22:12.629Z","doi":"10.25663/brainlife.app.634"},{"name":"EEG eeglab to mne/raw","github":"guiomar/app_eeglab2mne","desc":null,"stats":{"resources":[],"examples":1,"success_rate":14.285714285714285,"users":2,"groups":3,"requested":8,"runtime_mean":97280,"runtime_std":0},"create_date":"2022-05-23T10:34:40.073Z","doi":"10.25663/brainlife.app.633"},{"name":"EEG bdf to mne/raw","github":"guiomar/app_bdf2mne","desc":null,"stats":{"resources":[],"examples":1,"success_rate":50,"users":1,"groups":1,"runtime_mean":21669,"runtime_std":0,"requested":2},"create_date":"2022-05-23T10:54:38.164Z","doi":"10.25663/brainlife.app.635"},{"name":"EEG brainvision to mne/raw","github":"guiomar/app_brainvision2mne","desc":null,"stats":{"resources":[],"examples":0,"success_rate":0,"users":1,"groups":1,"requested":2},"create_date":"2022-05-23T11:00:09.003Z","doi":"10.25663/brainlife.app.636"},{"name":"EEG edf to mne/raw","github":"guiomar/app_edf2mne","desc":null,"stats":{"resources":[],"examples":1,"success_rate":50,"users":2,"groups":2,"runtime_mean":10933,"runtime_std":0,"requested":2},"create_date":"2022-05-23T11:08:46.291Z","doi":"10.25663/brainlife.app.637"},{"name":"Generate tract figures (wma_pyTools)","github":"DanNBullock/app-wma_pyTools-TractFigs","desc":"An app for generating multiple different kinds of figures from an input set of tracts (e.g as represented by a WMC object)","stats":{"resources":[],"examples":0,"success_rate":27.368421052631582,"users":3,"groups":6,"runtime_mean":4370918.288461538,"runtime_std":4268621.406846785,"requested":252},"create_date":"2022-05-24T14:28:33.443Z","doi":"10.25663/brainlife.app.638"},{"name":"Postprocess parcellation: island removal & inflation","github":"DanNBullock/app-de-island_parcellation","desc":"Remove islands (unconnected components) from and/or inflate a given volumetric parcellation.","stats":{"resources":[],"success_rate":77.77777777777779,"users":2,"groups":3,"runtime_mean":103443.14285714286,"runtime_std":46614.17566249432,"requested":12,"examples":0},"create_date":"2022-06-03T20:21:16.393Z","doi":"10.25663/brainlife.app.639"},{"name":"Structural connectivity & White Matter Classification (WMC) using DIPY","github":"DanNBullock/app-DIPY-connectome_and_WMC_from_parc","desc":"Generate a structural connectivity matrix and a White Matter Classification structure for a given parcellation and tractogram.","stats":{"resources":[],"success_rate":44.44444444444444,"users":2,"groups":2,"requested":9,"examples":0,"runtime_mean":45543,"runtime_std":19841.333952131343},"create_date":"2022-06-03T20:28:20.976Z","doi":"10.25663/brainlife.app.640"},{"name":"Convert tcks to tck and WMC","github":"DanNBullock/app-tcks_to_tck_and_WMC","desc":"Simple converter for the multi-tck format, tcks, which combines these into a single tck file and produces an associated WMC file.","stats":{"resources":[],"success_rate":60,"users":2,"groups":2,"runtime_mean":20091.666666666668,"runtime_std":3651.07676659305,"requested":12,"examples":1},"create_date":"2022-06-03T21:32:01.714Z","doi":"10.25663/brainlife.app.641"},{"name":"Clustering edge time series","github":"FarnazZE/bnbl-brainlife-clustering-edge-time-series","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfeb8de14be11ff272d93"}],"users":1,"groups":1,"requested":4,"examples":1,"success_rate":33.33333333333333,"runtime_mean":32563,"runtime_std":0},"create_date":"2022-06-06T19:42:29.836Z","doi":"10.25663/brainlife.app.642"},{"name":"Tissue-specific SNR (and other tissue-specific metrics)","github":"DanNBullock/app-SNR_Report","desc":null,"stats":{"resources":[],"examples":0},"create_date":"2022-06-07T20:33:14.025Z","doi":"10.25663/brainlife.app.643"},{"name":"Average ERP (MNE)","github":"guiomar/app-average-erp","desc":null,"stats":{"success_rate":99.49945593035908,"groups":8,"users":2,"runtime_mean":24796.16,"runtime_std":10354.143488207994,"requested":4709,"resources":[],"examples":0},"create_date":"2022-06-09T14:58:57.834Z","doi":"10.25663/brainlife.app.644"},{"name":"Emptyroom projs","github":"guiomar/app-emptyroom-proj","desc":null,"stats":{"success_rate":92.3076923076923,"groups":3,"users":2,"runtime_mean":18286.416666666668,"runtime_std":20583.971508831546,"requested":14,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfec8de14be11ff272dac"}],"examples":1},"create_date":"2022-06-10T11:00:58.376Z","doi":"10.25663/brainlife.app.645"},{"name":"Predict functional connectivity from structural connectivity","github":"FarnazZE/bnbl-brainlife-predict-fc-from-sc","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfecede14be11ff272dee"}],"examples":0,"users":2,"groups":3,"requested":26,"success_rate":12,"runtime_mean":74650.66666666667,"runtime_std":37047.714210491074},"create_date":"2022-06-12T02:43:53.157Z","doi":"10.25663/brainlife.app.646"},{"name":"Track Visual White Matter Tracks by Visual Field Eccentricty: Contrack","github":"brainlife/app-contrack-visual-white-matter","desc":null,"stats":{"groups":4,"users":3,"requested":166,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfed3de14be11ff272e28"}],"examples":1,"success_rate":57.54716981132076,"runtime_mean":21450760.508196723,"runtime_std":10681959.291094214},"create_date":"2022-06-13T22:05:13.432Z","doi":"10.25663/brainlife.app.647"},{"name":"Bundle segmented tracks by eccentricity","github":"brainlife/app-eccentricity-classification","desc":null,"stats":{"success_rate":72.15189873417721,"groups":3,"users":1,"runtime_mean":845065.18,"runtime_std":765765.3651332945,"requested":301,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfed8de14be11ff272e2b"}],"examples":0},"create_date":"2022-06-13T22:52:06.975Z","doi":"10.25663/brainlife.app.648"},{"name":"Bundle segmented tracks by eccentricity - Parcellation (Matlab)","github":"brainlife/app-eccentricity-classification","desc":null,"stats":{"success_rate":72.15189873417721,"groups":3,"users":1,"runtime_mean":845065.18,"runtime_std":765765.3651332945,"requested":301,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfedede14be11ff272e2f"}],"examples":0},"create_date":"2022-06-16T01:45:43.405Z","doi":"10.25663/brainlife.app.649"},{"name":"app-decoding-full-epochs","github":"zahransa/app-decoding-full-epochs","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cfee3de14be11ff272e3b"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfee3de14be11ff272e3c"}],"examples":1,"success_rate":100,"users":1,"groups":1,"runtime_mean":43782.5,"runtime_std":10591.5,"requested":2},"create_date":"2022-06-16T11:14:34.432Z","doi":"10.25663/brainlife.app.650"},{"name":"Compute summary statistics of diffusion measures mapped to visual regions binned by eccentricity - Benson14","github":"brainlife/app-cortex-tissue-mapping-stats","desc":null,"stats":{"success_rate":44.93765121905825,"groups":27,"users":12,"runtime_mean":817560.56,"runtime_std":2302860.854492113,"requested":38152,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfee9de14be11ff272eb2"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfee9de14be11ff272eb3"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfee9de14be11ff272eb4"}],"examples":0},"create_date":"2022-06-17T04:02:31.639Z","doi":"10.25663/brainlife.app.651"},{"name":"dwi-fslswap-app","github":"hanna-willis/app-fslswap","desc":"This is a template for a python-based brainlife.io/app","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfeeede14be11ff272ecb"}],"examples":1,"success_rate":45.65217391304348,"users":2,"groups":2,"runtime_mean":192083.85714285713,"runtime_std":600974.5910018465,"requested":52},"create_date":"2022-06-17T11:40:55.283Z","doi":"10.25663/brainlife.app.652"},{"name":"app-artifact-amplitude","github":"zahransa/app-artifact-amplitude","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfef4de14be11ff272eda"}],"examples":1,"success_rate":75,"users":1,"groups":1,"runtime_mean":32372,"runtime_std":16184.913407244414,"requested":4},"create_date":"2022-06-21T13:06:58.962Z","doi":"10.25663/brainlife.app.653"},{"name":"app-SSP","github":"zahransa/app-SSP","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfef9de14be11ff272ee4"}],"examples":1,"success_rate":100,"users":1,"groups":1,"runtime_mean":43876,"runtime_std":0,"requested":1},"create_date":"2022-06-27T07:09:03.501Z","doi":"10.25663/brainlife.app.654"},{"name":" app-decoding-time-by-time ","github":"zahransa/app-decoding-time-by-time","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cfefede14be11ff272ef4"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfefede14be11ff272ef5"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cfefede14be11ff272ef6"}],"examples":0,"success_rate":100,"users":1,"groups":1,"runtime_mean":58462,"runtime_std":17390.56643125807,"requested":5},"create_date":"2022-06-27T09:30:02.889Z","doi":"10.25663/brainlife.app.655"},{"name":"Compute summary statistics of diffusion measures mapped to cortical surface - Freesurfer computations","github":"brainlife/app-cortex-tissue-mapping-stats","desc":null,"stats":{"success_rate":44.93765121905825,"groups":27,"users":12,"runtime_mean":817560.56,"runtime_std":2302860.854492113,"requested":38152,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cff04de14be11ff273013"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cff04de14be11ff273014"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cff04de14be11ff273015"}],"examples":0},"create_date":"2022-07-03T21:41:38.022Z","doi":"10.25663/brainlife.app.656"},{"name":"Compute summary statistics of diffusion measures mapped to cortical surface - Freesurfer stats - Deprecated Surface","github":"brainlife/app-cortex-tissue-mapping-stats","desc":null,"stats":{"success_rate":44.93765121905825,"groups":27,"users":12,"runtime_mean":817560.56,"runtime_std":2302860.854492113,"requested":38152,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cff0ade14be11ff273051"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cff0ade14be11ff273052"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cff0ade14be11ff273053"}],"examples":1},"create_date":"2022-07-03T21:53:13.410Z","doi":"10.25663/brainlife.app.657"},{"name":"app-anatomy","github":"zahransa/app-anatomy","desc":null,"stats":{"resources":[],"examples":0},"create_date":"2022-07-08T09:33:25.065Z","doi":"10.25663/brainlife.app.658"},{"name":"app-time-frequency","github":"zahransa/app-time-frequency","desc":null,"stats":{"resources":[],"examples":0},"create_date":"2022-07-08T09:35:03.377Z","doi":"10.25663/brainlife.app.659"},{"name":"app-maxwell-filtering","github":"zahransa/app-maxwell-filtering","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cff19de14be11ff27305b"}],"examples":0},"create_date":"2022-07-08T09:42:13.451Z","doi":"10.25663/brainlife.app.660"},{"name":"app-filter","github":"zahransa/app-filter","desc":null,"stats":{"resources":[],"examples":0},"create_date":"2022-07-08T09:44:08.870Z","doi":"10.25663/brainlife.app.661"},{"name":"FSL Top-up & Eddy Correct","github":"brainlife/app-FSLTopupEddy","desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","stats":{"success_rate":58.620689655172406,"groups":45,"users":24,"runtime_mean":5133032.47,"runtime_std":8164410.893760923,"requested":3399,"gitinfo":{"desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","tags":["preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"642cff24de14be11ff2730bb"}],"examples":1},"create_date":"2022-07-15T17:58:16.090Z","doi":"10.25663/brainlife.app.662"},{"name":"Freesurfer 7.3.2","github":"brainlife/app-freesurfer","desc":"Freesurfer segments the t1w anatomical data into functionally different parts of the brain. Segmentation/parcellation can then be fed to many other subsequent analysis. ","stats":{"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642cff29de14be11ff273150"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cff29de14be11ff273151"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cff29de14be11ff273152"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cff29de14be11ff273153"}],"success_rate":48.68517116737809,"users":431,"groups":1071,"runtime_mean":32186778.47,"runtime_std":21686686.3444785,"requested":368573,"examples":4},"create_date":"2022-08-15T18:37:09.298Z","doi":"10.25663/brainlife.app.664"},{"name":"Compute Network Backbone","github":"brainlife/app-network-backbone","desc":"Compute the backbone network from a structural or functional connectivity network","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cff2fde14be11ff2731d2"}],"success_rate":99.5683930942895,"users":2,"groups":8,"runtime_mean":83627.12,"runtime_std":706263.2724128627,"requested":3169,"examples":1},"create_date":"2022-08-21T19:58:39.061Z","doi":"10.25663/brainlife.app.665"},{"name":"Extract events from MEG/EEG raw data ","github":"dnacombo/app-events","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cff34de14be11ff2731e2"}],"success_rate":15.789473684210526,"users":1,"groups":1,"requested":20,"examples":1,"runtime_mean":36389,"runtime_std":11923.993318794952},"create_date":"2022-09-20T10:20:45.348Z","doi":"10.25663/brainlife.app.666"},{"name":"Apply warp from subject-to-standard space to ROIs (T2w)","github":"brainlife/app-register-rois-mni","desc":null,"stats":{"success_rate":77.3135359116022,"groups":8,"users":7,"runtime_mean":7732191,"runtime_std":9388716.477521751,"requested":3878,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cff3ade14be11ff27321d"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cff3ade14be11ff27321e"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cff3ade14be11ff27321f"}],"examples":2},"create_date":"2022-09-21T00:17:38.930Z","doi":"10.25663/brainlife.app.667"},{"name":"anat-fslswap-app","github":"hanna-willis/app-fslswap","desc":"This is a template for a python-based brainlife.io/app","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cff3fde14be11ff273238"}],"success_rate":45.65217391304348,"users":2,"groups":2,"runtime_mean":192083.85714285713,"runtime_std":600974.5910018465,"requested":52,"examples":1},"create_date":"2022-09-22T17:28:48.143Z","doi":"10.25663/brainlife.app.668"},{"name":"Apply warp from subject-to-standard space to ROIs (T1w)","github":"brainlife/app-register-rois-mni","desc":null,"stats":{"success_rate":77.3135359116022,"groups":8,"users":7,"runtime_mean":7732191,"runtime_std":9388716.477521751,"requested":3878,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cff46de14be11ff2733b4"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642cff46de14be11ff2733b5"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cff46de14be11ff2733b6"}],"examples":2},"create_date":"2022-09-26T14:06:54.513Z","doi":"10.25663/brainlife.app.670"},{"name":"Reslice ROIs to match input DWI","github":"bacaron/app-reslice-rois-dwi","desc":null,"stats":{"success_rate":80.37974683544303,"groups":3,"users":2,"runtime_mean":152093.17,"runtime_std":374703.477873186,"requested":327,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cff4cde14be11ff2734eb"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cff4cde14be11ff2734ec"}],"examples":4},"create_date":"2022-09-27T17:46:36.432Z","doi":"10.25663/brainlife.app.671"},{"name":" app-SSP-projectors-ECG ","github":"zahransa/app-SSP-projectors-ECG","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cff51de14be11ff273503"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cff51de14be11ff273504"}],"success_rate":45.28301886792453,"users":3,"groups":1,"runtime_mean":929817.2916666666,"runtime_std":1837090.212029009,"requested":56,"examples":1},"create_date":"2022-09-28T08:17:26.547Z","doi":"10.25663/brainlife.app.672"},{"name":"app-SSP-projectors-EOG ","github":"zahransa/app-SSP-projectors-EOG","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cff56de14be11ff273519"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cff56de14be11ff27351a"}],"success_rate":81.81818181818183,"users":1,"groups":1,"runtime_mean":35062.333333333336,"runtime_std":23106.644508548714,"requested":14,"examples":1},"create_date":"2022-09-28T08:56:07.487Z","doi":"10.25663/brainlife.app.673"},{"name":" app-apply-projectors ","github":"zahransa/app-apply-projectors","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cff5bde14be11ff273542"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cff5bde14be11ff273543"}],"success_rate":73.33333333333333,"users":2,"groups":1,"runtime_mean":1112711.5151515151,"runtime_std":5174097.198256986,"requested":48,"examples":1},"create_date":"2022-09-28T10:02:58.317Z","doi":"10.25663/brainlife.app.674"},{"name":"Fit ICA on raw MEG data","github":"dnacombo/app-ICA-fit","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cff61de14be11ff273557"}],"success_rate":0,"users":1,"groups":1,"requested":4,"examples":1},"create_date":"2022-09-28T12:52:25.283Z","doi":"10.25663/brainlife.app.675"},{"name":"app-ICA-plot ","github":"zahransa/app-ICA-plot","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cff66de14be11ff273564"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cff66de14be11ff273565"}],"success_rate":54.54545454545454,"users":1,"groups":1,"requested":16,"examples":1,"runtime_mean":34377.833333333336,"runtime_std":17780.59653495599},"create_date":"2022-09-28T13:18:50.563Z","doi":"10.25663/brainlife.app.676"},{"name":" app-find-bads-ecg","github":"zahransa/app-find-bads-ecg","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cff6bde14be11ff273581"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cff6bde14be11ff273582"}],"success_rate":87.5,"users":1,"groups":1,"runtime_mean":2411580.1428571427,"runtime_std":5805303.696721705,"requested":8,"examples":1},"create_date":"2022-09-29T11:10:34.911Z","doi":"10.25663/brainlife.app.677"},{"name":"app-selecting-ICA-components-manually","github":"zahransa/app-selecting-ICA-components-manually","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cff71de14be11ff27358f"}],"success_rate":100,"users":1,"groups":1,"runtime_mean":22101.333333333332,"runtime_std":8636.499689624778,"requested":3,"examples":1},"create_date":"2022-09-29T11:27:19.516Z","doi":"10.25663/brainlife.app.678"},{"name":"Reject components from MEG/EEG data using MNE-python","github":"zahransa/app-apply-ICA","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cff76de14be11ff2735a4"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cff76de14be11ff2735a5"}],"examples":1,"success_rate":64,"users":2,"groups":1,"runtime_mean":27943.8125,"runtime_std":10320.749507780129,"requested":25},"create_date":"2022-09-29T11:33:25.131Z","doi":"10.25663/brainlife.app.679"},{"name":"FSLmaths-app","github":"hanna-willis/app-roi-fslmaths","desc":"This app masks a region of interest by a lesion mask. ","stats":{"resources":[{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cff7cde14be11ff2736cf"}],"examples":1,"success_rate":56.07142857142857,"users":1,"groups":1,"runtime_mean":26322.08,"runtime_std":10232.024649774843,"requested":304},"create_date":"2022-10-06T20:44:15.295Z","doi":"10.25663/brainlife.app.680"},{"name":"combine-scans-rois","github":"hanna-willis/app-combine-roi-scans","desc":"An app that combines ROIs, diffusion image and t1 image into same location for easier viewing. ","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cff84de14be11ff273967"}],"success_rate":82.55813953488372,"users":1,"groups":1,"runtime_mean":1403215.676056338,"runtime_std":4304435.676898682,"requested":102,"examples":3},"create_date":"2022-10-07T20:09:03.322Z","doi":"10.25663/brainlife.app.681"},{"name":"fMRIPrep - Volume Output - ICA-AROMA","github":"vnbcs/app-fmriprep","desc":"fMRIPrep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting.","stats":{"success_rate":40.67179846046186,"groups":9,"users":9,"requested":10287,"gitinfo":{"desc":"runs fmriprep for brainlife","tags":["brain","fmri","mri","preprocessing"],"stats":{"stars":1},"contributors":[{"name":"Josh Faskowitz","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cff89de14be11ff2739e7"}],"examples":1,"runtime_mean":23089441.4,"runtime_std":15614858.941701828},"create_date":"2022-10-11T15:04:36.508Z","doi":"10.25663/brainlife.app.682"},{"name":"Compile tractmeasures csvs across project into one dataframe","github":"brainlife/app-compile-tractmeasures","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642cfff6de14be11ff2770b4"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642cfff6de14be11ff2770b5"}],"success_rate":13.346613545816732,"users":9,"groups":11,"runtime_mean":58869.54,"runtime_std":82864.24038117046,"requested":1021,"examples":0},"create_date":"2022-10-12T19:55:55.820Z","doi":"10.25663/brainlife.app.683"},{"name":"TractSeg from peaks","github":"brainlife/app-tractseg","desc":"Brainlife App for MIC-DKFZ/TractSeg. A tool for fast and accurate white matter bundle segmentation from Diffusion MRI using pretrained pytorch ML model.","stats":{"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"642cfffbde14be11ff277122"},{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642cfffbde14be11ff277123"}],"success_rate":72.25153595952295,"users":75,"groups":100,"runtime_mean":3566537.1,"runtime_std":3455392.223018305,"requested":18958,"examples":2},"create_date":"2022-10-17T21:08:03.687Z","doi":"10.25663/brainlife.app.684"},{"name":"Remove nodes from tract profiles","github":"brainlife/app-cut-tractmeasures-nodes","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0002de14be11ff27720b"}],"success_rate":98.84169884169884,"users":3,"groups":3,"runtime_mean":12701.09,"runtime_std":9679.494515825712,"requested":260,"examples":0},"create_date":"2022-10-18T15:34:00.062Z","doi":"10.25663/brainlife.app.685"},{"name":"fMRIPrep - Surface Output - ICA-AROMA","github":"vnbcs/app-fmriprep","desc":"fMRIPrep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting.","stats":{"success_rate":40.67179846046186,"groups":9,"users":9,"requested":10287,"gitinfo":{"desc":"runs fmriprep for brainlife","tags":["brain","fmri","mri","preprocessing"],"stats":{"stars":1},"contributors":[{"name":"Josh Faskowitz","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0007de14be11ff277223"}],"examples":1,"runtime_mean":23089441.4,"runtime_std":15614858.941701828},"create_date":"2022-10-20T15:41:31.028Z","doi":"10.25663/brainlife.app.686"},{"name":"Change strides of peaks","github":"brainlife/app-change-strides","desc":null,"stats":{"resources":[],"success_rate":90.47619047619048,"users":1,"groups":2,"requested":136,"examples":1,"runtime_mean":54864.10526315789,"runtime_std":21949.91652230796},"create_date":"2022-10-26T01:29:35.737Z","doi":"10.25663/brainlife.app.687"},{"name":"Fit Psychometric function","github":"antoniofs23/app-fitPsychFunc_test","desc":"app for brainlife.io that fits psychometric functions","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0012de14be11ff277244"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0012de14be11ff277245"}],"examples":0},"create_date":"2022-10-26T22:09:55.832Z","doi":"10.25663/brainlife.app.688"},{"name":"Generate images of FLAIR","github":"brainlife/app-slicer-fsl","desc":null,"stats":{"success_rate":82.31619858418544,"groups":185,"users":118,"runtime_mean":274514.93,"runtime_std":622047.7772298245,"requested":23119,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d0018de14be11ff277289"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0018de14be11ff27728a"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0018de14be11ff27728b"}],"examples":1},"create_date":"2022-10-27T16:31:11.203Z","doi":"10.25663/brainlife.app.689"},{"name":"Reslice T1w to Isotropic Voxel Dimensions using FSL","github":"brainlife/app-reslice-isotropic","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d001dde14be11ff277294"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d001dde14be11ff277295"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d001dde14be11ff277296"}],"success_rate":28.57142857142857,"users":1,"groups":1,"runtime_mean":1435917.5,"runtime_std":1401646.5,"requested":8,"examples":1},"create_date":"2022-10-27T21:17:47.906Z","doi":"10.25663/brainlife.app.690"},{"name":"Reslice T2w to Isotropic Voxel Dimensions using FSL ","github":"brainlife/app-reslice-isotropic","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d0022de14be11ff27729f"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0022de14be11ff2772a0"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0022de14be11ff2772a1"}],"success_rate":28.57142857142857,"users":1,"groups":1,"runtime_mean":1435917.5,"runtime_std":1401646.5,"requested":8,"examples":1},"create_date":"2022-10-28T01:06:48.757Z","doi":"10.25663/brainlife.app.691"},{"name":"Generate synthetic MP-RAGE T1 image from T1w data","github":"brainlife/app-synthsr","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d0027de14be11ff2772d5"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0027de14be11ff2772d6"}],"examples":2,"success_rate":89.90654205607477,"users":3,"groups":6,"runtime_mean":351287.67,"runtime_std":837949.9238282448,"requested":13702},"create_date":"2022-10-29T02:32:51.692Z","doi":"10.25663/brainlife.app.692"},{"name":"Generate synthetic MP-RAGE T1 image from T2w data","github":"brainlife/app-synthsr","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d002cde14be11ff277305"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d002cde14be11ff277306"}],"examples":1,"success_rate":89.90654205607477,"users":3,"groups":6,"runtime_mean":351287.67,"runtime_std":837949.9238282448,"requested":13702},"create_date":"2022-10-29T02:34:02.295Z","doi":"10.25663/brainlife.app.693"},{"name":"Generate synthetic MP-RAGE T1 image from clinical FLAIR data","github":"brainlife/app-synthsr","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d0032de14be11ff27731d"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0032de14be11ff27731e"}],"examples":1,"success_rate":89.90654205607477,"users":3,"groups":6,"runtime_mean":351287.67,"runtime_std":837949.9238282448,"requested":13702},"create_date":"2022-10-29T02:34:26.635Z","doi":"10.25663/brainlife.app.694"},{"name":"Combine 2D T1w images into a single 3D volume - 3 orientations","github":"bacaron/app-combine-2d-to-3d","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d0037de14be11ff27732e"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0037de14be11ff27732f"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0037de14be11ff277330"}],"success_rate":26.141078838174277,"users":1,"groups":3,"runtime_mean":13219251.825396825,"runtime_std":8193047.66735271,"requested":276,"examples":1},"create_date":"2022-10-29T23:10:12.532Z","doi":"10.25663/brainlife.app.695"},{"name":"Combine 2D T1w images into a single 3D volume - 2 orientations","github":"bacaron/app-combine-2d-to-3d","desc":null,"stats":{"success_rate":26.141078838174277,"groups":3,"users":1,"runtime_mean":13219251.825396825,"runtime_std":8193047.66735271,"requested":276,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d003cde14be11ff277339"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d003cde14be11ff27733a"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d003cde14be11ff27733b"}],"examples":1},"create_date":"2022-10-30T18:21:18.525Z","doi":"10.25663/brainlife.app.696"},{"name":"Combine 2D T2w images into a single 3D volume - 2 orientations","github":"bacaron/app-combine-2d-to-3d","desc":null,"stats":{"success_rate":26.141078838174277,"groups":3,"users":1,"runtime_mean":13219251.825396825,"runtime_std":8193047.66735271,"requested":276,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d0041de14be11ff27733e"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0041de14be11ff27733f"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0041de14be11ff277340"}],"examples":0},"create_date":"2022-10-30T20:19:05.230Z","doi":"10.25663/brainlife.app.697"},{"name":"Combine 2D T2w images into a single 3D volume - 3 orientations","github":"bacaron/app-combine-2d-to-3d","desc":null,"stats":{"success_rate":26.141078838174277,"groups":3,"users":1,"runtime_mean":13219251.825396825,"runtime_std":8193047.66735271,"requested":276,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d0047de14be11ff277375"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0047de14be11ff277376"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0047de14be11ff277377"}],"examples":1},"create_date":"2022-10-30T20:20:03.448Z","doi":"10.25663/brainlife.app.698"},{"name":"Change strides of tensor","github":"brainlife/app-change-strides","desc":null,"stats":{"resources":[],"success_rate":90.47619047619048,"users":1,"groups":2,"runtime_mean":54864.10526315789,"runtime_std":21949.91652230796,"requested":136,"examples":1},"create_date":"2022-10-31T18:31:16.908Z","doi":"10.25663/brainlife.app.699"},{"name":"Run MRIQC on Structural Data - T1w","github":"brainlife/app-mriqc","desc":"Runs MRIQC pipeline (http://mriqc.readthedocs.io/en/stable/reports/smri.html) from Poldrack Lab on selected T1 anatomy.","stats":{"success_rate":81.32886742483252,"groups":74,"users":49,"requested":23763,"gitinfo":{"desc":"Runs MRIQC pipeline (http://mriqc.readthedocs.io/en/stable/reports/smri.html) from Poldrack Lab on selected T1 anatomy.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0051de14be11ff2773d5"}],"examples":3,"runtime_mean":699483.09,"runtime_std":511608.74011592305},"create_date":"2022-11-03T17:16:15.038Z","doi":"10.25663/brainlife.app.701"},{"name":"Run MRIQC on Structural Data - T2w","github":"brainlife/app-mriqc","desc":"Runs MRIQC pipeline (http://mriqc.readthedocs.io/en/stable/reports/smri.html) from Poldrack Lab on selected T1 anatomy.","stats":{"success_rate":81.32886742483252,"groups":74,"users":49,"requested":23763,"gitinfo":{"desc":"Runs MRIQC pipeline (http://mriqc.readthedocs.io/en/stable/reports/smri.html) from Poldrack Lab on selected T1 anatomy.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0056de14be11ff2773eb"}],"examples":1,"runtime_mean":699483.09,"runtime_std":511608.74011592305},"create_date":"2022-11-03T17:18:26.784Z","doi":"10.25663/brainlife.app.702"},{"name":"Run MRIQC on Functional Data - FMRI","github":"brainlife/app-mriqc","desc":"Runs MRIQC pipeline (http://mriqc.readthedocs.io/en/stable/reports/smri.html) from Poldrack Lab on selected T1 anatomy.","stats":{"success_rate":81.32886742483252,"groups":74,"users":49,"requested":23763,"gitinfo":{"desc":"Runs MRIQC pipeline (http://mriqc.readthedocs.io/en/stable/reports/smri.html) from Poldrack Lab on selected T1 anatomy.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d005cde14be11ff277427"}],"examples":1,"runtime_mean":699483.09,"runtime_std":511608.74011592305},"create_date":"2022-11-03T17:19:35.977Z","doi":"10.25663/brainlife.app.703"},{"name":"FSL Reorient and Crop FLAIR","github":"brainlife/app-crop_reorient","desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","stats":{"success_rate":94.52861952861953,"groups":163,"users":106,"runtime_mean":464343.13,"runtime_std":3265360.1856333264,"requested":11099,"gitinfo":{"desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","tags":[],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0061de14be11ff277438"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0061de14be11ff277439"}],"examples":1},"create_date":"2022-11-06T21:34:23.402Z","doi":"10.25663/brainlife.app.704"},{"name":"Generate synthetic MP-RAGE T1 image from T1w and T2w data using SynthSR Hyperfine","github":"brainlife/app-synthsr","desc":null,"stats":{"success_rate":89.90654205607477,"groups":6,"users":3,"runtime_mean":351287.67,"runtime_std":837949.9238282448,"requested":13702,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d0066de14be11ff27746f"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0066de14be11ff277470"}],"examples":1},"create_date":"2022-11-11T04:15:41.723Z","doi":"10.25663/brainlife.app.705"},{"name":"Compute average measures per tract","github":"brainlife/app-compute-average-tractmeasure","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d006dde14be11ff2775ae"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d006dde14be11ff2775af"}],"success_rate":87.90697674418605,"users":5,"groups":5,"runtime_mean":111624.89,"runtime_std":119064.6799741128,"requested":451,"examples":1},"create_date":"2022-11-16T19:35:28.474Z","doi":"10.25663/brainlife.app.706"},{"name":"Convert tractmasks to rois","github":"brainlife/app-convert-tractmasks-to-rois","desc":"This app converts from tractmasks datatype to rois datatype.","stats":{"resources":[{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0072de14be11ff2775b9"}],"examples":1,"success_rate":93.39164237123421,"users":3,"groups":3,"runtime_mean":8425304.64,"runtime_std":56329493.74436096,"requested":1029},"create_date":"2022-12-01T16:29:17.801Z","doi":"10.25663/brainlife.app.707"},{"name":"Tractometry over tensor","github":"brainlife/app-tractometry-after-tractseg","desc":"This App computes tractometry on the TractSeg output.","stats":{"resources":[],"success_rate":77.62660619803476,"users":2,"groups":2,"requested":2652,"examples":1,"runtime_mean":2362816.61,"runtime_std":3648334.321288187},"create_date":"2022-12-03T14:30:30.830Z","doi":"10.25663/brainlife.app.708"},{"name":"Anatomically Constrained Tractography using precomputed 5tt & CSD - No DWI & T1w input","github":"bacaron/app-mrtrix3-act","desc":"Runs mrtrix3 ACT (Anatomically Constrained Tractography) using either single- or multi-shell diffusion-weighted MRI data. ","stats":{"success_rate":78.61335502992968,"groups":68,"users":34,"runtime_mean":15292131.23,"runtime_std":30785532.43603803,"requested":20639,"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d007dde14be11ff277636"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d007dde14be11ff277637"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642d007dde14be11ff277638"}],"examples":1},"create_date":"2022-12-07T21:51:43.047Z","doi":"10.25663/brainlife.app.709"},{"name":"Merge multiple ROIs together using AFNI","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"success_rate":83.53765323992994,"groups":58,"users":27,"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"requested":13134,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0083de14be11ff277654"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0083de14be11ff277655"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642d0083de14be11ff277656"}],"examples":1},"create_date":"2023-01-05T21:55:59.710Z","doi":"10.25663/brainlife.app.710"},{"name":"Combine classified white matter tracts","github":"brainlife/app-combine-tracts","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0089de14be11ff277682"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0089de14be11ff277683"}],"success_rate":66.66666666666666,"users":1,"groups":1,"requested":4,"examples":1,"runtime_mean":347822,"runtime_std":272308},"create_date":"2023-01-08T01:19:00.528Z","doi":"10.25663/brainlife.app.711"},{"name":"Bundle segmented tracks by eccentricity - Parcellation (multiple parcellations)","github":"brainlife/app-eccentricity-classification","desc":null,"stats":{"success_rate":72.15189873417721,"groups":3,"users":1,"runtime_mean":845065.18,"runtime_std":765765.3651332945,"requested":301,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d008ede14be11ff2776c1"}],"examples":1},"create_date":"2023-01-08T06:26:11.358Z","doi":"10.25663/brainlife.app.712"},{"name":"Generate Eccentricity Parcellations from pRF - Diffusion Space","github":"brainlife/app-roiGenerator","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","stats":{"success_rate":83.53765323992994,"groups":58,"users":27,"runtime_mean":10950145.15,"runtime_std":20251521.151558306,"requested":13134,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0094de14be11ff2776e8"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0094de14be11ff2776e9"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642d0094de14be11ff2776ea"}],"examples":0},"create_date":"2023-01-08T20:12:08.052Z","doi":"10.25663/brainlife.app.713"},{"name":"Bundle segmented tracks by eccentricity - Parcellation","github":"brainlife/app-eccentricity-classification","desc":null,"stats":{"success_rate":72.15189873417721,"groups":3,"users":1,"runtime_mean":845065.18,"runtime_std":765765.3651332945,"requested":301,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d009ade14be11ff27776f"}],"examples":0},"create_date":"2023-01-08T22:41:20.477Z","doi":"10.25663/brainlife.app.714"},{"name":"Apply warp to or from standard space to ROIs (T1w) - Scanner T1 space","github":"brainlife/app-register-rois-mni","desc":null,"stats":{"success_rate":77.3135359116022,"groups":8,"users":7,"runtime_mean":7732191,"runtime_std":9388716.477521751,"requested":3878,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d009fde14be11ff277773"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d009fde14be11ff277774"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642d009fde14be11ff277775"}],"examples":0},"create_date":"2023-01-21T20:34:38.068Z","doi":"10.25663/brainlife.app.715"},{"name":"Apply warp to or from standard space to ROIs (T1w) - ACPC T1 space","github":"brainlife/app-register-rois-mni","desc":null,"stats":{"success_rate":77.3135359116022,"groups":8,"users":7,"runtime_mean":7732191,"runtime_std":9388716.477521751,"requested":3878,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d00a5de14be11ff277829"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d00a5de14be11ff27782a"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642d00a5de14be11ff27782b"}],"examples":1},"create_date":"2023-01-21T20:35:07.351Z","doi":"10.25663/brainlife.app.716"},{"name":" Apply warp to or from standard space to ROIs (T2w) - Scanner T2 space ","github":"brainlife/app-register-rois-mni","desc":null,"stats":{"success_rate":77.3135359116022,"groups":8,"users":7,"runtime_mean":7732191,"runtime_std":9388716.477521751,"requested":3878,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d00aade14be11ff27782e"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d00aade14be11ff27782f"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642d00aade14be11ff277830"}],"examples":0},"create_date":"2023-01-21T20:38:55.722Z","doi":"10.25663/brainlife.app.717"},{"name":"Apply warp to or from standard space to ROIs (T2w) - ACPC T2 space","github":"brainlife/app-register-rois-mni","desc":null,"stats":{"success_rate":77.3135359116022,"groups":8,"users":7,"runtime_mean":7732191,"runtime_std":9388716.477521751,"requested":3878,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d00b0de14be11ff277833"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d00b0de14be11ff277834"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642d00b0de14be11ff277835"}],"examples":0},"create_date":"2023-01-21T20:39:45.297Z","doi":"10.25663/brainlife.app.718"},{"name":"Create white matter mask from FA","github":"brainlife/app-white-matter-mask-fa","desc":null,"stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d00b5de14be11ff2778a3"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d00b5de14be11ff2778a4"}],"success_rate":5.263157894736842,"users":1,"groups":1,"runtime_mean":11354,"runtime_std":0,"requested":21,"examples":1},"create_date":"2023-01-23T17:13:50.470Z","doi":"10.25663/brainlife.app.719"},{"name":"Tissue-type segmentation with hsvs","github":"brainlife/app-mrtrix3-5tt","desc":"This app will generate a 5-tissue type mask (5tt) from a T1 anatomical image using mrtrix3's 5ttgen. This code was adapted from app-mrtrix3-act (https://brainlife.io/app/5aac2437f0b5260027e24ae1), written by Brent McPherson (bcmcpher@iu.edu).","stats":{"success_rate":74.46177645997165,"groups":94,"users":43,"runtime_mean":1095260.97,"runtime_std":390697.17401213583,"requested":21092,"resources":[],"examples":0},"create_date":"2023-01-24T04:25:50.147Z","doi":"10.25663/brainlife.app.720"},{"name":"Warp tractogram to MNI space using precomputed transformation","github":"brainlife/app-warp-tractogram","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d00c1de14be11ff2779c3"}],"success_rate":58.92463640370207,"users":1,"groups":1,"runtime_mean":661218.9,"runtime_std":160671.9892061774,"requested":2274,"examples":1},"create_date":"2023-01-26T19:36:27.586Z","doi":"10.25663/brainlife.app.721"},{"name":"Generate brain extracted image with SynthStrip (T1w)","github":"brainlife/app-synthstrip","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d00c6de14be11ff277a23"}],"success_rate":44.44444444444444,"users":4,"groups":5,"runtime_mean":86432.41666666667,"runtime_std":79831.7095984404,"requested":28,"examples":0},"create_date":"2023-02-01T17:42:28.654Z","doi":"10.25663/brainlife.app.722"},{"name":"Generate brain extracted image with SynthStrip (T2w)","github":"brainlife/app-synthstrip","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d00ccde14be11ff277a2a"}],"success_rate":44.44444444444444,"users":4,"groups":5,"runtime_mean":86432.41666666667,"runtime_std":79831.7095984404,"requested":28,"examples":1},"create_date":"2023-02-01T17:45:26.407Z","doi":"10.25663/brainlife.app.723"},{"name":"Generate brain extracted image with SynthStrip (FLAIR)","github":"brainlife/app-synthstrip","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d00d1de14be11ff277a2d"}],"success_rate":44.44444444444444,"users":4,"groups":5,"runtime_mean":86432.41666666667,"runtime_std":79831.7095984404,"requested":28,"examples":0},"create_date":"2023-02-01T17:51:48.270Z","doi":"10.25663/brainlife.app.724"},{"name":"Generate brain extracted image with SynthStrip (DWI)","github":"brainlife/app-synthstrip","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d00d6de14be11ff277a93"}],"success_rate":44.44444444444444,"users":4,"groups":5,"runtime_mean":86432.41666666667,"runtime_std":79831.7095984404,"requested":28,"examples":1},"create_date":"2023-02-01T18:24:24.649Z","doi":"10.25663/brainlife.app.725"},{"name":"Generate brain extracted image with SynthStrip (FMRI)","github":"brainlife/app-synthstrip","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d00dcde14be11ff277aa0"}],"success_rate":44.44444444444444,"users":4,"groups":5,"runtime_mean":86432.41666666667,"runtime_std":79831.7095984404,"requested":28,"examples":1},"create_date":"2023-02-01T18:41:53.738Z","doi":"10.25663/brainlife.app.726"},{"name":"Warp ROIs for Visual White Matter From MNI to T1 space","github":"brainlife/app-register-rois-mni","desc":null,"stats":{"success_rate":77.3135359116022,"groups":8,"users":7,"runtime_mean":7732191,"runtime_std":9388716.477521751,"requested":3878,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d00e1de14be11ff277b00"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d00e1de14be11ff277b01"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642d00e1de14be11ff277b02"}],"examples":0},"create_date":"2023-02-03T20:38:11.764Z","doi":"10.25663/brainlife.app.727"},{"name":"FSL Brain Extraction (BET) on FLAIR","github":"brainlife/app-FSLBET","desc":"Brain Extraction via FSL's BET command","stats":{"success_rate":62.43668720054757,"groups":115,"users":73,"runtime_mean":29685.56,"runtime_std":9501.90325073877,"requested":42857,"gitinfo":{"desc":"Brain Extraction via FSL's BET command","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d00e6de14be11ff277b09"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642d00e6de14be11ff277b0a"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d00e6de14be11ff277b0b"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642d00e6de14be11ff277b0c"}],"examples":1},"create_date":"2023-02-09T18:06:29.536Z","doi":"10.25663/brainlife.app.728"},{"name":"DSC evaluation (wmc - wmc) - Seperate tractograms","github":"bacaron/app-compute-dsc","desc":"Compute the degree of overlap between two bundle masks using the Dice Similarity Coefficient (DSC) score.","stats":{"success_rate":100,"groups":1,"users":1,"runtime_mean":75563,"runtime_std":0,"requested":1,"gitinfo":{"desc":"Compute the Dice Similarity Coefficient (DSC) between corresponding tracts of the given segmentation and the ground truth when using HCP data.","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"resources":[{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d00ecde14be11ff277bc5"}],"examples":1},"create_date":"2023-02-09T20:39:03.936Z","doi":"10.25663/brainlife.app.729"},{"name":"Test app to add value to t1","github":"bacaron/app-add-to-t1","desc":"This is a test app that will add a value of 1 to each voxel of a t1, and output a new t1","stats":{"resources":[],"examples":0},"create_date":"2023-02-10T16:51:39.790Z","doi":"10.25663/brainlife.app.730"},{"name":"Warp and resample surface label ROIs to volume (Freesurfer space)","github":"brainlife/app-warp-standard-label-rois","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d00f7de14be11ff277bdc"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d00f7de14be11ff277bdd"}],"success_rate":50,"users":2,"groups":2,"runtime_mean":452873.47222222225,"runtime_std":548676.4513598705,"requested":72,"examples":0},"create_date":"2023-02-15T16:45:21.978Z","doi":"10.25663/brainlife.app.731"},{"name":"Convert thalamic segmentation into parcellation","github":"brainlife/app-generate-parc-thal-amyg-hipp","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d00fcde14be11ff277bee"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d00fcde14be11ff277bef"}],"examples":1,"success_rate":71.50537634408603,"users":4,"groups":11,"runtime_mean":172635.27,"runtime_std":452731.959968166,"requested":221},"create_date":"2023-02-17T05:38:48.455Z","doi":"10.25663/brainlife.app.732"},{"name":"Convert hippocampal and amygdala segmentation into parcellation","github":"brainlife/app-generate-parc-thal-amyg-hipp","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0101de14be11ff277c03"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0101de14be11ff277c04"}],"examples":0,"success_rate":71.50537634408603,"users":4,"groups":11,"runtime_mean":172635.27,"runtime_std":452731.959968166,"requested":221},"create_date":"2023-02-17T05:40:51.298Z","doi":"10.25663/brainlife.app.733"},{"name":"Convert thalamic, hippocampal and amygdala segmentation into parcellation","github":"brainlife/app-generate-parc-thal-amyg-hipp","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0107de14be11ff277c5c"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0107de14be11ff277c5d"}],"examples":1,"success_rate":71.50537634408603,"users":4,"groups":11,"runtime_mean":172635.27,"runtime_std":452731.959968166,"requested":221},"create_date":"2023-02-17T05:41:36.240Z","doi":"10.25663/brainlife.app.734"},{"name":"Show events in an MEG file","github":"dnacombo/app-eventslog","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d010cde14be11ff277c63"}],"success_rate":16.666666666666664,"users":1,"groups":1,"requested":6,"examples":1,"runtime_mean":22646,"runtime_std":0},"create_date":"2023-02-22T12:11:43.283Z","doi":"10.25663/brainlife.app.735"},{"name":"Map  ROIs to cortical surface","github":"brainlife/app-cortex-tissue-mapping","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","stats":{"success_rate":76.52514036969276,"groups":44,"users":16,"runtime_mean":250899.08,"runtime_std":392917.6303011785,"requested":19134,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0112de14be11ff277ccb"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0112de14be11ff277ccc"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642d0112de14be11ff277ccd"}],"examples":1},"create_date":"2023-02-26T18:26:58.913Z","doi":"10.25663/brainlife.app.736"},{"name":"Map tract endpoint ROIs to cortical surface for quantitative analyses - fsaverage","github":"brainlife/app-cortex-tissue-mapping","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","stats":{"success_rate":76.52514036969276,"groups":44,"users":16,"runtime_mean":250899.08,"runtime_std":392917.6303011785,"requested":19134,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0117de14be11ff277d01"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0117de14be11ff277d02"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642d0117de14be11ff277d03"}],"examples":0},"create_date":"2023-02-26T18:46:11.071Z","doi":"10.25663/brainlife.app.737"},{"name":"Segment hippocampal and amygdala nuclei","github":"brainlife/app-segment-hippamyg-nuclei","desc":"This app will segment the hippocampus and amygdala into its multiple components using the developer version of Freesurfer's segmentThalamicNuclei.sh function (http://freesurfer.net/fswiki/ThalamicNuclei). This app takes a Freesurfer segmentation in as an input and generates .mgz files with the appropriate thalamic segmentation inside the Freesurfer","stats":{"success_rate":100,"groups":2,"users":1,"runtime_mean":780549.3333333334,"runtime_std":39916.97547270946,"requested":6,"gitinfo":{"desc":"This app will segment the thalamus into its multiple components using the developer version of Freesurfer's segmentThalamicNuclei.sh function (http://freesurfer.net/fswiki/ThalamicNuclei). This app takes a Freesurfer segmentation in as an input and generates .mgz files with the appropriate thalamic segmentation inside the Freesurfer directory as an output.","tags":["analysis","anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"resources":[{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d011cde14be11ff277d67"}],"examples":0},"create_date":"2023-02-28T16:30:04.978Z","doi":"10.25663/brainlife.app.738"},{"name":"Combine two parcellations into a single parcellation","github":"brainlife/app-combine-parcellation","desc":null,"stats":{"resources":[{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0123de14be11ff277e54"}],"success_rate":86.1280487804878,"users":3,"groups":8,"runtime_mean":133746.13,"runtime_std":24933.8965353011,"requested":680,"examples":1},"create_date":"2023-03-01T00:21:33.630Z","doi":"10.25663/brainlife.app.739"},{"name":"Plot projectors stored in MEG file using MNE-python","github":"dnacombo/app-plot_proj_topomaps-raw","desc":"Brainlife App to plot SSP projectors","stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d0128de14be11ff277e57"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642d0128de14be11ff277e58"}],"examples":0,"success_rate":0,"users":1,"groups":1,"requested":1},"create_date":"2023-03-02T11:53:23.661Z","doi":"10.25663/brainlife.app.740"},{"name":"Interpolate bad channels","github":"guiomar/app-interpolate","desc":null,"stats":{"resources":[],"success_rate":50,"users":2,"groups":2,"requested":2,"examples":1,"runtime_mean":444314,"runtime_std":0},"create_date":"2023-03-07T14:47:01.270Z","doi":"10.25663/brainlife.app.741"},{"name":"EEG egi to mne/raw","github":"guiomar/app-egi2mne","desc":null,"stats":{"success_rate":0,"groups":1,"users":1,"requested":1,"resources":[],"examples":0},"create_date":"2023-03-07T15:08:54.668Z","doi":"10.25663/brainlife.app.742"},{"name":"Reject bad data in raw MEG file using MNE-python","github":"dnacombo/app-mark_bad-raw","desc":"Brainlife app to mark bad channels and segments in a raw MNE by hand.","stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d0138de14be11ff277e65"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642d0138de14be11ff277e66"}],"examples":0},"create_date":"2023-03-07T15:42:39.458Z","doi":"10.25663/brainlife.app.743"},{"name":"Apply baseline correction to epoched data (MEG/EEG)","github":"KSalibay/app-apply-baseline","desc":"Apply baseline correction to MNE Epochs instance","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d013dde14be11ff277e69"}],"examples":0,"success_rate":0,"users":1,"groups":1,"requested":1},"create_date":"2023-03-08T04:04:49.068Z","doi":"10.25663/brainlife.app.744"},{"name":"Set EEG reference (on epoched data)","github":"KSalibay/app-rereference","desc":"App for rereferencing EEG recordings","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0142de14be11ff277e6c"}],"examples":0,"success_rate":0,"users":1,"groups":1,"requested":3},"create_date":"2023-03-08T04:23:58.151Z","doi":"10.25663/brainlife.app.745"},{"name":"Extract summary measures within tissue types","github":"brainlife/app-extract-diffusion-metrics-tissue-types","desc":null,"stats":{"success_rate":33.33333333333333,"groups":4,"users":3,"runtime_mean":36380.2,"runtime_std":18245.891224053707,"requested":17,"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642d0148de14be11ff277ee8"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0148de14be11ff277ee9"}],"examples":1},"create_date":"2023-03-15T17:51:17.324Z","doi":"10.25663/brainlife.app.746"},{"name":"Convert surface-based annotation in standard space to parcellation (volume)","github":"brainlife/app-annotation-to-parcellation","desc":null,"stats":{"resources":[{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d014dde14be11ff277ef0"}],"examples":1,"success_rate":100,"users":1,"groups":1,"runtime_mean":188910,"runtime_std":0,"requested":1},"create_date":"2023-03-17T00:33:04.986Z","doi":"10.25663/brainlife.app.747"},{"name":"Warp and resample surface label annotation to parcellation volume (Freesurfer space)","github":"brainlife/app-warp-standard-label-rois","desc":null,"stats":{"success_rate":50,"groups":2,"users":2,"runtime_mean":452873.47222222225,"runtime_std":548676.4513598705,"requested":72,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0152de14be11ff277f0e"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0152de14be11ff277f0f"}],"examples":0},"create_date":"2023-03-20T22:27:19.728Z","doi":"10.25663/brainlife.app.748"},{"name":"Reslice parcellation to match input anatomy","github":"bacaron/app-reslice-roi-t1","desc":null,"stats":{"success_rate":36.64942300039793,"groups":9,"users":4,"runtime_mean":578251.76,"runtime_std":1161990.5048332633,"requested":12030,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d0158de14be11ff277f3d"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0158de14be11ff277f3e"}],"examples":0},"create_date":"2023-03-21T20:18:05.115Z","doi":"10.25663/brainlife.app.749"},{"name":"Convert freesurfer annotations to parcellation","github":"brainlife/app-convert-freesurfer-parcellation","desc":null,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"642d015dde14be11ff277f45"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d015dde14be11ff277f46"}],"success_rate":50,"users":1,"groups":2,"runtime_mean":517225,"runtime_std":907538.3088972057,"requested":12,"examples":1},"create_date":"2023-03-22T19:50:49.254Z","doi":"10.25663/brainlife.app.750"},{"name":"Apply mask to extract brain data - T1","github":"brainlife/app-FSLBET","desc":"Brain Extraction via FSL's BET command","stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d0162de14be11ff277fb1"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642d0162de14be11ff277fb2"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0162de14be11ff277fb3"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642d0162de14be11ff277fb4"}],"success_rate":62.43668720054757,"users":73,"groups":115,"runtime_mean":29685.56,"runtime_std":9501.90325073877,"requested":42857,"examples":0},"create_date":"2023-03-27T16:42:26.898Z","doi":"10.25663/brainlife.app.751"},{"name":"Apply mask to extract brain data - T2","github":"brainlife/app-FSLBET","desc":"Brain Extraction via FSL's BET command","stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d0168de14be11ff277fbe"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642d0168de14be11ff277fbf"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0168de14be11ff277fc0"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642d0168de14be11ff277fc1"}],"success_rate":62.43668720054757,"users":73,"groups":115,"runtime_mean":29685.56,"runtime_std":9501.90325073877,"requested":42857,"examples":1},"create_date":"2023-03-27T16:43:12.525Z","doi":"10.25663/brainlife.app.752"},{"name":"Apply mask to extract brain data - FLAIR","github":"brainlife/app-FSLBET","desc":"Brain Extraction via FSL's BET command","stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d016dde14be11ff277fcd"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642d016dde14be11ff277fce"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d016dde14be11ff277fcf"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642d016dde14be11ff277fd0"}],"success_rate":62.43668720054757,"users":73,"groups":115,"runtime_mean":29685.56,"runtime_std":9501.90325073877,"requested":42857,"examples":1},"create_date":"2023-03-27T16:43:34.272Z","doi":"10.25663/brainlife.app.753"},{"name":"Apply mask to extract brain data - BOLD","github":"brainlife/app-FSLBET","desc":"Brain Extraction via FSL's BET command","stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d0172de14be11ff277fd4"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642d0172de14be11ff277fd5"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0172de14be11ff277fd6"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642d0172de14be11ff277fd7"}],"success_rate":62.43668720054757,"users":73,"groups":115,"runtime_mean":29685.56,"runtime_std":9501.90325073877,"requested":42857,"examples":0},"create_date":"2023-03-27T16:43:58.622Z","doi":"10.25663/brainlife.app.754"},{"name":"Apply mask to extract brain data - DWI","github":"brainlife/app-FSLBET","desc":"Brain Extraction via FSL's BET command","stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"642d0177de14be11ff277fdb"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"642d0177de14be11ff277fdc"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"642d0177de14be11ff277fdd"},{"resource_id":"637676756408745da79f04b4","name":"Lonestar6 @ TACC/UT","_id":"642d0177de14be11ff277fde"}],"success_rate":62.43668720054757,"users":73,"groups":115,"runtime_mean":29685.56,"runtime_std":9501.90325073877,"requested":42857,"examples":0},"create_date":"2023-03-27T16:44:20.431Z","doi":"10.25663/brainlife.app.755"},{"name":"Concatenate MNE raws","github":"ksalibay/app-concat","desc":"Concatenate multiple MNE.Raw instances into single .Raw","stats":{"resources":[]},"create_date":"2023-04-05T17:26:05.264Z"}]